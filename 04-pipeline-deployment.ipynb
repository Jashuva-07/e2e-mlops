{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "109707f2",
   "metadata": {},
   "source": [
    "# 04 - Test and Deploy Training Pipeline to Vertex Pipelines\n",
    "\n",
    "The purpose of this notebook is to test, deploy, and run the `TFX` pipeline on `Vertex Pipelines`. The notebook covers the following tasks:\n",
    "1. Run the tests locally.\n",
    "2. Run the pipeline using `Vertex Pipelines`\n",
    "3. Execute the pipeline deployment `CI/CD` steps using `Cloud Build`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a51af1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133e7d80",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3bb184e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version: 1.15.1\n",
      "KFP Version: 2.5.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import kfp\n",
    "import tfx\n",
    "\n",
    "print(\"Tensorflow Version:\", tfx.__version__)\n",
    "print(\"KFP Version:\", kfp.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7bdded",
   "metadata": {},
   "source": [
    "### Setup Google Cloud project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b4b22be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project ID: supply-chain-twin-349311\n",
      "Region: us-central1\n",
      "Bucket name: test-lora\n",
      "Service Account: db-migration-genai@supply-chain-twin-349311.iam.gserviceaccount.com\n",
      "Vertex API Parent URI: projects/supply-chain-twin-349311/locations/us-central1\n"
     ]
    }
   ],
   "source": [
    "PROJECT = 'supply-chain-twin-349311' # Change to your project id.\n",
    "REGION = 'us-central1' # Change to your region.\n",
    "BUCKET = 'test-lora' # Change to your bucket name.\n",
    "SERVICE_ACCOUNT =\"db-migration-genai@supply-chain-twin-349311.iam.gserviceaccount.com\"\n",
    "\n",
    "if PROJECT == \"\" or PROJECT is None or PROJECT == \"[your-project-id]\":\n",
    "    # Get your GCP project id from gcloud\n",
    "    shell_output = !gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT = shell_output[0]\n",
    "    \n",
    "if SERVICE_ACCOUNT == \"\" or SERVICE_ACCOUNT is None or SERVICE_ACCOUNT == \"[your-service-account]\":\n",
    "    # Get your GCP project id from gcloud\n",
    "    shell_output = !gcloud config list --format 'value(core.account)' 2>/dev/null\n",
    "    SERVICE_ACCOUNT = shell_output[0]\n",
    "    \n",
    "if BUCKET == \"\" or BUCKET is None or BUCKET == \"[your-bucket-name]\":\n",
    "    # Get your bucket name to GCP projet id\n",
    "    BUCKET = PROJECT\n",
    "    # Try to create the bucket if it doesn'exists\n",
    "    ! gsutil mb -l $REGION gs://$BUCKET\n",
    "    print(\"\")\n",
    "    \n",
    "PARENT = f\"projects/{PROJECT}/locations/{REGION}\"\n",
    "    \n",
    "print(\"Project ID:\", PROJECT)\n",
    "print(\"Region:\", REGION)\n",
    "print(\"Bucket name:\", BUCKET)\n",
    "print(\"Service Account:\", SERVICE_ACCOUNT)\n",
    "print(\"Vertex API Parent URI:\", PARENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660a9dc9",
   "metadata": {},
   "source": [
    "### Set configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a75e169",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gcr.io/supply-chain-twin-349311/cicd:latest'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BQ_LOCATION = 'US'\n",
    "BQ_DATASET_NAME = 'chi_e2e' # Change to your BQ dataset name.\n",
    "BQ_TABLE_NAME = 'chicago_taxitrips_prep'\n",
    "\n",
    "VERSION = 'v09'\n",
    "DATASET_DISPLAY_NAME = 'chicago-taxi-tips'\n",
    "MODEL_DISPLAY_NAME = f'{DATASET_DISPLAY_NAME}-classifier-{VERSION}'\n",
    "PIPELINE_NAME = f'{MODEL_DISPLAY_NAME}-train-pipeline'\n",
    "\n",
    "CICD_IMAGE_NAME = 'cicd:latest'\n",
    "CICD_IMAGE_URI = f\"gcr.io/{PROJECT}/{CICD_IMAGE_NAME}\"\n",
    "CICD_IMAGE_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06be3555",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'src/raw_schema/.ipynb_checkpoints/': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm -r src/raw_schema/.ipynb_checkpoints/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44678373",
   "metadata": {},
   "source": [
    "## 1. Run the CICD steps locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68204ed",
   "metadata": {},
   "source": [
    "### Set pipeline configurations for the local run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05a1d20d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"DATASET_DISPLAY_NAME\"] = DATASET_DISPLAY_NAME\n",
    "os.environ[\"MODEL_DISPLAY_NAME\"] =  MODEL_DISPLAY_NAME\n",
    "os.environ[\"PIPELINE_NAME\"] = PIPELINE_NAME\n",
    "os.environ[\"PROJECT\"] = PROJECT\n",
    "os.environ[\"REGION\"] = REGION\n",
    "os.environ[\"BQ_LOCATION\"] = BQ_LOCATION\n",
    "os.environ[\"BQ_DATASET_NAME\"] = BQ_DATASET_NAME\n",
    "os.environ[\"BQ_TABLE_NAME\"] = BQ_TABLE_NAME\n",
    "os.environ[\"GCS_LOCATION\"] = f\"gs://{BUCKET}/{DATASET_DISPLAY_NAME}/e2e_tests\"\n",
    "os.environ[\"TRAIN_LIMIT\"] = \"1000\"\n",
    "os.environ[\"TEST_LIMIT\"] = \"100\"\n",
    "os.environ[\"UPLOAD_MODEL\"] = \"0\"\n",
    "os.environ[\"ACCURACY_THRESHOLD\"] = \"0.1\"\n",
    "os.environ[\"BEAM_RUNNER\"] = \"DirectRunner\"\n",
    "os.environ[\"TRAINING_RUNNER\"] = \"local\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d353e3d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-27 07:17:28.954647: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-27 07:17:28.954756: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-27 07:17:28.956929: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-27 07:17:28.967127: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-27 07:17:30.402802: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING:root:TensorFlow Decision Forests 1.9.1 is compatible with the following TensorFlow Versions: ['2.16.1']. However, TensorFlow 2.15.0 was detected. This can cause issues with the TF API and symbols in the custom C++ ops. See the TF and TF-DF compatibility table at https://github.com/tensorflow/decision-forests/blob/main/documentation/known_issues.md#compatibility-table.\n",
      "WARNING:root:Failure to load the inference.so custom c++ tensorflow ops. This error is likely caused the version of TensorFlow and TensorFlow Decision Forests are not compatible. Full error:/opt/conda/lib/python3.10/site-packages/tensorflow_decision_forests/tensorflow/ops/inference/inference.so: undefined symbol: _ZN10tensorflow20OpKernelConstruction21CtxFailureWithWarningEPKciRKN4absl12lts_202308026StatusE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT: supply-chain-twin-349311\n",
      "REGION: us-central1\n",
      "GCS_LOCATION: gs://test-lora/chicago-taxi-tips/e2e_tests\n",
      "ARTIFACT_STORE_URI: gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts\n",
      "MODEL_REGISTRY_URI: gs://test-lora/chicago-taxi-tips/e2e_tests/model_registry\n",
      "DATASET_DISPLAY_NAME: chicago-taxi-tips\n",
      "MODEL_DISPLAY_NAME: chicago-taxi-tips-classifier-v09\n",
      "PIPELINE_NAME: chicago-taxi-tips-classifier-v09-train-pipeline\n",
      "ML_USE_COLUMN: ml_use\n",
      "EXCLUDE_COLUMNS: trip_start_timestamp\n",
      "TRAIN_LIMIT: 1000\n",
      "TEST_LIMIT: 100\n",
      "SERVE_LIMIT: 0\n",
      "NUM_TRAIN_SPLITS: 4\n",
      "NUM_EVAL_SPLITS: 1\n",
      "ACCURACY_THRESHOLD: 0.1\n",
      "USE_KFP_SA: False\n",
      "TFX_IMAGE_URI: gcr.io/supply-chain-twin-349311/tfx-chicago-taxi-tips:latest\n",
      "BEAM_RUNNER: DirectRunner\n",
      "BEAM_DIRECT_PIPELINE_ARGS: ['--project=supply-chain-twin-349311', '--temp_location=gs://test-lora/chicago-taxi-tips/e2e_tests/temp']\n",
      "BEAM_DATAFLOW_PIPELINE_ARGS: ['--project=supply-chain-twin-349311', '--temp_location=gs://test-lora/chicago-taxi-tips/e2e_tests/temp', '--region=us-central1', '--runner=DirectRunner']\n",
      "TRAINING_RUNNER: local\n",
      "VERTEX_TRAINING_ARGS: {'project': 'supply-chain-twin-349311', 'worker_pool_specs': [{'machine_spec': {'machine_type': 'n1-standard-4'}, 'replica_count': 1, 'container_spec': {'image_uri': 'gcr.io/supply-chain-twin-349311/tfx-chicago-taxi-tips:latest'}}]}\n",
      "VERTEX_TRAINING_CONFIG: {'ai_platform_training_enable_ucaip': True, 'ai_platform_training_ucaip_region': 'us-central1', 'ai_platform_training_args': {'project': 'supply-chain-twin-349311', 'worker_pool_specs': [{'machine_spec': {'machine_type': 'n1-standard-4'}, 'replica_count': 1, 'container_spec': {'image_uri': 'gcr.io/supply-chain-twin-349311/tfx-chicago-taxi-tips:latest'}}]}, 'use_gpu': False}\n",
      "SERVING_RUNTIME: tf2-cpu.2-5\n",
      "SERVING_IMAGE_URI: us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-5:latest\n",
      "BATCH_PREDICTION_BQ_DATASET_NAME: playground_us\n",
      "BATCH_PREDICTION_BQ_TABLE_NAME: chicago_taxitrips_prep\n",
      "BATCH_PREDICTION_BEAM_ARGS: {'runner': 'DirectRunner', 'temporary_dir': 'gs://test-lora/chicago-taxi-tips/e2e_tests/temp', 'gcs_location': 'gs://test-lora/chicago-taxi-tips/e2e_tests/temp', 'project': 'supply-chain-twin-349311', 'region': 'us-central1', 'setup_file': './setup.py'}\n",
      "BATCH_PREDICTION_JOB_RESOURCES: {'machine_type': 'n1-standard-2', 'starting_replica_count': 1, 'max_replica_count': 10}\n",
      "DATASTORE_PREDICTION_KIND: chicago-taxi-tips-classifier-v09-predictions\n",
      "ENABLE_CACHE: 0\n",
      "UPLOAD_MODEL: 0\n"
     ]
    }
   ],
   "source": [
    "from src.tfx_pipelines import config\n",
    "import importlib\n",
    "importlib.reload(config)\n",
    "\n",
    "for key, value in config.__dict__.items():\n",
    "    if key.isupper(): print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d51c12",
   "metadata": {},
   "source": [
    "### Run unit tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309c1913-3e7e-4e39-8b8a-8da8b73b4f85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d4ccac-b6f0-49ff-8972-8ae711d69726",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install typing_extensions==4.7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9be84a8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.10.14, pytest-8.2.2, pluggy-1.5.0\n",
      "rootdir: /home/jupyter/mlops-with-vertex-ai\n",
      "plugins: typeguard-4.3.0, anyio-4.4.0, time-machine-2.14.1\n",
      "collected 2 items                                                              \u001b[0m\u001b[1m\n",
      "\n",
      "src/tests/datasource_utils_tests.py BigQuery Source: supply-chain-twin-349311.chi_e2e.chicago_taxitrips_prep\n",
      "\u001b[32m.\u001b[0mBigQuery Source: supply-chain-twin-349311.chi_e2e.chicago_taxitrips_prep\n",
      "\u001b[32m.\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 10.16s\u001b[0m\u001b[32m ==============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!py.test src/tests/datasource_utils_tests.py -s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4358f955",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.10.14, pytest-8.2.2, pluggy-1.5.0\n",
      "rootdir: /home/jupyter/mlops-with-vertex-ai\n",
      "plugins: typeguard-4.3.0, anyio-4.4.0, time-machine-2.14.1\n",
      "\u001b[1mcollecting ... \u001b[0m2024-06-27 07:17:57.907375: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-27 07:17:57.907443: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-27 07:17:57.909202: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-27 07:17:57.918398: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-27 07:17:59.304496: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "collected 2 items                                                              \u001b[0m\u001b[1m\n",
      "\n",
      "src/tests/model_tests.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 3.80s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!py.test src/tests/model_tests.py -s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa00fd5",
   "metadata": {},
   "source": [
    "### Run e2e pipeline test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb9aad70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.10.14, pytest-8.2.2, pluggy-1.5.0\n",
      "rootdir: /home/jupyter/mlops-with-vertex-ai\n",
      "plugins: typeguard-4.3.0, anyio-4.4.0, time-machine-2.14.1\n",
      "\u001b[1mcollecting ... \u001b[0m2024-06-27 07:18:05.930147: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-27 07:18:05.930210: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-27 07:18:05.931826: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-27 07:18:05.940504: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-27 07:18:07.269377: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "collected 1 item                                                               \u001b[0m\u001b[1m\n",
      "\n",
      "src/tests/pipeline_deployment_tests.py upload_model: 0\n",
      "Pipeline e2e test artifacts stored in: gs://test-lora/chicago-taxi-tips/e2e_tests\n",
      "ML metadata store is ready.\n",
      "Excluding no splits because exclude_splits is not set.\n",
      "Excluding no splits because exclude_splits is not set.\n",
      "Pipeline components: ['HyperparamsGen', 'TrainDataGen', 'TestDataGen', 'StatisticsGen', 'SchemaImporter', 'ExampleValidator', 'DataTransformer', 'WarmstartModelResolver', 'ModelTrainer', 'BaselineModelResolver', 'ModelEvaluator', 'ModelPusher']\n",
      "Beam pipeline args: ['--project=supply-chain-twin-349311', '--temp_location=gs://test-lora/chicago-taxi-tips/e2e_tests/temp']\n",
      "Generating ephemeral wheel package for '/home/jupyter/mlops-with-vertex-ai/src/preprocessing/transformations.py' (including modules: ['etl', 'transformations']).\n",
      "User module package has hash fingerprint version de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d.\n",
      "Executing: ['/opt/conda/bin/python', '/var/tmp/tmpw63y1g4i/_tfx_generated_setup.py', 'bdist_wheel', '--bdist-dir', '/var/tmp/tmpbk67vg9t', '--dist-dir', '/var/tmp/tmpbk39x59b']\n",
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "copying etl.py -> build/lib\n",
      "copying transformations.py -> build/lib\n",
      "/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "!!\n",
      "\n",
      "        ********************************************************************************\n",
      "        Please avoid running ``setup.py`` directly.\n",
      "        Instead, use pypa/build, pypa/installer or other\n",
      "        standards-based tools.\n",
      "\n",
      "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "        ********************************************************************************\n",
      "\n",
      "!!\n",
      "  self.initialize_options()\n",
      "installing to /var/tmp/tmpbk67vg9t\n",
      "running install\n",
      "running install_lib\n",
      "copying build/lib/etl.py -> /var/tmp/tmpbk67vg9t\n",
      "copying build/lib/transformations.py -> /var/tmp/tmpbk67vg9t\n",
      "running install_egg_info\n",
      "running egg_info\n",
      "creating tfx_user_code_DataTransformer.egg-info\n",
      "writing tfx_user_code_DataTransformer.egg-info/PKG-INFO\n",
      "writing dependency_links to tfx_user_code_DataTransformer.egg-info/dependency_links.txt\n",
      "writing top-level names to tfx_user_code_DataTransformer.egg-info/top_level.txt\n",
      "writing manifest file 'tfx_user_code_DataTransformer.egg-info/SOURCES.txt'\n",
      "reading manifest file 'tfx_user_code_DataTransformer.egg-info/SOURCES.txt'\n",
      "writing manifest file 'tfx_user_code_DataTransformer.egg-info/SOURCES.txt'\n",
      "Copying tfx_user_code_DataTransformer.egg-info to /var/tmp/tmpbk67vg9t/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3.10.egg-info\n",
      "running install_scripts\n",
      "creating /var/tmp/tmpbk67vg9t/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d.dist-info/WHEEL\n",
      "creating '/var/tmp/tmpbk39x59b/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl' and adding '/var/tmp/tmpbk67vg9t' to it\n",
      "adding 'etl.py'\n",
      "adding 'transformations.py'\n",
      "adding 'tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d.dist-info/METADATA'\n",
      "adding 'tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d.dist-info/WHEEL'\n",
      "adding 'tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d.dist-info/top_level.txt'\n",
      "adding 'tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d.dist-info/RECORD'\n",
      "removing /var/tmp/tmpbk67vg9t\n",
      "Successfully built user code wheel distribution at 'gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/_wheels/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl'; target user module is 'transformations'.\n",
      "Full user module path is 'transformations@gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/_wheels/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl'\n",
      "Generating ephemeral wheel package for '/home/jupyter/mlops-with-vertex-ai/src/model_training/runner.py' (including modules: ['exporter', 'task', 'trainer', 'runner', 'model', 'data', 'defaults']).\n",
      "User module package has hash fingerprint version 88cee01a077ea7ce1a9871764b3718ea318b1da2b217190de116232b22159367.\n",
      "Executing: ['/opt/conda/bin/python', '/var/tmp/tmpegqkp2st/_tfx_generated_setup.py', 'bdist_wheel', '--bdist-dir', '/var/tmp/tmpvgcso7sx', '--dist-dir', '/var/tmp/tmpg05grgx5']\n",
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "copying exporter.py -> build/lib\n",
      "copying task.py -> build/lib\n",
      "copying trainer.py -> build/lib\n",
      "copying runner.py -> build/lib\n",
      "copying model.py -> build/lib\n",
      "copying data.py -> build/lib\n",
      "copying defaults.py -> build/lib\n",
      "/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "!!\n",
      "\n",
      "        ********************************************************************************\n",
      "        Please avoid running ``setup.py`` directly.\n",
      "        Instead, use pypa/build, pypa/installer or other\n",
      "        standards-based tools.\n",
      "\n",
      "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "        ********************************************************************************\n",
      "\n",
      "!!\n",
      "  self.initialize_options()\n",
      "installing to /var/tmp/tmpvgcso7sx\n",
      "running install\n",
      "running install_lib\n",
      "copying build/lib/exporter.py -> /var/tmp/tmpvgcso7sx\n",
      "copying build/lib/data.py -> /var/tmp/tmpvgcso7sx\n",
      "copying build/lib/model.py -> /var/tmp/tmpvgcso7sx\n",
      "copying build/lib/runner.py -> /var/tmp/tmpvgcso7sx\n",
      "copying build/lib/trainer.py -> /var/tmp/tmpvgcso7sx\n",
      "copying build/lib/task.py -> /var/tmp/tmpvgcso7sx\n",
      "copying build/lib/defaults.py -> /var/tmp/tmpvgcso7sx\n",
      "running install_egg_info\n",
      "running egg_info\n",
      "creating tfx_user_code_ModelTrainer.egg-info\n",
      "writing tfx_user_code_ModelTrainer.egg-info/PKG-INFO\n",
      "writing dependency_links to tfx_user_code_ModelTrainer.egg-info/dependency_links.txt\n",
      "writing top-level names to tfx_user_code_ModelTrainer.egg-info/top_level.txt\n",
      "writing manifest file 'tfx_user_code_ModelTrainer.egg-info/SOURCES.txt'\n",
      "reading manifest file 'tfx_user_code_ModelTrainer.egg-info/SOURCES.txt'\n",
      "writing manifest file 'tfx_user_code_ModelTrainer.egg-info/SOURCES.txt'\n",
      "Copying tfx_user_code_ModelTrainer.egg-info to /var/tmp/tmpvgcso7sx/tfx_user_code_ModelTrainer-0.0+88cee01a077ea7ce1a9871764b3718ea318b1da2b217190de116232b22159367-py3.10.egg-info\n",
      "running install_scripts\n",
      "creating /var/tmp/tmpvgcso7sx/tfx_user_code_ModelTrainer-0.0+88cee01a077ea7ce1a9871764b3718ea318b1da2b217190de116232b22159367.dist-info/WHEEL\n",
      "creating '/var/tmp/tmpg05grgx5/tfx_user_code_ModelTrainer-0.0+88cee01a077ea7ce1a9871764b3718ea318b1da2b217190de116232b22159367-py3-none-any.whl' and adding '/var/tmp/tmpvgcso7sx' to it\n",
      "adding 'data.py'\n",
      "adding 'defaults.py'\n",
      "adding 'exporter.py'\n",
      "adding 'model.py'\n",
      "adding 'runner.py'\n",
      "adding 'task.py'\n",
      "adding 'trainer.py'\n",
      "adding 'tfx_user_code_ModelTrainer-0.0+88cee01a077ea7ce1a9871764b3718ea318b1da2b217190de116232b22159367.dist-info/METADATA'\n",
      "adding 'tfx_user_code_ModelTrainer-0.0+88cee01a077ea7ce1a9871764b3718ea318b1da2b217190de116232b22159367.dist-info/WHEEL'\n",
      "adding 'tfx_user_code_ModelTrainer-0.0+88cee01a077ea7ce1a9871764b3718ea318b1da2b217190de116232b22159367.dist-info/top_level.txt'\n",
      "adding 'tfx_user_code_ModelTrainer-0.0+88cee01a077ea7ce1a9871764b3718ea318b1da2b217190de116232b22159367.dist-info/RECORD'\n",
      "removing /var/tmp/tmpvgcso7sx\n",
      "Successfully built user code wheel distribution at 'gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/_wheels/tfx_user_code_ModelTrainer-0.0+88cee01a077ea7ce1a9871764b3718ea318b1da2b217190de116232b22159367-py3-none-any.whl'; target user module is 'runner'.\n",
      "Full user module path is 'runner@gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/_wheels/tfx_user_code_ModelTrainer-0.0+88cee01a077ea7ce1a9871764b3718ea318b1da2b217190de116232b22159367-py3-none-any.whl'\n",
      "Using deployment config:\n",
      " executor_specs {\n",
      "  key: \"DataTransformer\"\n",
      "  value {\n",
      "    beam_executable_spec {\n",
      "      python_executor_spec {\n",
      "        class_path: \"tfx.components.transform.executor.Executor\"\n",
      "      }\n",
      "      beam_pipeline_args: \"--project=supply-chain-twin-349311\"\n",
      "      beam_pipeline_args: \"--temp_location=gs://test-lora/chicago-taxi-tips/e2e_tests/temp\"\n",
      "      beam_pipeline_args_placeholders {\n",
      "        value {\n",
      "          string_value: \"--project=supply-chain-twin-349311\"\n",
      "        }\n",
      "      }\n",
      "      beam_pipeline_args_placeholders {\n",
      "        value {\n",
      "          string_value: \"--temp_location=gs://test-lora/chicago-taxi-tips/e2e_tests/temp\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"ExampleValidator\"\n",
      "  value {\n",
      "    python_class_executable_spec {\n",
      "      class_path: \"tfx.components.example_validator.executor.Executor\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"HyperparamsGen\"\n",
      "  value {\n",
      "    python_class_executable_spec {\n",
      "      class_path: \"src.tfx_pipelines.components.hyperparameters_gen_Executor\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"ModelEvaluator\"\n",
      "  value {\n",
      "    beam_executable_spec {\n",
      "      python_executor_spec {\n",
      "        class_path: \"tfx.components.evaluator.executor.Executor\"\n",
      "      }\n",
      "      beam_pipeline_args: \"--project=supply-chain-twin-349311\"\n",
      "      beam_pipeline_args: \"--temp_location=gs://test-lora/chicago-taxi-tips/e2e_tests/temp\"\n",
      "      beam_pipeline_args_placeholders {\n",
      "        value {\n",
      "          string_value: \"--project=supply-chain-twin-349311\"\n",
      "        }\n",
      "      }\n",
      "      beam_pipeline_args_placeholders {\n",
      "        value {\n",
      "          string_value: \"--temp_location=gs://test-lora/chicago-taxi-tips/e2e_tests/temp\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"ModelPusher\"\n",
      "  value {\n",
      "    python_class_executable_spec {\n",
      "      class_path: \"tfx.components.pusher.executor.Executor\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"ModelTrainer\"\n",
      "  value {\n",
      "    python_class_executable_spec {\n",
      "      class_path: \"tfx.components.trainer.executor.GenericExecutor\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"StatisticsGen\"\n",
      "  value {\n",
      "    beam_executable_spec {\n",
      "      python_executor_spec {\n",
      "        class_path: \"tfx.components.statistics_gen.executor.Executor\"\n",
      "      }\n",
      "      beam_pipeline_args: \"--project=supply-chain-twin-349311\"\n",
      "      beam_pipeline_args: \"--temp_location=gs://test-lora/chicago-taxi-tips/e2e_tests/temp\"\n",
      "      beam_pipeline_args_placeholders {\n",
      "        value {\n",
      "          string_value: \"--project=supply-chain-twin-349311\"\n",
      "        }\n",
      "      }\n",
      "      beam_pipeline_args_placeholders {\n",
      "        value {\n",
      "          string_value: \"--temp_location=gs://test-lora/chicago-taxi-tips/e2e_tests/temp\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"TestDataGen\"\n",
      "  value {\n",
      "    beam_executable_spec {\n",
      "      python_executor_spec {\n",
      "        class_path: \"tfx.extensions.google_cloud_big_query.example_gen.executor.Executor\"\n",
      "      }\n",
      "      beam_pipeline_args: \"--project=supply-chain-twin-349311\"\n",
      "      beam_pipeline_args: \"--temp_location=gs://test-lora/chicago-taxi-tips/e2e_tests/temp\"\n",
      "      beam_pipeline_args_placeholders {\n",
      "        value {\n",
      "          string_value: \"--project=supply-chain-twin-349311\"\n",
      "        }\n",
      "      }\n",
      "      beam_pipeline_args_placeholders {\n",
      "        value {\n",
      "          string_value: \"--temp_location=gs://test-lora/chicago-taxi-tips/e2e_tests/temp\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "executor_specs {\n",
      "  key: \"TrainDataGen\"\n",
      "  value {\n",
      "    beam_executable_spec {\n",
      "      python_executor_spec {\n",
      "        class_path: \"tfx.extensions.google_cloud_big_query.example_gen.executor.Executor\"\n",
      "      }\n",
      "      beam_pipeline_args: \"--project=supply-chain-twin-349311\"\n",
      "      beam_pipeline_args: \"--temp_location=gs://test-lora/chicago-taxi-tips/e2e_tests/temp\"\n",
      "      beam_pipeline_args_placeholders {\n",
      "        value {\n",
      "          string_value: \"--project=supply-chain-twin-349311\"\n",
      "        }\n",
      "      }\n",
      "      beam_pipeline_args_placeholders {\n",
      "        value {\n",
      "          string_value: \"--temp_location=gs://test-lora/chicago-taxi-tips/e2e_tests/temp\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "custom_driver_specs {\n",
      "  key: \"TestDataGen\"\n",
      "  value {\n",
      "    python_class_executable_spec {\n",
      "      class_path: \"tfx.components.example_gen.driver.QueryBasedDriver\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "custom_driver_specs {\n",
      "  key: \"TrainDataGen\"\n",
      "  value {\n",
      "    python_class_executable_spec {\n",
      "      class_path: \"tfx.components.example_gen.driver.QueryBasedDriver\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "metadata_connection_config {\n",
      "  database_connection_config {\n",
      "    sqlite {\n",
      "      filename_uri: \"mlmd.sqllite\"\n",
      "      connection_mode: READWRITE_OPENCREATE\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "Using connection config:\n",
      " sqlite {\n",
      "  filename_uri: \"mlmd.sqllite\"\n",
      "  connection_mode: READWRITE_OPENCREATE\n",
      "}\n",
      "\n",
      "Component BaselineModelResolver is running.\n",
      "Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.dsl.components.common.resolver.Resolver\"\n",
      "  }\n",
      "  id: \"BaselineModelResolver\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2024-06-27T07:18:57.100035\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline.BaselineModelResolver\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"_generated_model_3\"\n",
      "    value {\n",
      "      channels {\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      hidden: true\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"_generated_modelblessing_4\"\n",
      "    value {\n",
      "      channels {\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"ModelBlessing\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      hidden: true\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"model\"\n",
      "    value {\n",
      "      input_graph_ref {\n",
      "        graph_id: \"graph_1\"\n",
      "        key: \"model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"model_blessing\"\n",
      "    value {\n",
      "      input_graph_ref {\n",
      "        graph_id: \"graph_1\"\n",
      "        key: \"model_blessing\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  input_graphs {\n",
      "    key: \"graph_1\"\n",
      "    value {\n",
      "      nodes {\n",
      "        key: \"dict_2\"\n",
      "        value {\n",
      "          output_data_type: ARTIFACT_MULTIMAP\n",
      "          dict_node {\n",
      "            node_ids {\n",
      "              key: \"model\"\n",
      "              value: \"input_3\"\n",
      "            }\n",
      "            node_ids {\n",
      "              key: \"model_blessing\"\n",
      "              value: \"input_4\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        key: \"input_3\"\n",
      "        value {\n",
      "          output_data_type: ARTIFACT_LIST\n",
      "          input_node {\n",
      "            input_key: \"_generated_model_3\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        key: \"input_4\"\n",
      "        value {\n",
      "          output_data_type: ARTIFACT_LIST\n",
      "          input_node {\n",
      "            input_key: \"_generated_modelblessing_4\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        key: \"op_1\"\n",
      "        value {\n",
      "          output_data_type: ARTIFACT_MULTIMAP\n",
      "          op_node {\n",
      "            op_type: \"tfx.dsl.input_resolution.strategies.latest_blessed_model_strategy.LatestBlessedModelStrategy\"\n",
      "            args {\n",
      "              node_id: \"dict_2\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      result_node: \"op_1\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"ModelEvaluator\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "Running as an resolver node.\n",
      "MetadataStore with DB connection initialized\n",
      "[BaselineModelResolver] Resolved inputs: ({'model_blessing': [], 'model': []},)\n",
      "Component BaselineModelResolver is finished.\n",
      "Component HyperparamsGen is running.\n",
      "Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"src.tfx_pipelines.components.hyperparameters_gen\"\n",
      "  }\n",
      "  id: \"HyperparamsGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2024-06-27T07:18:57.100035\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline.HyperparamsGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"hyperparameters\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"HyperParameters\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"batch_size\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 512\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"hidden_units\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"128,128\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"learning_rate\"\n",
      "    value {\n",
      "      field_value {\n",
      "        double_value: 0.001\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"num_epochs\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"ModelTrainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "MetadataStore with DB connection initialized\n",
      "[HyperparamsGen] Resolved inputs: ({},)\n",
      "MetadataStore with DB connection initialized\n",
      "Going to run a new execution 2\n",
      "Going to run a new execution: ExecutionInfo(execution_id=2, input_dict={}, output_dict=defaultdict(<class 'list'>, {'hyperparameters': [Artifact(artifact: uri: \"gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/HyperparamsGen/hyperparameters/2\"\n",
      ", artifact_type: name: \"HyperParameters\"\n",
      ")]}), exec_properties={'batch_size': 512, 'learning_rate': 0.001, 'hidden_units': '128,128', 'num_epochs': 1}, execution_output_uri='gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/HyperparamsGen/.system/executor_execution/2/executor_output.pb', stateful_working_dir='gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/HyperparamsGen/.system/stateful_working_dir/bf7d2dd8-74ad-4e3f-a2a0-e180e6326206', tmp_dir='gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/HyperparamsGen/.system/executor_execution/2/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"src.tfx_pipelines.components.hyperparameters_gen\"\n",
      "  }\n",
      "  id: \"HyperparamsGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2024-06-27T07:18:57.100035\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline.HyperparamsGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"hyperparameters\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"HyperParameters\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"batch_size\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 512\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"hidden_units\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"128,128\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"learning_rate\"\n",
      "    value {\n",
      "      field_value {\n",
      "        double_value: 0.001\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"num_epochs\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"ModelTrainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"chicago-taxi-tips-classifier-v09-train-pipeline\"\n",
      ", pipeline_run_id='2024-06-27T07:18:57.100035', top_level_pipeline_run_id=None, frontend_url=None)\n",
      "Hyperparameters: {'num_epochs': 1, 'batch_size': 512, 'learning_rate': 0.001, 'hidden_units': [128, 128]}\n",
      "Hyperparameters are written to: gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/HyperparamsGen/hyperparameters/2/hyperparameters.json\n",
      "Cleaning up stateless execution info.\n",
      "Execution 2 succeeded.\n",
      "Cleaning up stateful execution info.\n",
      "Deleted stateful_working_dir gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/HyperparamsGen/.system/stateful_working_dir/bf7d2dd8-74ad-4e3f-a2a0-e180e6326206\n",
      "Publishing output artifacts defaultdict(<class 'list'>, {'hyperparameters': [Artifact(artifact: uri: \"gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/HyperparamsGen/hyperparameters/2\"\n",
      ", artifact_type: name: \"HyperParameters\"\n",
      ")]}) for execution 2\n",
      "MetadataStore with DB connection initialized\n",
      "Component HyperparamsGen is finished.\n",
      "Component SchemaImporter is running.\n",
      "Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.dsl.components.common.importer.Importer\"\n",
      "  }\n",
      "  id: \"SchemaImporter\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2024-06-27T07:18:57.100035\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline.SchemaImporter\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"result\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Schema\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"artifact_uri\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"src/raw_schema\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_key\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"result\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"reimport\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"DataTransformer\"\n",
      "downstream_nodes: \"ExampleValidator\"\n",
      "downstream_nodes: \"ModelEvaluator\"\n",
      "downstream_nodes: \"ModelTrainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "Running as an importer node.\n",
      "MetadataStore with DB connection initialized\n",
      "Processing source uri: src/raw_schema, properties: {}, custom_properties: {}\n",
      "Component SchemaImporter is finished.\n",
      "Component TestDataGen is running.\n",
      "Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.extensions.google_cloud_big_query.example_gen.component.BigQueryExampleGen\"\n",
      "    base_type: PROCESS\n",
      "  }\n",
      "  id: \"TestDataGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2024-06-27T07:18:57.100035\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline.TestDataGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Examples\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          properties {\n",
      "            key: \"version\"\n",
      "            value: INT\n",
      "          }\n",
      "          base_type: DATASET\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"input_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"\\\\n    SELECT \\\\n        IF(trip_month IS NULL, -1, trip_month) trip_month,\\\\n        IF(trip_day IS NULL, -1, trip_day) trip_day,\\\\n        IF(trip_day_of_week IS NULL, -1, trip_day_of_week) trip_day_of_week,\\\\n        IF(trip_hour IS NULL, -1, trip_hour) trip_hour,\\\\n        IF(trip_seconds IS NULL, -1, trip_seconds) trip_seconds,\\\\n        IF(trip_miles IS NULL, -1, trip_miles) trip_miles,\\\\n        IF(payment_type IS NULL, \\'NA\\', payment_type) payment_type,\\\\n        IF(pickup_grid IS NULL, \\'NA\\', pickup_grid) pickup_grid,\\\\n        IF(dropoff_grid IS NULL, \\'NA\\', dropoff_grid) dropoff_grid,\\\\n        IF(euclidean IS NULL, -1, euclidean) euclidean,\\\\n        IF(loc_cross IS NULL, \\'NA\\', loc_cross) loc_cross,\\\\n        tip_bin\\\\n    FROM chi_e2e.chicago_taxitrips_prep \\\\n    WHERE ML_use = \\'TEST\\'\\\\n    LIMIT 100\\\"\\n    }\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 1,\\n        \\\"name\\\": \\\"test\\\"\\n      }\\n    ]\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_data_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 6\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_file_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 5\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"ModelEvaluator\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "MetadataStore with DB connection initialized\n",
      "[TestDataGen] Resolved inputs: ({},)\n",
      "MetadataStore with DB connection initialized\n",
      "Going to run a new execution 4\n",
      "Going to run a new execution: ExecutionInfo(execution_id=4, input_dict={}, output_dict=defaultdict(<class 'list'>, {'examples': [Artifact(artifact: uri: \"gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/TestDataGen/examples/4\"\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]}), exec_properties={'output_config': '{\\n  \"split_config\": {\\n    \"splits\": [\\n      {\\n        \"hash_buckets\": 1,\\n        \"name\": \"test\"\\n      }\\n    ]\\n  }\\n}', 'output_data_format': 6, 'input_config': '{\\n  \"splits\": [\\n    {\\n      \"name\": \"single_split\",\\n      \"pattern\": \"\\\\n    SELECT \\\\n        IF(trip_month IS NULL, -1, trip_month) trip_month,\\\\n        IF(trip_day IS NULL, -1, trip_day) trip_day,\\\\n        IF(trip_day_of_week IS NULL, -1, trip_day_of_week) trip_day_of_week,\\\\n        IF(trip_hour IS NULL, -1, trip_hour) trip_hour,\\\\n        IF(trip_seconds IS NULL, -1, trip_seconds) trip_seconds,\\\\n        IF(trip_miles IS NULL, -1, trip_miles) trip_miles,\\\\n        IF(payment_type IS NULL, \\'NA\\', payment_type) payment_type,\\\\n        IF(pickup_grid IS NULL, \\'NA\\', pickup_grid) pickup_grid,\\\\n        IF(dropoff_grid IS NULL, \\'NA\\', dropoff_grid) dropoff_grid,\\\\n        IF(euclidean IS NULL, -1, euclidean) euclidean,\\\\n        IF(loc_cross IS NULL, \\'NA\\', loc_cross) loc_cross,\\\\n        tip_bin\\\\n    FROM chi_e2e.chicago_taxitrips_prep \\\\n    WHERE ML_use = \\'TEST\\'\\\\n    LIMIT 100\"\\n    }\\n  ]\\n}', 'output_file_format': 5, 'span': 0, 'version': None, 'input_fingerprint': None}, execution_output_uri='gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/TestDataGen/.system/executor_execution/4/executor_output.pb', stateful_working_dir='gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/TestDataGen/.system/stateful_working_dir/498cc02c-5abc-4d57-8b33-ae758a4fa3e2', tmp_dir='gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/TestDataGen/.system/executor_execution/4/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.extensions.google_cloud_big_query.example_gen.component.BigQueryExampleGen\"\n",
      "    base_type: PROCESS\n",
      "  }\n",
      "  id: \"TestDataGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2024-06-27T07:18:57.100035\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline.TestDataGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Examples\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          properties {\n",
      "            key: \"version\"\n",
      "            value: INT\n",
      "          }\n",
      "          base_type: DATASET\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"input_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"\\\\n    SELECT \\\\n        IF(trip_month IS NULL, -1, trip_month) trip_month,\\\\n        IF(trip_day IS NULL, -1, trip_day) trip_day,\\\\n        IF(trip_day_of_week IS NULL, -1, trip_day_of_week) trip_day_of_week,\\\\n        IF(trip_hour IS NULL, -1, trip_hour) trip_hour,\\\\n        IF(trip_seconds IS NULL, -1, trip_seconds) trip_seconds,\\\\n        IF(trip_miles IS NULL, -1, trip_miles) trip_miles,\\\\n        IF(payment_type IS NULL, \\'NA\\', payment_type) payment_type,\\\\n        IF(pickup_grid IS NULL, \\'NA\\', pickup_grid) pickup_grid,\\\\n        IF(dropoff_grid IS NULL, \\'NA\\', dropoff_grid) dropoff_grid,\\\\n        IF(euclidean IS NULL, -1, euclidean) euclidean,\\\\n        IF(loc_cross IS NULL, \\'NA\\', loc_cross) loc_cross,\\\\n        tip_bin\\\\n    FROM chi_e2e.chicago_taxitrips_prep \\\\n    WHERE ML_use = \\'TEST\\'\\\\n    LIMIT 100\\\"\\n    }\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 1,\\n        \\\"name\\\": \\\"test\\\"\\n      }\\n    ]\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_data_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 6\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_file_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 5\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"ModelEvaluator\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"chicago-taxi-tips-classifier-v09-train-pipeline\"\n",
      ", pipeline_run_id='2024-06-27T07:18:57.100035', top_level_pipeline_run_id=None, frontend_url=None)\n",
      "Attempting to infer TFX Python dependency for beam\n",
      "Copying all content from install dir /opt/conda/lib/python3.10/site-packages/tfx to temp dir /var/tmp/tmpp28njctm/build/tfx\n",
      "Generating a temp setup file at /var/tmp/tmpp28njctm/build/tfx/setup.py\n",
      "Creating temporary sdist package, logs available at /var/tmp/tmpp28njctm/build/tfx/setup.log\n",
      "Added --extra_package=/var/tmp/tmpp28njctm/build/tfx/dist/tfx_ephemeral-1.15.1.tar.gz to beam args\n",
      "Length of label `tfx-extensions-google_cloud_big_query-example_gen-executor-executor` exceeds maximum length(63), trimmed.\n",
      "Generating examples.\n",
      "Missing pipeline option (runner). Executing pipeline using the default runner: DirectRunner.\n",
      "Creating state cache with size 104857600\n",
      "Started BigQuery job: <JobReference\n",
      " location: 'US'\n",
      " projectId: 'supply-chain-twin-349311'>\n",
      " bq show -j --format=prettyjson --project_id=supply-chain-twin-349311 None\n",
      "Using location 'US' from table <TableReference\n",
      " datasetId: 'chi_e2e'\n",
      " projectId: 'supply-chain-twin-349311'\n",
      " tableId: 'chicago_taxitrips_prep'> referenced by query \n",
      "    SELECT \n",
      "        IF(trip_month IS NULL, -1, trip_month) trip_month,\n",
      "        IF(trip_day IS NULL, -1, trip_day) trip_day,\n",
      "        IF(trip_day_of_week IS NULL, -1, trip_day_of_week) trip_day_of_week,\n",
      "        IF(trip_hour IS NULL, -1, trip_hour) trip_hour,\n",
      "        IF(trip_seconds IS NULL, -1, trip_seconds) trip_seconds,\n",
      "        IF(trip_miles IS NULL, -1, trip_miles) trip_miles,\n",
      "        IF(payment_type IS NULL, 'NA', payment_type) payment_type,\n",
      "        IF(pickup_grid IS NULL, 'NA', pickup_grid) pickup_grid,\n",
      "        IF(dropoff_grid IS NULL, 'NA', dropoff_grid) dropoff_grid,\n",
      "        IF(euclidean IS NULL, -1, euclidean) euclidean,\n",
      "        IF(loc_cross IS NULL, 'NA', loc_cross) loc_cross,\n",
      "        tip_bin\n",
      "    FROM chi_e2e.chicago_taxitrips_prep \n",
      "    WHERE ML_use = 'TEST'\n",
      "    LIMIT 100\n",
      "Dataset supply-chain-twin-349311:beam_temp_dataset_c234e6e5e13548d1a771e2449e857d76 does not exist so we will create it as temporary with location=US\n",
      "Started BigQuery job: <JobReference\n",
      " jobId: 'beam_bq_job_QUERY_BQ_EXPORT_JOB_f49bc31a-8_1719472749_603'\n",
      " location: 'US'\n",
      " projectId: 'supply-chain-twin-349311'>\n",
      " bq show -j --format=prettyjson --project_id=supply-chain-twin-349311 beam_bq_job_QUERY_BQ_EXPORT_JOB_f49bc31a-8_1719472749_603\n",
      "Job supply-chain-twin-349311:US.beam_bq_job_QUERY_BQ_EXPORT_JOB_f49bc31a-8_1719472749_603 status: RUNNING\n",
      "Job supply-chain-twin-349311:US.beam_bq_job_QUERY_BQ_EXPORT_JOB_f49bc31a-8_1719472749_603 status: DONE\n",
      "Started BigQuery job: <JobReference\n",
      " jobId: 'beam_bq_job_EXPORT_BQ_EXPORT_JOB_f49bc31a-8_1719472755_930'\n",
      " location: 'US'\n",
      " projectId: 'supply-chain-twin-349311'>\n",
      " bq show -j --format=prettyjson --project_id=supply-chain-twin-349311 beam_bq_job_EXPORT_BQ_EXPORT_JOB_f49bc31a-8_1719472755_930\n",
      "Job supply-chain-twin-349311:US.beam_bq_job_EXPORT_BQ_EXPORT_JOB_f49bc31a-8_1719472755_930 status: RUNNING\n",
      "Job supply-chain-twin-349311:US.beam_bq_job_EXPORT_BQ_EXPORT_JOB_f49bc31a-8_1719472755_930 status: DONE\n",
      "Finished listing 1 files in 0.037276268005371094 seconds.\n",
      "Finished listing 1 files in 0.03641057014465332 seconds.\n",
      "Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\n",
      "Finished listing 1 files in 0.0284879207611084 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.35 seconds.\n",
      "Examples generated.\n",
      "Value type <class 'NoneType'> of key version in exec_properties is not supported, going to drop it\n",
      "Value type <class 'NoneType'> of key input_fingerprint in exec_properties is not supported, going to drop it\n",
      "Value type <class 'list'> of key _beam_pipeline_args in exec_properties is not supported, going to drop it\n",
      "Cleaning up stateless execution info.\n",
      "Execution 4 succeeded.\n",
      "Cleaning up stateful execution info.\n",
      "Deleted stateful_working_dir gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/TestDataGen/.system/stateful_working_dir/498cc02c-5abc-4d57-8b33-ae758a4fa3e2\n",
      "Publishing output artifacts defaultdict(<class 'list'>, {'examples': [Artifact(artifact: uri: \"gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/TestDataGen/examples/4\"\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]}) for execution 4\n",
      "MetadataStore with DB connection initialized\n",
      "Component TestDataGen is finished.\n",
      "Component TrainDataGen is running.\n",
      "Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.extensions.google_cloud_big_query.example_gen.component.BigQueryExampleGen\"\n",
      "    base_type: PROCESS\n",
      "  }\n",
      "  id: \"TrainDataGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2024-06-27T07:18:57.100035\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline.TrainDataGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Examples\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          properties {\n",
      "            key: \"version\"\n",
      "            value: INT\n",
      "          }\n",
      "          base_type: DATASET\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"input_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"\\\\n    SELECT \\\\n        IF(trip_month IS NULL, -1, trip_month) trip_month,\\\\n        IF(trip_day IS NULL, -1, trip_day) trip_day,\\\\n        IF(trip_day_of_week IS NULL, -1, trip_day_of_week) trip_day_of_week,\\\\n        IF(trip_hour IS NULL, -1, trip_hour) trip_hour,\\\\n        IF(trip_seconds IS NULL, -1, trip_seconds) trip_seconds,\\\\n        IF(trip_miles IS NULL, -1, trip_miles) trip_miles,\\\\n        IF(payment_type IS NULL, \\'NA\\', payment_type) payment_type,\\\\n        IF(pickup_grid IS NULL, \\'NA\\', pickup_grid) pickup_grid,\\\\n        IF(dropoff_grid IS NULL, \\'NA\\', dropoff_grid) dropoff_grid,\\\\n        IF(euclidean IS NULL, -1, euclidean) euclidean,\\\\n        IF(loc_cross IS NULL, \\'NA\\', loc_cross) loc_cross,\\\\n        tip_bin\\\\n    FROM chi_e2e.chicago_taxitrips_prep \\\\n    WHERE ML_use = \\'UNASSIGNED\\'\\\\n    LIMIT 1000\\\"\\n    }\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 4,\\n        \\\"name\\\": \\\"train\\\"\\n      },\\n      {\\n        \\\"hash_buckets\\\": 1,\\n        \\\"name\\\": \\\"eval\\\"\\n      }\\n    ]\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_data_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 6\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_file_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 5\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"DataTransformer\"\n",
      "downstream_nodes: \"StatisticsGen\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "MetadataStore with DB connection initialized\n",
      "[TrainDataGen] Resolved inputs: ({},)\n",
      "MetadataStore with DB connection initialized\n",
      "Going to run a new execution 5\n",
      "Going to run a new execution: ExecutionInfo(execution_id=5, input_dict={}, output_dict=defaultdict(<class 'list'>, {'examples': [Artifact(artifact: uri: \"gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/TrainDataGen/examples/5\"\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]}), exec_properties={'input_config': '{\\n  \"splits\": [\\n    {\\n      \"name\": \"single_split\",\\n      \"pattern\": \"\\\\n    SELECT \\\\n        IF(trip_month IS NULL, -1, trip_month) trip_month,\\\\n        IF(trip_day IS NULL, -1, trip_day) trip_day,\\\\n        IF(trip_day_of_week IS NULL, -1, trip_day_of_week) trip_day_of_week,\\\\n        IF(trip_hour IS NULL, -1, trip_hour) trip_hour,\\\\n        IF(trip_seconds IS NULL, -1, trip_seconds) trip_seconds,\\\\n        IF(trip_miles IS NULL, -1, trip_miles) trip_miles,\\\\n        IF(payment_type IS NULL, \\'NA\\', payment_type) payment_type,\\\\n        IF(pickup_grid IS NULL, \\'NA\\', pickup_grid) pickup_grid,\\\\n        IF(dropoff_grid IS NULL, \\'NA\\', dropoff_grid) dropoff_grid,\\\\n        IF(euclidean IS NULL, -1, euclidean) euclidean,\\\\n        IF(loc_cross IS NULL, \\'NA\\', loc_cross) loc_cross,\\\\n        tip_bin\\\\n    FROM chi_e2e.chicago_taxitrips_prep \\\\n    WHERE ML_use = \\'UNASSIGNED\\'\\\\n    LIMIT 1000\"\\n    }\\n  ]\\n}', 'output_data_format': 6, 'output_file_format': 5, 'output_config': '{\\n  \"split_config\": {\\n    \"splits\": [\\n      {\\n        \"hash_buckets\": 4,\\n        \"name\": \"train\"\\n      },\\n      {\\n        \"hash_buckets\": 1,\\n        \"name\": \"eval\"\\n      }\\n    ]\\n  }\\n}', 'span': 0, 'version': None, 'input_fingerprint': None}, execution_output_uri='gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/TrainDataGen/.system/executor_execution/5/executor_output.pb', stateful_working_dir='gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/TrainDataGen/.system/stateful_working_dir/f9e4374b-b5d6-44cc-a946-7c5d0b83d988', tmp_dir='gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/TrainDataGen/.system/executor_execution/5/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.extensions.google_cloud_big_query.example_gen.component.BigQueryExampleGen\"\n",
      "    base_type: PROCESS\n",
      "  }\n",
      "  id: \"TrainDataGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2024-06-27T07:18:57.100035\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline.TrainDataGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Examples\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          properties {\n",
      "            key: \"version\"\n",
      "            value: INT\n",
      "          }\n",
      "          base_type: DATASET\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"input_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"splits\\\": [\\n    {\\n      \\\"name\\\": \\\"single_split\\\",\\n      \\\"pattern\\\": \\\"\\\\n    SELECT \\\\n        IF(trip_month IS NULL, -1, trip_month) trip_month,\\\\n        IF(trip_day IS NULL, -1, trip_day) trip_day,\\\\n        IF(trip_day_of_week IS NULL, -1, trip_day_of_week) trip_day_of_week,\\\\n        IF(trip_hour IS NULL, -1, trip_hour) trip_hour,\\\\n        IF(trip_seconds IS NULL, -1, trip_seconds) trip_seconds,\\\\n        IF(trip_miles IS NULL, -1, trip_miles) trip_miles,\\\\n        IF(payment_type IS NULL, \\'NA\\', payment_type) payment_type,\\\\n        IF(pickup_grid IS NULL, \\'NA\\', pickup_grid) pickup_grid,\\\\n        IF(dropoff_grid IS NULL, \\'NA\\', dropoff_grid) dropoff_grid,\\\\n        IF(euclidean IS NULL, -1, euclidean) euclidean,\\\\n        IF(loc_cross IS NULL, \\'NA\\', loc_cross) loc_cross,\\\\n        tip_bin\\\\n    FROM chi_e2e.chicago_taxitrips_prep \\\\n    WHERE ML_use = \\'UNASSIGNED\\'\\\\n    LIMIT 1000\\\"\\n    }\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"split_config\\\": {\\n    \\\"splits\\\": [\\n      {\\n        \\\"hash_buckets\\\": 4,\\n        \\\"name\\\": \\\"train\\\"\\n      },\\n      {\\n        \\\"hash_buckets\\\": 1,\\n        \\\"name\\\": \\\"eval\\\"\\n      }\\n    ]\\n  }\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_data_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 6\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"output_file_format\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 5\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"DataTransformer\"\n",
      "downstream_nodes: \"StatisticsGen\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"chicago-taxi-tips-classifier-v09-train-pipeline\"\n",
      ", pipeline_run_id='2024-06-27T07:18:57.100035', top_level_pipeline_run_id=None, frontend_url=None)\n",
      "Attempting to infer TFX Python dependency for beam\n",
      "Copying all content from install dir /opt/conda/lib/python3.10/site-packages/tfx to temp dir /var/tmp/tmp4bfo8n59/build/tfx\n",
      "Generating a temp setup file at /var/tmp/tmp4bfo8n59/build/tfx/setup.py\n",
      "Creating temporary sdist package, logs available at /var/tmp/tmp4bfo8n59/build/tfx/setup.log\n",
      "Added --extra_package=/var/tmp/tmp4bfo8n59/build/tfx/dist/tfx_ephemeral-1.15.1.tar.gz to beam args\n",
      "Length of label `tfx-extensions-google_cloud_big_query-example_gen-executor-executor` exceeds maximum length(63), trimmed.\n",
      "Generating examples.\n",
      "Missing pipeline option (runner). Executing pipeline using the default runner: DirectRunner.\n",
      "Creating state cache with size 104857600\n",
      "Started BigQuery job: <JobReference\n",
      " location: 'US'\n",
      " projectId: 'supply-chain-twin-349311'>\n",
      " bq show -j --format=prettyjson --project_id=supply-chain-twin-349311 None\n",
      "Using location 'US' from table <TableReference\n",
      " datasetId: 'chi_e2e'\n",
      " projectId: 'supply-chain-twin-349311'\n",
      " tableId: 'chicago_taxitrips_prep'> referenced by query \n",
      "    SELECT \n",
      "        IF(trip_month IS NULL, -1, trip_month) trip_month,\n",
      "        IF(trip_day IS NULL, -1, trip_day) trip_day,\n",
      "        IF(trip_day_of_week IS NULL, -1, trip_day_of_week) trip_day_of_week,\n",
      "        IF(trip_hour IS NULL, -1, trip_hour) trip_hour,\n",
      "        IF(trip_seconds IS NULL, -1, trip_seconds) trip_seconds,\n",
      "        IF(trip_miles IS NULL, -1, trip_miles) trip_miles,\n",
      "        IF(payment_type IS NULL, 'NA', payment_type) payment_type,\n",
      "        IF(pickup_grid IS NULL, 'NA', pickup_grid) pickup_grid,\n",
      "        IF(dropoff_grid IS NULL, 'NA', dropoff_grid) dropoff_grid,\n",
      "        IF(euclidean IS NULL, -1, euclidean) euclidean,\n",
      "        IF(loc_cross IS NULL, 'NA', loc_cross) loc_cross,\n",
      "        tip_bin\n",
      "    FROM chi_e2e.chicago_taxitrips_prep \n",
      "    WHERE ML_use = 'UNASSIGNED'\n",
      "    LIMIT 1000\n",
      "Dataset supply-chain-twin-349311:beam_temp_dataset_07278da6f0f44d259c932b3907bcfcf8 does not exist so we will create it as temporary with location=US\n",
      "Started BigQuery job: <JobReference\n",
      " jobId: 'beam_bq_job_QUERY_BQ_EXPORT_JOB_f376007b-5_1719472773_715'\n",
      " location: 'US'\n",
      " projectId: 'supply-chain-twin-349311'>\n",
      " bq show -j --format=prettyjson --project_id=supply-chain-twin-349311 beam_bq_job_QUERY_BQ_EXPORT_JOB_f376007b-5_1719472773_715\n",
      "Job supply-chain-twin-349311:US.beam_bq_job_QUERY_BQ_EXPORT_JOB_f376007b-5_1719472773_715 status: RUNNING\n",
      "Job supply-chain-twin-349311:US.beam_bq_job_QUERY_BQ_EXPORT_JOB_f376007b-5_1719472773_715 status: DONE\n",
      "Started BigQuery job: <JobReference\n",
      " jobId: 'beam_bq_job_EXPORT_BQ_EXPORT_JOB_f376007b-5_1719472779_442'\n",
      " location: 'US'\n",
      " projectId: 'supply-chain-twin-349311'>\n",
      " bq show -j --format=prettyjson --project_id=supply-chain-twin-349311 beam_bq_job_EXPORT_BQ_EXPORT_JOB_f376007b-5_1719472779_442\n",
      "Job supply-chain-twin-349311:US.beam_bq_job_EXPORT_BQ_EXPORT_JOB_f376007b-5_1719472779_442 status: RUNNING\n",
      "Job supply-chain-twin-349311:US.beam_bq_job_EXPORT_BQ_EXPORT_JOB_f376007b-5_1719472779_442 status: DONE\n",
      "Finished listing 1 files in 0.040812015533447266 seconds.\n",
      "Finished listing 1 files in 0.02936244010925293 seconds.\n",
      "Finished listing 1 files in 0.0341951847076416 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.37 seconds.\n",
      "Finished listing 1 files in 0.027953386306762695 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.33 seconds.\n",
      "Examples generated.\n",
      "Value type <class 'NoneType'> of key version in exec_properties is not supported, going to drop it\n",
      "Value type <class 'NoneType'> of key input_fingerprint in exec_properties is not supported, going to drop it\n",
      "Value type <class 'list'> of key _beam_pipeline_args in exec_properties is not supported, going to drop it\n",
      "Cleaning up stateless execution info.\n",
      "Execution 5 succeeded.\n",
      "Cleaning up stateful execution info.\n",
      "Deleted stateful_working_dir gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/TrainDataGen/.system/stateful_working_dir/f9e4374b-b5d6-44cc-a946-7c5d0b83d988\n",
      "Publishing output artifacts defaultdict(<class 'list'>, {'examples': [Artifact(artifact: uri: \"gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/TrainDataGen/examples/5\"\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      ", artifact_type: name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]}) for execution 5\n",
      "MetadataStore with DB connection initialized\n",
      "Component TrainDataGen is finished.\n",
      "Component WarmstartModelResolver is running.\n",
      "Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.dsl.components.common.resolver.Resolver\"\n",
      "  }\n",
      "  id: \"WarmstartModelResolver\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2024-06-27T07:18:57.100035\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline.WarmstartModelResolver\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"_generated_model_2\"\n",
      "    value {\n",
      "      channels {\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Model\"\n",
      "            base_type: MODEL\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      hidden: true\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"latest_model\"\n",
      "    value {\n",
      "      input_graph_ref {\n",
      "        graph_id: \"graph_1\"\n",
      "        key: \"latest_model\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  input_graphs {\n",
      "    key: \"graph_1\"\n",
      "    value {\n",
      "      nodes {\n",
      "        key: \"dict_2\"\n",
      "        value {\n",
      "          output_data_type: ARTIFACT_MULTIMAP\n",
      "          dict_node {\n",
      "            node_ids {\n",
      "              key: \"latest_model\"\n",
      "              value: \"input_3\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        key: \"input_3\"\n",
      "        value {\n",
      "          output_data_type: ARTIFACT_LIST\n",
      "          input_node {\n",
      "            input_key: \"_generated_model_2\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      nodes {\n",
      "        key: \"op_1\"\n",
      "        value {\n",
      "          output_data_type: ARTIFACT_MULTIMAP\n",
      "          op_node {\n",
      "            op_type: \"tfx.dsl.input_resolution.strategies.latest_artifact_strategy.LatestArtifactStrategy\"\n",
      "            args {\n",
      "              node_id: \"dict_2\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      result_node: \"op_1\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "downstream_nodes: \"ModelTrainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "Running as an resolver node.\n",
      "MetadataStore with DB connection initialized\n",
      "[WarmstartModelResolver] Input resolution error: Error while resolving inputs for WarmstartModelResolver: <tfx.dsl.input_resolution.strategies.latest_artifact_strategy.LatestArtifactStrategy object at 0x7f0f3c777c70> returned None.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tfx/orchestration/portable/resolver_node_handler.py\", line 75, in run\n",
      "    resolved_inputs = inputs_utils.resolve_input_artifacts(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tfx/orchestration/portable/inputs_utils.py\", line 65, in resolve_input_artifacts\n",
      "    resolved = node_inputs_resolver.resolve(metadata_handle, node_inputs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tfx/orchestration/portable/input_resolution/node_inputs_resolver.py\", line 517, in resolve\n",
      "    _resolve_input_graph_ref(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tfx/orchestration/portable/input_resolution/node_inputs_resolver.py\", line 377, in _resolve_input_graph_ref\n",
      "    result = graph_fn(input_dict)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tfx/orchestration/portable/input_resolution/input_graph_resolver.py\", line 254, in facade_fn\n",
      "    return graph_fn({\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tfx/orchestration/portable/input_resolution/input_graph_resolver.py\", line 204, in new_graph_fn\n",
      "    return graph_fn({**data, node_id: output})\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tfx/orchestration/portable/input_resolution/input_graph_resolver.py\", line 197, in new_graph_fn\n",
      "    output = node_fn(data)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/tfx/orchestration/portable/input_resolution/input_graph_resolver.py\", line 149, in _evaluate_op_node\n",
      "    raise exceptions.InputResolutionError(f'{strategy} returned None.')\n",
      "tfx.orchestration.portable.input_resolution.exceptions.InputResolutionError: Error while resolving inputs for WarmstartModelResolver: <tfx.dsl.input_resolution.strategies.latest_artifact_strategy.LatestArtifactStrategy object at 0x7f0f3c777c70> returned None.\n",
      "Component WarmstartModelResolver is finished.\n",
      "Component StatisticsGen is running.\n",
      "Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.statistics_gen.component.StatisticsGen\"\n",
      "    base_type: PROCESS\n",
      "  }\n",
      "  id: \"StatisticsGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2024-06-27T07:18:57.100035\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline.StatisticsGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"TrainDataGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2024-06-27T07:18:57.100035\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline.TrainDataGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"statistics\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleStatistics\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          base_type: STATISTICS\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"exclude_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"[]\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"TrainDataGen\"\n",
      "downstream_nodes: \"ExampleValidator\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "MetadataStore with DB connection initialized\n",
      "ArtifactQuery.property_predicate is not supported.\n",
      "[StatisticsGen] Resolved inputs: ({'examples': [Artifact(artifact: id: 4\n",
      "type_id: 20\n",
      "uri: \"gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/TrainDataGen/examples/5\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"file_format\"\n",
      "  value {\n",
      "    string_value: \"tfrecords_gzip\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"payload_format\"\n",
      "  value {\n",
      "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.15.1\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Examples\"\n",
      "create_time_since_epoch: 1719472789648\n",
      "last_update_time_since_epoch: 1719472789648\n",
      ", artifact_type: id: 20\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]},)\n",
      "MetadataStore with DB connection initialized\n",
      "Going to run a new execution 7\n",
      "Going to run a new execution: ExecutionInfo(execution_id=7, input_dict={'examples': [Artifact(artifact: id: 4\n",
      "type_id: 20\n",
      "uri: \"gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/TrainDataGen/examples/5\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"file_format\"\n",
      "  value {\n",
      "    string_value: \"tfrecords_gzip\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"payload_format\"\n",
      "  value {\n",
      "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.15.1\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Examples\"\n",
      "create_time_since_epoch: 1719472789648\n",
      "last_update_time_since_epoch: 1719472789648\n",
      ", artifact_type: id: 20\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'statistics': [Artifact(artifact: uri: \"gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/StatisticsGen/statistics/7\"\n",
      ", artifact_type: name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "base_type: STATISTICS\n",
      ")]}), exec_properties={'exclude_splits': '[]'}, execution_output_uri='gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/StatisticsGen/.system/executor_execution/7/executor_output.pb', stateful_working_dir='gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/StatisticsGen/.system/stateful_working_dir/81ccb225-abdb-4d99-8da1-d8c2b7083df8', tmp_dir='gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/StatisticsGen/.system/executor_execution/7/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.statistics_gen.component.StatisticsGen\"\n",
      "    base_type: PROCESS\n",
      "  }\n",
      "  id: \"StatisticsGen\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2024-06-27T07:18:57.100035\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline.StatisticsGen\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"TrainDataGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2024-06-27T07:18:57.100035\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline.TrainDataGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"statistics\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleStatistics\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          base_type: STATISTICS\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"exclude_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"[]\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"TrainDataGen\"\n",
      "downstream_nodes: \"ExampleValidator\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"chicago-taxi-tips-classifier-v09-train-pipeline\"\n",
      ", pipeline_run_id='2024-06-27T07:18:57.100035', top_level_pipeline_run_id=None, frontend_url=None)\n",
      "Attempting to infer TFX Python dependency for beam\n",
      "Copying all content from install dir /opt/conda/lib/python3.10/site-packages/tfx to temp dir /var/tmp/tmppibc94e0/build/tfx\n",
      "Generating a temp setup file at /var/tmp/tmppibc94e0/build/tfx/setup.py\n",
      "Creating temporary sdist package, logs available at /var/tmp/tmppibc94e0/build/tfx/setup.log\n",
      "Added --extra_package=/var/tmp/tmppibc94e0/build/tfx/dist/tfx_ephemeral-1.15.1.tar.gz to beam args\n",
      "Reading from pattern ['gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/TrainDataGen/examples/5/Split-train/*'] for split train\n",
      "Reading from pattern ['gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/TrainDataGen/examples/5/Split-eval/*'] for split eval\n",
      "Missing pipeline option (runner). Executing pipeline using the default runner: DirectRunner.\n",
      "Generating statistics for split train.\n",
      "Finished listing 1 files in 0.026178836822509766 seconds.\n",
      "Using Any for unsupported type: typing.Sequence[str]\n",
      "Using Any for unsupported type: typing.Mapping[tensorflow_data_validation.utils.path.FeaturePath, ForwardRef('schema_pb2.FeatureType')]\n",
      "Using Any for unsupported type: typing.Mapping[tensorflow_data_validation.utils.path.FeaturePath, ForwardRef('schema_pb2.FeatureType')]\n",
      "Using Any for unsupported type: typing.Mapping[tensorflow_data_validation.utils.path.FeaturePath, ForwardRef('schema_pb2.FeatureType')]\n",
      "Statistics for split train written to gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/StatisticsGen/statistics/7/Split-train.\n",
      "Generating statistics for split eval.\n",
      "Finished listing 1 files in 0.03677725791931152 seconds.\n",
      "Using Any for unsupported type: typing.Sequence[str]\n",
      "Using Any for unsupported type: typing.Mapping[tensorflow_data_validation.utils.path.FeaturePath, ForwardRef('schema_pb2.FeatureType')]\n",
      "Using Any for unsupported type: typing.Mapping[tensorflow_data_validation.utils.path.FeaturePath, ForwardRef('schema_pb2.FeatureType')]\n",
      "Using Any for unsupported type: typing.Mapping[tensorflow_data_validation.utils.path.FeaturePath, ForwardRef('schema_pb2.FeatureType')]\n",
      "Statistics for split eval written to gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/StatisticsGen/statistics/7/Split-eval.\n",
      "Creating state cache with size 104857600\n",
      "Finished listing 1 files in 0.02748250961303711 seconds.\n",
      "Finished listing 1 files in 0.03421735763549805 seconds.\n",
      "BatchElements statistics: element_count=217 batch_count=9 next_batch_size=178 timings=[(1, 0.002516031265258789), (2, 0.0024247169494628906), (4, 0.002449512481689453), (8, 0.002539396286010742), (16, 0.0025131702423095703), (32, 0.0029420852661132812), (64, 0.0034303665161132812), (89, 0.003959178924560547)]\n",
      "BatchElements statistics: element_count=783 batch_count=11 next_batch_size=542 timings=[(1, 0.002144336700439453), (2, 0.0021238327026367188), (4, 0.0021941661834716797), (8, 0.0022499561309814453), (16, 0.0024580955505371094), (32, 0.002641916275024414), (64, 0.0031409263610839844), (128, 0.00678706169128418), (256, 0.005968570709228516), (271, 0.006032466888427734)]\n",
      "Finished listing 1 files in 0.03147387504577637 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.33 seconds.\n",
      "Finished listing 1 files in 0.03355836868286133 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.37 seconds.\n",
      "Cleaning up stateless execution info.\n",
      "Execution 7 succeeded.\n",
      "Cleaning up stateful execution info.\n",
      "Deleted stateful_working_dir gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/StatisticsGen/.system/stateful_working_dir/81ccb225-abdb-4d99-8da1-d8c2b7083df8\n",
      "Publishing output artifacts defaultdict(<class 'list'>, {'statistics': [Artifact(artifact: uri: \"gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/StatisticsGen/statistics/7\"\n",
      ", artifact_type: name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "base_type: STATISTICS\n",
      ")]}) for execution 7\n",
      "MetadataStore with DB connection initialized\n",
      "Component StatisticsGen is finished.\n",
      "Component ExampleValidator is running.\n",
      "Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.example_validator.component.ExampleValidator\"\n",
      "  }\n",
      "  id: \"ExampleValidator\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2024-06-27T07:18:57.100035\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline.ExampleValidator\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"SchemaImporter\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2024-06-27T07:18:57.100035\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline.SchemaImporter\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Schema\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"result\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"statistics\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"StatisticsGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2024-06-27T07:18:57.100035\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline.StatisticsGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"ExampleStatistics\"\n",
      "            base_type: STATISTICS\n",
      "          }\n",
      "        }\n",
      "        output_key: \"statistics\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"anomalies\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleAnomalies\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"exclude_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"[]\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"SchemaImporter\"\n",
      "upstream_nodes: \"StatisticsGen\"\n",
      "downstream_nodes: \"DataTransformer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "MetadataStore with DB connection initialized\n",
      "ArtifactQuery.property_predicate is not supported.\n",
      "ArtifactQuery.property_predicate is not supported.\n",
      "[ExampleValidator] Resolved inputs: ({'statistics': [Artifact(artifact: id: 5\n",
      "type_id: 22\n",
      "uri: \"gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/StatisticsGen/statistics/7\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"stats_dashboard_link\"\n",
      "  value {\n",
      "    string_value: \"\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.15.1\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"ExampleStatistics\"\n",
      "create_time_since_epoch: 1719472801623\n",
      "last_update_time_since_epoch: 1719472801623\n",
      ", artifact_type: id: 22\n",
      "name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "base_type: STATISTICS\n",
      ")], 'schema': [Artifact(artifact: id: 2\n",
      "type_id: 18\n",
      "uri: \"src/raw_schema\"\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 1\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.15.1\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Schema\"\n",
      "create_time_since_epoch: 1719472741230\n",
      "last_update_time_since_epoch: 1719472741230\n",
      ", artifact_type: id: 18\n",
      "name: \"Schema\"\n",
      ")]},)\n",
      "MetadataStore with DB connection initialized\n",
      "Going to run a new execution 8\n",
      "Going to run a new execution: ExecutionInfo(execution_id=8, input_dict={'statistics': [Artifact(artifact: id: 5\n",
      "type_id: 22\n",
      "uri: \"gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/StatisticsGen/statistics/7\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"stats_dashboard_link\"\n",
      "  value {\n",
      "    string_value: \"\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.15.1\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"ExampleStatistics\"\n",
      "create_time_since_epoch: 1719472801623\n",
      "last_update_time_since_epoch: 1719472801623\n",
      ", artifact_type: id: 22\n",
      "name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "base_type: STATISTICS\n",
      ")], 'schema': [Artifact(artifact: id: 2\n",
      "type_id: 18\n",
      "uri: \"src/raw_schema\"\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 1\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.15.1\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Schema\"\n",
      "create_time_since_epoch: 1719472741230\n",
      "last_update_time_since_epoch: 1719472741230\n",
      ", artifact_type: id: 18\n",
      "name: \"Schema\"\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'anomalies': [Artifact(artifact: uri: \"gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/ExampleValidator/anomalies/8\"\n",
      ", artifact_type: name: \"ExampleAnomalies\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      ")]}), exec_properties={'exclude_splits': '[]'}, execution_output_uri='gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/ExampleValidator/.system/executor_execution/8/executor_output.pb', stateful_working_dir='gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/ExampleValidator/.system/stateful_working_dir/39db18e3-426a-452f-add8-bb1f7da5199d', tmp_dir='gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/ExampleValidator/.system/executor_execution/8/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.example_validator.component.ExampleValidator\"\n",
      "  }\n",
      "  id: \"ExampleValidator\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2024-06-27T07:18:57.100035\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline.ExampleValidator\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"SchemaImporter\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2024-06-27T07:18:57.100035\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline.SchemaImporter\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Schema\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"result\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"statistics\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"StatisticsGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2024-06-27T07:18:57.100035\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline.StatisticsGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"ExampleStatistics\"\n",
      "            base_type: STATISTICS\n",
      "          }\n",
      "        }\n",
      "        output_key: \"statistics\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"anomalies\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleAnomalies\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"exclude_splits\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"[]\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"SchemaImporter\"\n",
      "upstream_nodes: \"StatisticsGen\"\n",
      "downstream_nodes: \"DataTransformer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"chicago-taxi-tips-classifier-v09-train-pipeline\"\n",
      ", pipeline_run_id='2024-06-27T07:18:57.100035', top_level_pipeline_run_id=None, frontend_url=None)\n",
      "Validating schema against the computed statistics for split train.\n",
      "Anomalies alerts created for split train.\n",
      "Validation complete for split train. Anomalies written to gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/ExampleValidator/anomalies/8/Split-train.\n",
      "Validating schema against the computed statistics for split eval.\n",
      "Anomalies alerts created for split eval.\n",
      "Validation complete for split eval. Anomalies written to gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/ExampleValidator/anomalies/8/Split-eval.\n",
      "Cleaning up stateless execution info.\n",
      "Execution 8 succeeded.\n",
      "Cleaning up stateful execution info.\n",
      "Deleted stateful_working_dir gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/ExampleValidator/.system/stateful_working_dir/39db18e3-426a-452f-add8-bb1f7da5199d\n",
      "Publishing output artifacts defaultdict(<class 'list'>, {'anomalies': [Artifact(artifact: uri: \"gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/ExampleValidator/anomalies/8\"\n",
      ", artifact_type: name: \"ExampleAnomalies\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      ")]}) for execution 8\n",
      "MetadataStore with DB connection initialized\n",
      "Component ExampleValidator is finished.\n",
      "Component DataTransformer is running.\n",
      "Running launcher for node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.transform.component.Transform\"\n",
      "    base_type: TRANSFORM\n",
      "  }\n",
      "  id: \"DataTransformer\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2024-06-27T07:18:57.100035\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline.DataTransformer\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"TrainDataGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2024-06-27T07:18:57.100035\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline.TrainDataGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"SchemaImporter\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2024-06-27T07:18:57.100035\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline.SchemaImporter\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Schema\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"result\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"post_transform_anomalies\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleAnomalies\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"post_transform_schema\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Schema\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"post_transform_stats\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleStatistics\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          base_type: STATISTICS\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"pre_transform_schema\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Schema\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"pre_transform_stats\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleStatistics\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          base_type: STATISTICS\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"transform_graph\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"TransformGraph\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"transformed_examples\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Examples\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          properties {\n",
      "            key: \"version\"\n",
      "            value: INT\n",
      "          }\n",
      "          base_type: DATASET\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"updated_analyzer_cache\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"TransformCache\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"disable_statistics\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"force_tf_compat_v1\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"module_path\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"transformations@gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/_wheels/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"splits_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"analyze\\\": [\\n    \\\"train\\\"\\n  ],\\n  \\\"transform\\\": [\\n    \\\"train\\\",\\n    \\\"eval\\\"\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"ExampleValidator\"\n",
      "upstream_nodes: \"SchemaImporter\"\n",
      "upstream_nodes: \"TrainDataGen\"\n",
      "downstream_nodes: \"ModelTrainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      "\n",
      "MetadataStore with DB connection initialized\n",
      "ArtifactQuery.property_predicate is not supported.\n",
      "ArtifactQuery.property_predicate is not supported.\n",
      "[DataTransformer] Resolved inputs: ({'schema': [Artifact(artifact: id: 2\n",
      "type_id: 18\n",
      "uri: \"src/raw_schema\"\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 1\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.15.1\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Schema\"\n",
      "create_time_since_epoch: 1719472741230\n",
      "last_update_time_since_epoch: 1719472741230\n",
      ", artifact_type: id: 18\n",
      "name: \"Schema\"\n",
      ")], 'examples': [Artifact(artifact: id: 4\n",
      "type_id: 20\n",
      "uri: \"gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/TrainDataGen/examples/5\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"file_format\"\n",
      "  value {\n",
      "    string_value: \"tfrecords_gzip\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"payload_format\"\n",
      "  value {\n",
      "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.15.1\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Examples\"\n",
      "create_time_since_epoch: 1719472789648\n",
      "last_update_time_since_epoch: 1719472789648\n",
      ", artifact_type: id: 20\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]},)\n",
      "MetadataStore with DB connection initialized\n",
      "Going to run a new execution 9\n",
      "Going to run a new execution: ExecutionInfo(execution_id=9, input_dict={'schema': [Artifact(artifact: id: 2\n",
      "type_id: 18\n",
      "uri: \"src/raw_schema\"\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 1\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.15.1\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Schema\"\n",
      "create_time_since_epoch: 1719472741230\n",
      "last_update_time_since_epoch: 1719472741230\n",
      ", artifact_type: id: 18\n",
      "name: \"Schema\"\n",
      ")], 'examples': [Artifact(artifact: id: 4\n",
      "type_id: 20\n",
      "uri: \"gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/TrainDataGen/examples/5\"\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value {\n",
      "    string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"file_format\"\n",
      "  value {\n",
      "    string_value: \"tfrecords_gzip\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"is_external\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"payload_format\"\n",
      "  value {\n",
      "    string_value: \"FORMAT_TF_EXAMPLE\"\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"span\"\n",
      "  value {\n",
      "    int_value: 0\n",
      "  }\n",
      "}\n",
      "custom_properties {\n",
      "  key: \"tfx_version\"\n",
      "  value {\n",
      "    string_value: \"1.15.1\"\n",
      "  }\n",
      "}\n",
      "state: LIVE\n",
      "type: \"Examples\"\n",
      "create_time_since_epoch: 1719472789648\n",
      "last_update_time_since_epoch: 1719472789648\n",
      ", artifact_type: id: 20\n",
      "name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")]}, output_dict=defaultdict(<class 'list'>, {'post_transform_schema': [Artifact(artifact: uri: \"gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/DataTransformer/post_transform_schema/9\"\n",
      ", artifact_type: name: \"Schema\"\n",
      ")], 'updated_analyzer_cache': [Artifact(artifact: uri: \"gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/DataTransformer/updated_analyzer_cache/9\"\n",
      ", artifact_type: name: \"TransformCache\"\n",
      ")], 'pre_transform_stats': [Artifact(artifact: uri: \"gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/DataTransformer/pre_transform_stats/9\"\n",
      ", artifact_type: name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "base_type: STATISTICS\n",
      ")], 'post_transform_stats': [Artifact(artifact: uri: \"gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/DataTransformer/post_transform_stats/9\"\n",
      ", artifact_type: name: \"ExampleStatistics\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "base_type: STATISTICS\n",
      ")], 'post_transform_anomalies': [Artifact(artifact: uri: \"gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/DataTransformer/post_transform_anomalies/9\"\n",
      ", artifact_type: name: \"ExampleAnomalies\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      ")], 'transformed_examples': [Artifact(artifact: uri: \"gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/DataTransformer/transformed_examples/9\"\n",
      ", artifact_type: name: \"Examples\"\n",
      "properties {\n",
      "  key: \"span\"\n",
      "  value: INT\n",
      "}\n",
      "properties {\n",
      "  key: \"split_names\"\n",
      "  value: STRING\n",
      "}\n",
      "properties {\n",
      "  key: \"version\"\n",
      "  value: INT\n",
      "}\n",
      "base_type: DATASET\n",
      ")], 'transform_graph': [Artifact(artifact: uri: \"gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/DataTransformer/transform_graph/9\"\n",
      ", artifact_type: name: \"TransformGraph\"\n",
      ")], 'pre_transform_schema': [Artifact(artifact: uri: \"gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/DataTransformer/pre_transform_schema/9\"\n",
      ", artifact_type: name: \"Schema\"\n",
      ")]}), exec_properties={'force_tf_compat_v1': 0, 'custom_config': 'null', 'disable_statistics': 0, 'module_path': 'transformations@gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/_wheels/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl', 'splits_config': '{\\n  \"analyze\": [\\n    \"train\"\\n  ],\\n  \"transform\": [\\n    \"train\",\\n    \"eval\"\\n  ]\\n}'}, execution_output_uri='gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/DataTransformer/.system/executor_execution/9/executor_output.pb', stateful_working_dir='gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/DataTransformer/.system/stateful_working_dir/5756d73f-0de3-4cc1-b4d2-3b6bdd8683ca', tmp_dir='gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/DataTransformer/.system/executor_execution/9/.temp/', pipeline_node=node_info {\n",
      "  type {\n",
      "    name: \"tfx.components.transform.component.Transform\"\n",
      "    base_type: TRANSFORM\n",
      "  }\n",
      "  id: \"DataTransformer\"\n",
      "}\n",
      "contexts {\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"pipeline_run\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"2024-06-27T07:18:57.100035\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  contexts {\n",
      "    type {\n",
      "      name: \"node\"\n",
      "    }\n",
      "    name {\n",
      "      field_value {\n",
      "        string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline.DataTransformer\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "inputs {\n",
      "  inputs {\n",
      "    key: \"examples\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"TrainDataGen\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2024-06-27T07:18:57.100035\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline.TrainDataGen\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Examples\"\n",
      "            base_type: DATASET\n",
      "          }\n",
      "        }\n",
      "        output_key: \"examples\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "  inputs {\n",
      "    key: \"schema\"\n",
      "    value {\n",
      "      channels {\n",
      "        producer_node_query {\n",
      "          id: \"SchemaImporter\"\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"pipeline_run\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"2024-06-27T07:18:57.100035\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        context_queries {\n",
      "          type {\n",
      "            name: \"node\"\n",
      "          }\n",
      "          name {\n",
      "            field_value {\n",
      "              string_value: \"chicago-taxi-tips-classifier-v09-train-pipeline.SchemaImporter\"\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        artifact_query {\n",
      "          type {\n",
      "            name: \"Schema\"\n",
      "          }\n",
      "        }\n",
      "        output_key: \"result\"\n",
      "      }\n",
      "      min_count: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "outputs {\n",
      "  outputs {\n",
      "    key: \"post_transform_anomalies\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleAnomalies\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"post_transform_schema\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Schema\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"post_transform_stats\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleStatistics\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          base_type: STATISTICS\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"pre_transform_schema\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Schema\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"pre_transform_stats\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"ExampleStatistics\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          base_type: STATISTICS\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"transform_graph\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"TransformGraph\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"transformed_examples\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"Examples\"\n",
      "          properties {\n",
      "            key: \"span\"\n",
      "            value: INT\n",
      "          }\n",
      "          properties {\n",
      "            key: \"split_names\"\n",
      "            value: STRING\n",
      "          }\n",
      "          properties {\n",
      "            key: \"version\"\n",
      "            value: INT\n",
      "          }\n",
      "          base_type: DATASET\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  outputs {\n",
      "    key: \"updated_analyzer_cache\"\n",
      "    value {\n",
      "      artifact_spec {\n",
      "        type {\n",
      "          name: \"TransformCache\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameters {\n",
      "    key: \"custom_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"null\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"disable_statistics\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"force_tf_compat_v1\"\n",
      "    value {\n",
      "      field_value {\n",
      "        int_value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"module_path\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"transformations@gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/_wheels/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    key: \"splits_config\"\n",
      "    value {\n",
      "      field_value {\n",
      "        string_value: \"{\\n  \\\"analyze\\\": [\\n    \\\"train\\\"\\n  ],\\n  \\\"transform\\\": [\\n    \\\"train\\\",\\n    \\\"eval\\\"\\n  ]\\n}\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "upstream_nodes: \"ExampleValidator\"\n",
      "upstream_nodes: \"SchemaImporter\"\n",
      "upstream_nodes: \"TrainDataGen\"\n",
      "downstream_nodes: \"ModelTrainer\"\n",
      "execution_options {\n",
      "  caching_options {\n",
      "  }\n",
      "}\n",
      ", pipeline_info=id: \"chicago-taxi-tips-classifier-v09-train-pipeline\"\n",
      ", pipeline_run_id='2024-06-27T07:18:57.100035', top_level_pipeline_run_id=None, frontend_url=None)\n",
      "Attempting to infer TFX Python dependency for beam\n",
      "Copying all content from install dir /opt/conda/lib/python3.10/site-packages/tfx to temp dir /var/tmp/tmpdd16agd_/build/tfx\n",
      "Generating a temp setup file at /var/tmp/tmpdd16agd_/build/tfx/setup.py\n",
      "Creating temporary sdist package, logs available at /var/tmp/tmpdd16agd_/build/tfx/setup.log\n",
      "Added --extra_package=/var/tmp/tmpdd16agd_/build/tfx/dist/tfx_ephemeral-1.15.1.tar.gz to beam args\n",
      "udf_utils.get_fn {'module_file': None, 'module_path': 'transformations@gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/_wheels/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl', 'preprocessing_fn': None} 'preprocessing_fn'\n",
      "Installing '/var/tmp/tmprqwtde4q/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl' to a temporary directory.\n",
      "Executing: ['/opt/conda/bin/python', '-m', 'pip', 'install', '--target', '/var/tmp/tmpch6ob_2t', '/var/tmp/tmprqwtde4q/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl']\n",
      "Processing /var/tmp/tmprqwtde4q/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl\n",
      "Installing collected packages: tfx-user-code-DataTransformer\n",
      "Successfully installed tfx-user-code-DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d\n",
      "Successfully installed '/var/tmp/tmprqwtde4q/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl'.\n",
      "udf_utils.get_fn {'module_file': None, 'module_path': 'transformations@gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/_wheels/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl', 'stats_options_updater_fn': None} 'stats_options_updater_fn'\n",
      "Installing '/var/tmp/tmpkx_r2j2d/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl' to a temporary directory.\n",
      "Executing: ['/opt/conda/bin/python', '-m', 'pip', 'install', '--target', '/var/tmp/tmpwz37mr8g', '/var/tmp/tmpkx_r2j2d/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl']\n",
      "Processing /var/tmp/tmpkx_r2j2d/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl\n",
      "Installing collected packages: tfx-user-code-DataTransformer\n",
      "Successfully installed tfx-user-code-DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d\n",
      "Successfully installed '/var/tmp/tmpkx_r2j2d/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl'.\n",
      "Installing '/var/tmp/tmpb8lyjz82/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl' to a temporary directory.\n",
      "Executing: ['/opt/conda/bin/python', '-m', 'pip', 'install', '--target', '/var/tmp/tmpf8cft8u_', '/var/tmp/tmpb8lyjz82/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl']\n",
      "Processing /var/tmp/tmpb8lyjz82/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl\n",
      "Installing collected packages: tfx-user-code-DataTransformer\n",
      "Successfully installed tfx-user-code-DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d\n",
      "Successfully installed '/var/tmp/tmpb8lyjz82/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl'.\n",
      "Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Missing pipeline option (runner). Executing pipeline using the default runner: DirectRunner.\n",
      "Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_1/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_2/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_3/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_4/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_5/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_6/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_7/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_1/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_2/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_3/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_4/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_5/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_6/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_7/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "Finished listing 1 files in 0.029627323150634766 seconds.\n",
      "Using Any for unsupported type: typing.Sequence[str]\n",
      "Finished listing 1 files in 0.03619813919067383 seconds.\n",
      "Using Any for unsupported type: typing.Sequence[str]\n",
      "Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Finished listing 1 files in 0.02868938446044922 seconds.\n",
      "Using Any for unsupported type: typing.Sequence[str]\n",
      "Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_month has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_day has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_day_of_week has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_hour has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_seconds has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature trip_miles has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature payment_type has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature pickup_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature dropoff_grid has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature euclidean has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature loc_cross has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Feature tip_bin has a shape dim {\n",
      "  size: 1\n",
      "}\n",
      ". Setting to DenseTensor.\n",
      "Creating state cache with size 104857600\n",
      "Finished listing 1 files in 0.03150629997253418 seconds.\n",
      "Assets written to: gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/DataTransformer/transform_graph/9/.temp_path/tftransform_tmp/ccc47723a0f64c3e9caf7782c9576b27/assets\n",
      "Finished listing 1 files in 0.025814533233642578 seconds.\n",
      "Finished listing 1 files in 0.026717185974121094 seconds.\n",
      "struct2tensor is not available.\n",
      "TensorFlow Decision Forests 1.9.1 is compatible with the following TensorFlow Versions: ['2.16.1']. However, TensorFlow 2.15.0 was detected. This can cause issues with the TF API and symbols in the custom C++ ops. See the TF and TF-DF compatibility table at https://github.com/tensorflow/decision-forests/blob/main/documentation/known_issues.md#compatibility-table.\n",
      "Failure to load the inference.so custom c++ tensorflow ops. This error is likely caused the version of TensorFlow and TensorFlow Decision Forests are not compatible. Full error:/opt/conda/lib/python3.10/site-packages/tensorflow_decision_forests/tensorflow/ops/inference/inference.so: undefined symbol: _ZN10tensorflow20OpKernelConstruction21CtxFailureWithWarningEPKciRKN4absl12lts_202308026StatusE\n",
      "tensorflow_decision_forests is not available.\n",
      "tensorflow_text is not available.\n",
      "BatchElements statistics: element_count=783 batch_count=11 next_batch_size=542 timings=[(1, 0.00826716423034668), (2, 0.007909536361694336), (4, 0.007926464080810547), (8, 0.008983612060546875), (16, 0.009243011474609375), (32, 0.009456157684326172), (64, 0.010833024978637695), (128, 0.011963605880737305), (256, 0.015544652938842773), (271, 0.015305042266845703)]\n",
      "Finished listing 1 files in 0.04038572311401367 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.35 seconds.\n",
      "Finished listing 1 files in 0.028470754623413086 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.36 seconds.\n",
      "BatchElements statistics: element_count=9 batch_count=1 next_batch_size=150000 timings=[]\n",
      "BatchElements statistics: element_count=31 batch_count=1 next_batch_size=150000 timings=[]\n",
      "BatchElements statistics: element_count=7 batch_count=1 next_batch_size=150000 timings=[]\n",
      "BatchElements statistics: element_count=24 batch_count=1 next_batch_size=150000 timings=[]\n",
      "BatchElements statistics: element_count=6 batch_count=1 next_batch_size=150000 timings=[]\n",
      "BatchElements statistics: element_count=2 batch_count=1 next_batch_size=150000 timings=[]\n",
      "BatchElements statistics: element_count=4 batch_count=1 next_batch_size=150000 timings=[]\n",
      "BatchElements statistics: element_count=6 batch_count=1 next_batch_size=150000 timings=[]\n",
      "Finished listing 1 files in 0.02741837501525879 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.31 seconds.\n",
      "Finished listing 1 files in 0.03022623062133789 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.34 seconds.\n",
      "Finished listing 1 files in 0.03673744201660156 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.33 seconds.\n",
      "Finished listing 1 files in 0.027846574783325195 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.33 seconds.\n",
      "Finished listing 1 files in 0.02744460105895996 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.32 seconds.\n",
      "Finished listing 1 files in 0.02782893180847168 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.31 seconds.\n",
      "Finished listing 1 files in 0.0334014892578125 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.31 seconds.\n",
      "Finished listing 1 files in 0.02666640281677246 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.32 seconds.\n",
      "Finished listing 1 files in 0.028237104415893555 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.31 seconds.\n",
      "Finished listing 1 files in 0.03343057632446289 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.32 seconds.\n",
      "Finished listing 1 files in 0.029753684997558594 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.31 seconds.\n",
      "Finished listing 1 files in 0.03272509574890137 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.34 seconds.\n",
      "Finished listing 1 files in 0.031191587448120117 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.32 seconds.\n",
      "Finished listing 1 files in 0.029419660568237305 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.31 seconds.\n",
      "Finished listing 1 files in 0.030832290649414062 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.37 seconds.\n",
      "Finished listing 1 files in 0.029048442840576172 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.33 seconds.\n",
      "Finished listing 1 files in 0.0388948917388916 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.32 seconds.\n",
      "Finished listing 1 files in 0.03242945671081543 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.40 seconds.\n",
      "Finished listing 1 files in 0.030582427978515625 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.31 seconds.\n",
      "Finished listing 1 files in 0.03751015663146973 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.33 seconds.\n",
      "Assets written to: gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/DataTransformer/transform_graph/9/.temp_path/tftransform_tmp/a74357ba32c74cc8b0fe9064a46597d5/assets\n",
      "struct2tensor is not available.\n",
      "TensorFlow Decision Forests 1.9.1 is compatible with the following TensorFlow Versions: ['2.16.1']. However, TensorFlow 2.15.0 was detected. This can cause issues with the TF API and symbols in the custom C++ ops. See the TF and TF-DF compatibility table at https://github.com/tensorflow/decision-forests/blob/main/documentation/known_issues.md#compatibility-table.\n",
      "Failure to load the inference.so custom c++ tensorflow ops. This error is likely caused the version of TensorFlow and TensorFlow Decision Forests are not compatible. Full error:/opt/conda/lib/python3.10/site-packages/tensorflow_decision_forests/tensorflow/ops/inference/inference.so: undefined symbol: _ZN10tensorflow20OpKernelConstruction21CtxFailureWithWarningEPKciRKN4absl12lts_202308026StatusE\n",
      "tensorflow_decision_forests is not available.\n",
      "tensorflow_text is not available.\n",
      "BatchElements statistics: element_count=217 batch_count=9 next_batch_size=178 timings=[(1, 0.0064008235931396484), (2, 0.006224155426025391), (4, 0.006369590759277344), (8, 0.006394624710083008), (16, 0.007966756820678711), (32, 0.009529352188110352), (64, 0.010102272033691406), (89, 0.012450218200683594)]\n",
      "struct2tensor is not available.\n",
      "TensorFlow Decision Forests 1.9.1 is compatible with the following TensorFlow Versions: ['2.16.1']. However, TensorFlow 2.15.0 was detected. This can cause issues with the TF API and symbols in the custom C++ ops. See the TF and TF-DF compatibility table at https://github.com/tensorflow/decision-forests/blob/main/documentation/known_issues.md#compatibility-table.\n",
      "Failure to load the inference.so custom c++ tensorflow ops. This error is likely caused the version of TensorFlow and TensorFlow Decision Forests are not compatible. Full error:/opt/conda/lib/python3.10/site-packages/tensorflow_decision_forests/tensorflow/ops/inference/inference.so: undefined symbol: _ZN10tensorflow20OpKernelConstruction21CtxFailureWithWarningEPKciRKN4absl12lts_202308026StatusE\n",
      "tensorflow_decision_forests is not available.\n",
      "tensorflow_text is not available.\n",
      "BatchElements statistics: element_count=783 batch_count=11 next_batch_size=542 timings=[(1, 0.006785869598388672), (2, 0.006830692291259766), (4, 0.008821249008178711), (8, 0.009305715560913086), (16, 0.00790858268737793), (32, 0.009356021881103516), (64, 0.010309934616088867), (128, 0.01397085189819336), (256, 0.020087003707885742), (271, 0.021659135818481445)]\n",
      "Finished listing 1 files in 0.038504838943481445 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.33 seconds.\n",
      "Finished listing 1 files in 0.029583215713500977 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.32 seconds.\n",
      "Finished listing 1 files in 0.03126716613769531 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.35 seconds.\n",
      "Finished listing 1 files in 0.03662681579589844 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.34 seconds.\n",
      "Finished listing 1 files in 0.02578425407409668 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.32 seconds.\n",
      "ArtifactQuery.property_predicate is not supported.\n",
      "ArtifactQuery.property_predicate is not supported.\n",
      "ArtifactQuery.property_predicate is not supported.\n",
      "ArtifactQuery.property_predicate is not supported.\n",
      "Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "Processing /var/tmp/tmpik_vf_6b/tfx_user_code_ModelTrainer-0.0+88cee01a077ea7ce1a9871764b3718ea318b1da2b217190de116232b22159367-py3-none-any.whl\n",
      "Installing collected packages: tfx-user-code-ModelTrainer\n",
      "Successfully installed tfx-user-code-ModelTrainer-0.0+88cee01a077ea7ce1a9871764b3718ea318b1da2b217190de116232b22159367\n",
      "Runner started...\n",
      "fn_args: FnArgs(working_dir=None, train_files=['gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/DataTransformer/transformed_examples/9/Split-train/*'], eval_files=['gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/DataTransformer/transformed_examples/9/Split-eval/*'], train_steps=None, eval_steps=None, schema_path='src/raw_schema/schema.pbtxt', schema_file='src/raw_schema/schema.pbtxt', transform_graph_path='gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/DataTransformer/transform_graph/9', transform_output='gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/DataTransformer/transform_graph/9', data_accessor=DataAccessor(tf_dataset_factory=<function get_tf_dataset_factory_from_artifact.<locals>.dataset_factory at 0x7f0ee87a9a20>, record_batch_factory=<function get_record_batch_factory_from_artifact.<locals>.record_batch_factory at 0x7f0ee87a8f70>, data_view_decode_fn=None), serving_model_dir='gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/ModelTrainer/model/10/Format-Serving', eval_model_dir='gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/ModelTrainer/model/10/Format-TFMA', model_run_dir='gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/ModelTrainer/model_run/10', base_model=None, hyperparameters={'num_epochs': 1, 'batch_size': 512, 'learning_rate': 0.001, 'hidden_units': [128, 128]}, custom_config=None)\n",
      "\n",
      "Hyperparameter:\n",
      "{'num_epochs': 1, 'batch_size': 512, 'learning_rate': 0.001, 'hidden_units': [128, 128]}\n",
      "\n",
      "Runner executing trainer...\n",
      "Loading tft output from gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/DataTransformer/transform_graph/9\n",
      "From /opt/conda/lib/python3.10/site-packages/tensorflow/python/data/experimental/ops/readers.py:1086: parse_example_dataset (from tensorflow.python.data.experimental.ops.parsing_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map(tf.io.parse_example(...))` instead.\n",
      "Model training started...\n",
      "      1/Unknown - 2s 2s/step - loss: 0.7339 - accuracy: 0.8438Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.7339 - accuracy: 0.8438\n",
      "Model training completed.\n",
      "Runner executing exporter...\n",
      "struct2tensor is not available.\n",
      "TensorFlow Decision Forests 1.9.1 is compatible with the following TensorFlow Versions: ['2.16.1']. However, TensorFlow 2.15.0 was detected. This can cause issues with the TF API and symbols in the custom C++ ops. See the TF and TF-DF compatibility table at https://github.com/tensorflow/decision-forests/blob/main/documentation/known_issues.md#compatibility-table.\n",
      "Failure to load the inference.so custom c++ tensorflow ops. This error is likely caused the version of TensorFlow and TensorFlow Decision Forests are not compatible. Full error:/opt/conda/lib/python3.10/site-packages/tensorflow_decision_forests/tensorflow/ops/inference/inference.so: undefined symbol: _ZN10tensorflow20OpKernelConstruction21CtxFailureWithWarningEPKciRKN4absl12lts_202308026StatusE\n",
      "tensorflow_decision_forests is not available.\n",
      "tensorflow_text is not available.\n",
      "Model export started...\n",
      "Assets written to: gs://test-lora/chicago-taxi-tips/e2e_tests/tfx_artifacts/chicago-taxi-tips-classifier-v09-train-pipeline/ModelTrainer/model/10/Format-Serving/assets\n",
      "Model export completed.\n",
      "Runner completed.\n",
      "ArtifactQuery.property_predicate is not supported.\n",
      "ArtifactQuery.property_predicate is not supported.\n",
      "ArtifactQuery.property_predicate is not supported.\n",
      "SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "Missing pipeline option (runner). Executing pipeline using the default runner: DirectRunner.\n",
      "Finished listing 1 files in 0.026360511779785156 seconds.\n",
      "Using Any for unsupported type: typing.Sequence[str]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.Sequence[typing.MutableMapping[str, typing.Any]]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.Sequence[typing.MutableMapping[str, typing.Any]]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.Sequence[typing.MutableMapping[str, typing.Any]]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.Sequence[typing.MutableMapping[str, typing.Any]]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.Sequence[typing.MutableMapping[str, typing.Any]]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.Sequence[typing.MutableMapping[str, typing.Any]]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.Sequence[typing.MutableMapping[str, typing.Any]]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.Sequence[typing.MutableMapping[str, typing.Any]]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.Sequence[typing.MutableMapping[str, typing.Any]]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.MutableMapping[str, typing.Any]\n",
      "Using Any for unsupported type: typing.Type[typing.Union[tensorflow_model_analysis.metrics.metric_types.MetricKey, tensorflow_model_analysis.metrics.metric_types.PlotKey, tensorflow_model_analysis.metrics.metric_types.AttributionsKey]]\n",
      "Using Any for unsupported type: typing.Type[typing.Union[tensorflow_model_analysis.metrics.metric_types.MetricKey, tensorflow_model_analysis.metrics.metric_types.PlotKey, tensorflow_model_analysis.metrics.metric_types.AttributionsKey]]\n",
      "Using Any for unsupported type: typing.Type[typing.Union[tensorflow_model_analysis.metrics.metric_types.MetricKey, tensorflow_model_analysis.metrics.metric_types.PlotKey, tensorflow_model_analysis.metrics.metric_types.AttributionsKey]]\n",
      "Using Any for unsupported type: typing.Callable[[typing.Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, typing.Dict[str, typing.Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor]]], typing.Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, typing.Dict[str, typing.Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor]]], typing.Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, typing.Dict[str, typing.Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor]]]], typing.Dict[str, typing.Tuple[typing.Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor], typing.Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor]]]]\n",
      "Using Any for unsupported type: typing.Callable[[typing.Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, typing.Dict[str, typing.Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor]]], typing.Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, typing.Dict[str, typing.Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor]]], typing.Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, typing.Dict[str, typing.Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor]]]], typing.Dict[str, typing.Tuple[typing.Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor], typing.Union[tensorflow.python.framework.tensor.Tensor, tensorflow.python.framework.sparse_tensor.SparseTensor, tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor]]]]\n",
      "Creating state cache with size 104857600\n",
      "Finished listing 1 files in 0.028424978256225586 seconds.\n",
      "BatchElements statistics: element_count=100 batch_count=8 next_batch_size=72 timings=[(1, 0.008858919143676758), (2, 0.009904623031616211), (4, 0.011691570281982422), (8, 0.01540517807006836), (16, 0.0199124813079834), (32, 0.027806520462036133), (36, 0.027962684631347656)]\n",
      "Finished listing 1 files in 0.027345895767211914 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.33 seconds.\n",
      "Finished listing 1 files in 0.03139328956604004 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.33 seconds.\n",
      "Finished listing 1 files in 0.026185274124145508 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.34 seconds.\n",
      "Finished listing 1 files in 0.031838178634643555 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.32 seconds.\n",
      "Finished listing 1 files in 0.031790733337402344 seconds.\n",
      "Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "Renamed 1 shards in 0.34 seconds.\n",
      "From /opt/conda/lib/python3.10/site-packages/tensorflow_model_analysis/writers/metrics_plots_and_validations_writer.py:112: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "ArtifactQuery.property_predicate is not supported.\n",
      "ArtifactQuery.property_predicate is not supported.\n",
      "Model output: gs://test-lora/chicago-taxi-tips/e2e_tests/model_registry/chicago-taxi-tips-classifier-v09\n",
      "\u001b[32m.\u001b[0m\n",
      "\n",
      "\u001b[33m=============================== warnings summary ===============================\u001b[0m\n",
      "../../../opt/conda/lib/python3.10/site-packages/tfx/utils/deprecation_utils.py:188\n",
      "  /opt/conda/lib/python3.10/site-packages/tfx/utils/deprecation_utils.py:188: TfxDeprecationWarning: DEFAULT_FILE_NAME will be deprecated soon\n",
      "    warnings.warn(msg, TfxDeprecationWarning)\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[33m=================== \u001b[32m1 passed\u001b[0m, \u001b[33m\u001b[1m1 warning\u001b[0m\u001b[33m in 369.04s (0:06:09)\u001b[0m\u001b[33m ===================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!py.test src/tests/pipeline_deployment_tests.py::test_e2e_pipeline -s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5704bcb",
   "metadata": {},
   "source": [
    "## 2. Run the training pipeline using Vertex Pipelines\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d7db74",
   "metadata": {},
   "source": [
    "### Set the pipeline configurations for the Vertex AI run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e2fe69b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"DATASET_DISPLAY_NAME\"] = DATASET_DISPLAY_NAME\n",
    "os.environ[\"MODEL_DISPLAY_NAME\"] = MODEL_DISPLAY_NAME\n",
    "os.environ[\"PIPELINE_NAME\"] = PIPELINE_NAME\n",
    "os.environ[\"PROJECT\"] = PROJECT\n",
    "os.environ[\"REGION\"] = REGION\n",
    "os.environ[\"GCS_LOCATION\"] = f\"gs://{BUCKET}/{DATASET_DISPLAY_NAME}\"\n",
    "os.environ[\"TRAIN_LIMIT\"] = \"85000\"\n",
    "os.environ[\"TEST_LIMIT\"] = \"15000\"\n",
    "os.environ[\"BEAM_RUNNER\"] = \"DataflowRunner\"\n",
    "os.environ[\"TRAINING_RUNNER\"] = \"vertex\"\n",
    "os.environ[\"TFX_IMAGE_URI\"] = f\"gcr.io/{PROJECT}/{DATASET_DISPLAY_NAME}:{VERSION}\"\n",
    "os.environ[\"ENABLE_CACHE\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d83ef31a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT: supply-chain-twin-349311\n",
      "REGION: us-central1\n",
      "GCS_LOCATION: gs://test-lora/chicago-taxi-tips\n",
      "ARTIFACT_STORE_URI: gs://test-lora/chicago-taxi-tips/tfx_artifacts\n",
      "MODEL_REGISTRY_URI: gs://test-lora/chicago-taxi-tips/e2e_tests/model_registry\n",
      "DATASET_DISPLAY_NAME: chicago-taxi-tips\n",
      "MODEL_DISPLAY_NAME: chicago-taxi-tips-classifier-v09\n",
      "PIPELINE_NAME: chicago-taxi-tips-classifier-v09-train-pipeline\n",
      "ML_USE_COLUMN: ml_use\n",
      "EXCLUDE_COLUMNS: trip_start_timestamp\n",
      "TRAIN_LIMIT: 85000\n",
      "TEST_LIMIT: 15000\n",
      "SERVE_LIMIT: 0\n",
      "NUM_TRAIN_SPLITS: 4\n",
      "NUM_EVAL_SPLITS: 1\n",
      "ACCURACY_THRESHOLD: 0.1\n",
      "USE_KFP_SA: False\n",
      "TFX_IMAGE_URI: gcr.io/supply-chain-twin-349311/chicago-taxi-tips:v09\n",
      "BEAM_RUNNER: DataflowRunner\n",
      "BEAM_DIRECT_PIPELINE_ARGS: ['--project=supply-chain-twin-349311', '--temp_location=gs://test-lora/chicago-taxi-tips/temp']\n",
      "BEAM_DATAFLOW_PIPELINE_ARGS: ['--project=supply-chain-twin-349311', '--temp_location=gs://test-lora/chicago-taxi-tips/temp', '--region=us-central1', '--runner=DataflowRunner']\n",
      "TRAINING_RUNNER: vertex\n",
      "VERTEX_TRAINING_ARGS: {'project': 'supply-chain-twin-349311', 'worker_pool_specs': [{'machine_spec': {'machine_type': 'n1-standard-4'}, 'replica_count': 1, 'container_spec': {'image_uri': 'gcr.io/supply-chain-twin-349311/chicago-taxi-tips:v09'}}]}\n",
      "VERTEX_TRAINING_CONFIG: {'ai_platform_training_enable_ucaip': True, 'ai_platform_training_ucaip_region': 'us-central1', 'ai_platform_training_args': {'project': 'supply-chain-twin-349311', 'worker_pool_specs': [{'machine_spec': {'machine_type': 'n1-standard-4'}, 'replica_count': 1, 'container_spec': {'image_uri': 'gcr.io/supply-chain-twin-349311/chicago-taxi-tips:v09'}}]}, 'use_gpu': False}\n",
      "SERVING_RUNTIME: tf2-cpu.2-5\n",
      "SERVING_IMAGE_URI: us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-5:latest\n",
      "BATCH_PREDICTION_BQ_DATASET_NAME: playground_us\n",
      "BATCH_PREDICTION_BQ_TABLE_NAME: chicago_taxitrips_prep\n",
      "BATCH_PREDICTION_BEAM_ARGS: {'runner': 'DataflowRunner', 'temporary_dir': 'gs://test-lora/chicago-taxi-tips/temp', 'gcs_location': 'gs://test-lora/chicago-taxi-tips/temp', 'project': 'supply-chain-twin-349311', 'region': 'us-central1', 'setup_file': './setup.py'}\n",
      "BATCH_PREDICTION_JOB_RESOURCES: {'machine_type': 'n1-standard-2', 'starting_replica_count': 1, 'max_replica_count': 10}\n",
      "DATASTORE_PREDICTION_KIND: chicago-taxi-tips-classifier-v09-predictions\n",
      "ENABLE_CACHE: 1\n",
      "UPLOAD_MODEL: 0\n"
     ]
    }
   ],
   "source": [
    "from src.tfx_pipelines import config\n",
    "import importlib\n",
    "importlib.reload(config)\n",
    "\n",
    "for key, value in config.__dict__.items():\n",
    "    if key.isupper(): print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f3164f",
   "metadata": {},
   "source": [
    "### Build the ML container image\n",
    "\n",
    "This is the `TFX` runtime environment for the training pipeline steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a0e729b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcr.io/supply-chain-twin-349311/chicago-taxi-tips:v09\n"
     ]
    }
   ],
   "source": [
    "!echo $TFX_IMAGE_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3087da4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary archive of 70 file(s) totalling 52.4 MiB before compression.\n",
      "Some files were not included in the source upload.\n",
      "\n",
      "Check the gcloud log [/home/jupyter/.config/gcloud/logs/2024.06.27/07.24.41.006481.log] to see which files and the contents of the\n",
      "default gcloudignore file used (see `$ gcloud topic gcloudignore` to learn\n",
      "more).\n",
      "\n",
      "Uploading tarball of [.] to [gs://supply-chain-twin-349311_cloudbuild/source/1719473081.198917-78831b76eb1846178aecf1692ee0f2c8.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/supply-chain-twin-349311/locations/global/builds/e0bc706b-d65f-4cfb-8b64-4eb0741047b4].\n",
      "Logs are available at [ https://console.cloud.google.com/cloud-build/builds/e0bc706b-d65f-4cfb-8b64-4eb0741047b4?project=1049330678395 ].\n",
      "Waiting for build to complete. Polling interval: 1 second(s).\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"e0bc706b-d65f-4cfb-8b64-4eb0741047b4\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://supply-chain-twin-349311_cloudbuild/source/1719473081.198917-78831b76eb1846178aecf1692ee0f2c8.tgz#1719473081782269\n",
      "Copying gs://supply-chain-twin-349311_cloudbuild/source/1719473081.198917-78831b76eb1846178aecf1692ee0f2c8.tgz#1719473081782269...\n",
      "/ [1 files][269.3 KiB/269.3 KiB]                                                \n",
      "Operation completed over 1 objects/269.3 KiB.\n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon  2.707MB\n",
      "Step 1/7 : FROM python:3.10-slim AS builder\n",
      "3.10-slim: Pulling from library/python\n",
      "2cc3ae149d28: Already exists\n",
      "318623cc513b: Pulling fs layer\n",
      "05ac4be303fa: Pulling fs layer\n",
      "2306c655b011: Pulling fs layer\n",
      "769e3784f667: Pulling fs layer\n",
      "769e3784f667: Waiting\n",
      "2306c655b011: Verifying Checksum\n",
      "2306c655b011: Download complete\n",
      "318623cc513b: Verifying Checksum\n",
      "318623cc513b: Download complete\n",
      "769e3784f667: Verifying Checksum\n",
      "769e3784f667: Download complete\n",
      "05ac4be303fa: Verifying Checksum\n",
      "05ac4be303fa: Download complete\n",
      "318623cc513b: Pull complete\n",
      "05ac4be303fa: Pull complete\n",
      "2306c655b011: Pull complete\n",
      "769e3784f667: Pull complete\n",
      "Digest: sha256:7031721c32bb04541037e71ba2ba4e88f25d42b8739035d589e21ae9226913d3\n",
      "Status: Downloaded newer image for python:3.10-slim\n",
      " ---> 6b73590883e6\n",
      "Step 2/7 : RUN apt-get update && apt-get install -y     build-essential     && apt-get clean     && rm -rf /var/lib/apt/lists/*\n",
      " ---> Running in a40bd41874d4\n",
      "Get:1 http://deb.debian.org/debian bookworm InRelease [151 kB]\n",
      "Get:2 http://deb.debian.org/debian bookworm-updates InRelease [55.4 kB]\n",
      "Get:3 http://deb.debian.org/debian-security bookworm-security InRelease [48.0 kB]\n",
      "Get:4 http://deb.debian.org/debian bookworm/main amd64 Packages [8786 kB]\n",
      "Get:5 http://deb.debian.org/debian bookworm-updates/main amd64 Packages [13.8 kB]\n",
      "Get:6 http://deb.debian.org/debian-security bookworm-security/main amd64 Packages [161 kB]\n",
      "Fetched 9215 kB in 2s (5636 kB/s)\n",
      "Reading package lists...\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following additional packages will be installed:\n",
      "  binutils binutils-common binutils-x86-64-linux-gnu bzip2 cpp cpp-12 dirmngr\n",
      "  dpkg-dev fakeroot fontconfig-config fonts-dejavu-core g++ g++-12 gcc gcc-12\n",
      "  gnupg gnupg-l10n gnupg-utils gpg gpg-agent gpg-wks-client gpg-wks-server\n",
      "  gpgconf gpgsm libabsl20220623 libalgorithm-diff-perl\n",
      "  libalgorithm-diff-xs-perl libalgorithm-merge-perl libaom3 libasan8\n",
      "  libassuan0 libatomic1 libavif15 libbinutils libbrotli1 libbsd0 libc-dev-bin\n",
      "  libc-devtools libc6-dev libcc1-0 libcrypt-dev libctf-nobfd0 libctf0\n",
      "  libdav1d6 libde265-0 libdeflate0 libdpkg-perl libfakeroot\n",
      "  libfile-fcntllock-perl libfontconfig1 libfreetype6 libgav1-1 libgcc-12-dev\n",
      "  libgd3 libgdbm-compat4 libgomp1 libgprofng0 libheif1 libisl23 libitm1\n",
      "  libjansson4 libjbig0 libjpeg62-turbo libksba8 libldap-2.5-0 libldap-common\n",
      "  liblerc4 liblocale-gettext-perl liblsan0 libmpc3 libmpfr6 libnpth0\n",
      "  libnsl-dev libnuma1 libperl5.36 libpng16-16 libquadmath0 librav1e0\n",
      "  libsasl2-2 libsasl2-modules libsasl2-modules-db libstdc++-12-dev\n",
      "  libsvtav1enc1 libtiff6 libtirpc-dev libtsan2 libubsan1 libwebp7 libx11-6\n",
      "  libx11-data libx265-199 libxau6 libxcb1 libxdmcp6 libxpm4 libyuv0\n",
      "  linux-libc-dev make manpages manpages-dev patch perl perl-modules-5.36\n",
      "  pinentry-curses rpcsvc-proto xz-utils\n",
      "Suggested packages:\n",
      "  binutils-doc bzip2-doc cpp-doc gcc-12-locales cpp-12-doc dbus-user-session\n",
      "  libpam-systemd pinentry-gnome3 tor debian-keyring g++-multilib\n",
      "  g++-12-multilib gcc-12-doc gcc-multilib autoconf automake libtool flex bison\n",
      "  gdb gcc-doc gcc-12-multilib parcimonie xloadimage scdaemon glibc-doc\n",
      "  sensible-utils git bzr libgd-tools libsasl2-modules-gssapi-mit\n",
      "  | libsasl2-modules-gssapi-heimdal libsasl2-modules-ldap libsasl2-modules-otp\n",
      "  libsasl2-modules-sql libstdc++-12-doc make-doc man-browser ed diffutils-doc\n",
      "  perl-doc libterm-readline-gnu-perl | libterm-readline-perl-perl\n",
      "  libtap-harness-archive-perl pinentry-doc\n",
      "The following NEW packages will be installed:\n",
      "  binutils binutils-common binutils-x86-64-linux-gnu build-essential bzip2 cpp\n",
      "  cpp-12 dirmngr dpkg-dev fakeroot fontconfig-config fonts-dejavu-core g++\n",
      "  g++-12 gcc gcc-12 gnupg gnupg-l10n gnupg-utils gpg gpg-agent gpg-wks-client\n",
      "  gpg-wks-server gpgconf gpgsm libabsl20220623 libalgorithm-diff-perl\n",
      "  libalgorithm-diff-xs-perl libalgorithm-merge-perl libaom3 libasan8\n",
      "  libassuan0 libatomic1 libavif15 libbinutils libbrotli1 libbsd0 libc-dev-bin\n",
      "  libc-devtools libc6-dev libcc1-0 libcrypt-dev libctf-nobfd0 libctf0\n",
      "  libdav1d6 libde265-0 libdeflate0 libdpkg-perl libfakeroot\n",
      "  libfile-fcntllock-perl libfontconfig1 libfreetype6 libgav1-1 libgcc-12-dev\n",
      "  libgd3 libgdbm-compat4 libgomp1 libgprofng0 libheif1 libisl23 libitm1\n",
      "  libjansson4 libjbig0 libjpeg62-turbo libksba8 libldap-2.5-0 libldap-common\n",
      "  liblerc4 liblocale-gettext-perl liblsan0 libmpc3 libmpfr6 libnpth0\n",
      "  libnsl-dev libnuma1 libperl5.36 libpng16-16 libquadmath0 librav1e0\n",
      "  libsasl2-2 libsasl2-modules libsasl2-modules-db libstdc++-12-dev\n",
      "  libsvtav1enc1 libtiff6 libtirpc-dev libtsan2 libubsan1 libwebp7 libx11-6\n",
      "  libx11-data libx265-199 libxau6 libxcb1 libxdmcp6 libxpm4 libyuv0\n",
      "  linux-libc-dev make manpages manpages-dev patch perl perl-modules-5.36\n",
      "  pinentry-curses rpcsvc-proto xz-utils\n",
      "0 upgraded, 107 newly installed, 0 to remove and 0 not upgraded.\n",
      "Need to get 98.3 MB of archives.\n",
      "After this operation, 389 MB of additional disk space will be used.\n",
      "Get:1 http://deb.debian.org/debian bookworm/main amd64 perl-modules-5.36 all 5.36.0-7+deb12u1 [2815 kB]\n",
      "Get:2 http://deb.debian.org/debian bookworm/main amd64 libgdbm-compat4 amd64 1.23-3 [48.2 kB]\n",
      "Get:3 http://deb.debian.org/debian bookworm/main amd64 libperl5.36 amd64 5.36.0-7+deb12u1 [4218 kB]\n",
      "Get:4 http://deb.debian.org/debian bookworm/main amd64 perl amd64 5.36.0-7+deb12u1 [239 kB]\n",
      "Get:5 http://deb.debian.org/debian bookworm/main amd64 liblocale-gettext-perl amd64 1.07-5 [15.4 kB]\n",
      "Get:6 http://deb.debian.org/debian bookworm/main amd64 bzip2 amd64 1.0.8-5+b1 [49.8 kB]\n",
      "Get:7 http://deb.debian.org/debian bookworm/main amd64 manpages all 6.03-2 [1332 kB]\n",
      "Get:8 http://deb.debian.org/debian bookworm/main amd64 xz-utils amd64 5.4.1-0.2 [471 kB]\n",
      "Get:9 http://deb.debian.org/debian bookworm/main amd64 binutils-common amd64 2.40-2 [2487 kB]\n",
      "Get:10 http://deb.debian.org/debian bookworm/main amd64 libbinutils amd64 2.40-2 [572 kB]\n",
      "Get:11 http://deb.debian.org/debian bookworm/main amd64 libctf-nobfd0 amd64 2.40-2 [153 kB]\n",
      "Get:12 http://deb.debian.org/debian bookworm/main amd64 libctf0 amd64 2.40-2 [89.8 kB]\n",
      "Get:13 http://deb.debian.org/debian bookworm/main amd64 libgprofng0 amd64 2.40-2 [812 kB]\n",
      "Get:14 http://deb.debian.org/debian bookworm/main amd64 libjansson4 amd64 2.14-2 [40.8 kB]\n",
      "Get:15 http://deb.debian.org/debian bookworm/main amd64 binutils-x86-64-linux-gnu amd64 2.40-2 [2246 kB]\n",
      "Get:16 http://deb.debian.org/debian bookworm/main amd64 binutils amd64 2.40-2 [65.0 kB]\n",
      "Get:17 http://deb.debian.org/debian-security bookworm-security/main amd64 libc-dev-bin amd64 2.36-9+deb12u7 [45.8 kB]\n",
      "Get:18 http://deb.debian.org/debian-security bookworm-security/main amd64 linux-libc-dev amd64 6.1.90-1 [1976 kB]\n",
      "Get:19 http://deb.debian.org/debian bookworm/main amd64 libcrypt-dev amd64 1:4.4.33-2 [118 kB]\n",
      "Get:20 http://deb.debian.org/debian bookworm/main amd64 libtirpc-dev amd64 1.3.3+ds-1 [191 kB]\n",
      "Get:21 http://deb.debian.org/debian bookworm/main amd64 libnsl-dev amd64 1.3.0-2 [66.4 kB]\n",
      "Get:22 http://deb.debian.org/debian bookworm/main amd64 rpcsvc-proto amd64 1.4.3-1 [63.3 kB]\n",
      "Get:23 http://deb.debian.org/debian-security bookworm-security/main amd64 libc6-dev amd64 2.36-9+deb12u7 [1899 kB]\n",
      "Get:24 http://deb.debian.org/debian bookworm/main amd64 libisl23 amd64 0.25-1.1 [683 kB]\n",
      "Get:25 http://deb.debian.org/debian bookworm/main amd64 libmpfr6 amd64 4.2.0-1 [701 kB]\n",
      "Get:26 http://deb.debian.org/debian bookworm/main amd64 libmpc3 amd64 1.3.1-1 [51.5 kB]\n",
      "Get:27 http://deb.debian.org/debian bookworm/main amd64 cpp-12 amd64 12.2.0-14 [9764 kB]\n",
      "Get:28 http://deb.debian.org/debian bookworm/main amd64 cpp amd64 4:12.2.0-3 [6836 B]\n",
      "Get:29 http://deb.debian.org/debian bookworm/main amd64 libcc1-0 amd64 12.2.0-14 [41.7 kB]\n",
      "Get:30 http://deb.debian.org/debian bookworm/main amd64 libgomp1 amd64 12.2.0-14 [116 kB]\n",
      "Get:31 http://deb.debian.org/debian bookworm/main amd64 libitm1 amd64 12.2.0-14 [26.1 kB]\n",
      "Get:32 http://deb.debian.org/debian bookworm/main amd64 libatomic1 amd64 12.2.0-14 [9328 B]\n",
      "Get:33 http://deb.debian.org/debian bookworm/main amd64 libasan8 amd64 12.2.0-14 [2195 kB]\n",
      "Get:34 http://deb.debian.org/debian bookworm/main amd64 liblsan0 amd64 12.2.0-14 [969 kB]\n",
      "Get:35 http://deb.debian.org/debian bookworm/main amd64 libtsan2 amd64 12.2.0-14 [2196 kB]\n",
      "Get:36 http://deb.debian.org/debian bookworm/main amd64 libubsan1 amd64 12.2.0-14 [883 kB]\n",
      "Get:37 http://deb.debian.org/debian bookworm/main amd64 libquadmath0 amd64 12.2.0-14 [144 kB]\n",
      "Get:38 http://deb.debian.org/debian bookworm/main amd64 libgcc-12-dev amd64 12.2.0-14 [2437 kB]\n",
      "Get:39 http://deb.debian.org/debian bookworm/main amd64 gcc-12 amd64 12.2.0-14 [19.3 MB]\n",
      "Get:40 http://deb.debian.org/debian bookworm/main amd64 gcc amd64 4:12.2.0-3 [5216 B]\n",
      "Get:41 http://deb.debian.org/debian bookworm/main amd64 libstdc++-12-dev amd64 12.2.0-14 [2046 kB]\n",
      "Get:42 http://deb.debian.org/debian bookworm/main amd64 g++-12 amd64 12.2.0-14 [10.7 MB]\n",
      "Get:43 http://deb.debian.org/debian bookworm/main amd64 g++ amd64 4:12.2.0-3 [1356 B]\n",
      "Get:44 http://deb.debian.org/debian bookworm/main amd64 make amd64 4.3-4.1 [396 kB]\n",
      "Get:45 http://deb.debian.org/debian bookworm/main amd64 libdpkg-perl all 1.21.22 [603 kB]\n",
      "Get:46 http://deb.debian.org/debian bookworm/main amd64 patch amd64 2.7.6-7 [128 kB]\n",
      "Get:47 http://deb.debian.org/debian bookworm/main amd64 dpkg-dev all 1.21.22 [1353 kB]\n",
      "Get:48 http://deb.debian.org/debian bookworm/main amd64 build-essential amd64 12.9 [7704 B]\n",
      "Get:49 http://deb.debian.org/debian bookworm/main amd64 libassuan0 amd64 2.5.5-5 [48.5 kB]\n",
      "Get:50 http://deb.debian.org/debian bookworm/main amd64 gpgconf amd64 2.2.40-1.1 [564 kB]\n",
      "Get:51 http://deb.debian.org/debian bookworm/main amd64 libksba8 amd64 1.6.3-2 [128 kB]\n",
      "Get:52 http://deb.debian.org/debian bookworm/main amd64 libsasl2-modules-db amd64 2.1.28+dfsg-10 [20.3 kB]\n",
      "Get:53 http://deb.debian.org/debian bookworm/main amd64 libsasl2-2 amd64 2.1.28+dfsg-10 [59.7 kB]\n",
      "Get:54 http://deb.debian.org/debian bookworm/main amd64 libldap-2.5-0 amd64 2.5.13+dfsg-5 [183 kB]\n",
      "Get:55 http://deb.debian.org/debian bookworm/main amd64 libnpth0 amd64 1.6-3 [19.0 kB]\n",
      "Get:56 http://deb.debian.org/debian bookworm/main amd64 dirmngr amd64 2.2.40-1.1 [792 kB]\n",
      "Get:57 http://deb.debian.org/debian bookworm/main amd64 libfakeroot amd64 1.31-1.2 [28.3 kB]\n",
      "Get:58 http://deb.debian.org/debian bookworm/main amd64 fakeroot amd64 1.31-1.2 [66.9 kB]\n",
      "Get:59 http://deb.debian.org/debian bookworm/main amd64 fonts-dejavu-core all 2.37-6 [1068 kB]\n",
      "Get:60 http://deb.debian.org/debian bookworm/main amd64 fontconfig-config amd64 2.14.1-4 [315 kB]\n",
      "Get:61 http://deb.debian.org/debian bookworm/main amd64 gnupg-l10n all 2.2.40-1.1 [1093 kB]\n",
      "Get:62 http://deb.debian.org/debian bookworm/main amd64 gnupg-utils amd64 2.2.40-1.1 [927 kB]\n",
      "Get:63 http://deb.debian.org/debian bookworm/main amd64 gpg amd64 2.2.40-1.1 [949 kB]\n",
      "Get:64 http://deb.debian.org/debian bookworm/main amd64 pinentry-curses amd64 1.2.1-1 [77.4 kB]\n",
      "Get:65 http://deb.debian.org/debian bookworm/main amd64 gpg-agent amd64 2.2.40-1.1 [695 kB]\n",
      "Get:66 http://deb.debian.org/debian bookworm/main amd64 gpg-wks-client amd64 2.2.40-1.1 [541 kB]\n",
      "Get:67 http://deb.debian.org/debian bookworm/main amd64 gpg-wks-server amd64 2.2.40-1.1 [531 kB]\n",
      "Get:68 http://deb.debian.org/debian bookworm/main amd64 gpgsm amd64 2.2.40-1.1 [671 kB]\n",
      "Get:69 http://deb.debian.org/debian bookworm/main amd64 gnupg all 2.2.40-1.1 [846 kB]\n",
      "Get:70 http://deb.debian.org/debian bookworm/main amd64 libabsl20220623 amd64 20220623.1-1 [391 kB]\n",
      "Get:71 http://deb.debian.org/debian bookworm/main amd64 libalgorithm-diff-perl all 1.201-1 [43.3 kB]\n",
      "Get:72 http://deb.debian.org/debian bookworm/main amd64 libalgorithm-diff-xs-perl amd64 0.04-8+b1 [11.4 kB]\n",
      "Get:73 http://deb.debian.org/debian bookworm/main amd64 libalgorithm-merge-perl all 0.08-5 [11.8 kB]\n",
      "Get:74 http://deb.debian.org/debian bookworm/main amd64 libaom3 amd64 3.6.0-1 [1851 kB]\n",
      "Get:75 http://deb.debian.org/debian-security bookworm-security/main amd64 libdav1d6 amd64 1.0.0-2+deb12u1 [513 kB]\n",
      "Get:76 http://deb.debian.org/debian bookworm/main amd64 libgav1-1 amd64 0.18.0-1+b1 [332 kB]\n",
      "Get:77 http://deb.debian.org/debian bookworm/main amd64 librav1e0 amd64 0.5.1-6 [763 kB]\n",
      "Get:78 http://deb.debian.org/debian bookworm/main amd64 libsvtav1enc1 amd64 1.4.1+dfsg-1 [2121 kB]\n",
      "Get:79 http://deb.debian.org/debian bookworm/main amd64 libjpeg62-turbo amd64 1:2.1.5-2 [166 kB]\n",
      "Get:80 http://deb.debian.org/debian bookworm/main amd64 libyuv0 amd64 0.0~git20230123.b2528b0-1 [168 kB]\n",
      "Get:81 http://deb.debian.org/debian bookworm/main amd64 libavif15 amd64 0.11.1-1 [93.8 kB]\n",
      "Get:82 http://deb.debian.org/debian bookworm/main amd64 libbrotli1 amd64 1.0.9-2+b6 [275 kB]\n",
      "Get:83 http://deb.debian.org/debian bookworm/main amd64 libbsd0 amd64 0.11.7-2 [117 kB]\n",
      "Get:84 http://deb.debian.org/debian bookworm/main amd64 libpng16-16 amd64 1.6.39-2 [276 kB]\n",
      "Get:85 http://deb.debian.org/debian bookworm/main amd64 libfreetype6 amd64 2.12.1+dfsg-5 [399 kB]\n",
      "Get:86 http://deb.debian.org/debian bookworm/main amd64 libfontconfig1 amd64 2.14.1-4 [386 kB]\n",
      "Get:87 http://deb.debian.org/debian bookworm/main amd64 libde265-0 amd64 1.0.11-1+deb12u2 [185 kB]\n",
      "Get:88 http://deb.debian.org/debian bookworm/main amd64 libnuma1 amd64 2.0.16-1 [21.0 kB]\n",
      "Get:89 http://deb.debian.org/debian bookworm/main amd64 libx265-199 amd64 3.5-2+b1 [1150 kB]\n",
      "Get:90 http://deb.debian.org/debian bookworm/main amd64 libheif1 amd64 1.15.1-1 [215 kB]\n",
      "Get:91 http://deb.debian.org/debian bookworm/main amd64 libdeflate0 amd64 1.14-1 [61.4 kB]\n",
      "Get:92 http://deb.debian.org/debian bookworm/main amd64 libjbig0 amd64 2.1-6.1 [31.7 kB]\n",
      "Get:93 http://deb.debian.org/debian bookworm/main amd64 liblerc4 amd64 4.0.0+ds-2 [170 kB]\n",
      "Get:94 http://deb.debian.org/debian bookworm/main amd64 libwebp7 amd64 1.2.4-0.2+deb12u1 [286 kB]\n",
      "Get:95 http://deb.debian.org/debian bookworm/main amd64 libtiff6 amd64 4.5.0-6+deb12u1 [316 kB]\n",
      "Get:96 http://deb.debian.org/debian bookworm/main amd64 libxau6 amd64 1:1.0.9-1 [19.7 kB]\n",
      "Get:97 http://deb.debian.org/debian bookworm/main amd64 libxdmcp6 amd64 1:1.1.2-3 [26.3 kB]\n",
      "Get:98 http://deb.debian.org/debian bookworm/main amd64 libxcb1 amd64 1.15-1 [144 kB]\n",
      "Get:99 http://deb.debian.org/debian bookworm/main amd64 libx11-data all 2:1.8.4-2+deb12u2 [292 kB]\n",
      "Get:100 http://deb.debian.org/debian bookworm/main amd64 libx11-6 amd64 2:1.8.4-2+deb12u2 [760 kB]\n",
      "Get:101 http://deb.debian.org/debian bookworm/main amd64 libxpm4 amd64 1:3.5.12-1.1+deb12u1 [48.6 kB]\n",
      "Get:102 http://deb.debian.org/debian bookworm/main amd64 libgd3 amd64 2.3.3-9 [124 kB]\n",
      "Get:103 http://deb.debian.org/debian-security bookworm-security/main amd64 libc-devtools amd64 2.36-9+deb12u7 [53.4 kB]\n",
      "Get:104 http://deb.debian.org/debian bookworm/main amd64 libfile-fcntllock-perl amd64 0.22-4+b1 [34.8 kB]\n",
      "Get:105 http://deb.debian.org/debian bookworm/main amd64 libldap-common all 2.5.13+dfsg-5 [29.3 kB]\n",
      "Get:106 http://deb.debian.org/debian bookworm/main amd64 libsasl2-modules amd64 2.1.28+dfsg-10 [66.6 kB]\n",
      "Get:107 http://deb.debian.org/debian bookworm/main amd64 manpages-dev all 6.03-2 [2030 kB]\n",
      "\u001b[91mdebconf: delaying package configuration, since apt-utils is not installed\n",
      "\u001b[0mFetched 98.3 MB in 2s (50.4 MB/s)\n",
      "Selecting previously unselected package perl-modules-5.36.\n",
      "(Reading database ... 6697 files and directories currently installed.)\n",
      "Preparing to unpack .../000-perl-modules-5.36_5.36.0-7+deb12u1_all.deb ...\n",
      "Unpacking perl-modules-5.36 (5.36.0-7+deb12u1) ...\n",
      "Selecting previously unselected package libgdbm-compat4:amd64.\n",
      "Preparing to unpack .../001-libgdbm-compat4_1.23-3_amd64.deb ...\n",
      "Unpacking libgdbm-compat4:amd64 (1.23-3) ...\n",
      "Selecting previously unselected package libperl5.36:amd64.\n",
      "Preparing to unpack .../002-libperl5.36_5.36.0-7+deb12u1_amd64.deb ...\n",
      "Unpacking libperl5.36:amd64 (5.36.0-7+deb12u1) ...\n",
      "Selecting previously unselected package perl.\n",
      "Preparing to unpack .../003-perl_5.36.0-7+deb12u1_amd64.deb ...\n",
      "Unpacking perl (5.36.0-7+deb12u1) ...\n",
      "Selecting previously unselected package liblocale-gettext-perl.\n",
      "Preparing to unpack .../004-liblocale-gettext-perl_1.07-5_amd64.deb ...\n",
      "Unpacking liblocale-gettext-perl (1.07-5) ...\n",
      "Selecting previously unselected package bzip2.\n",
      "Preparing to unpack .../005-bzip2_1.0.8-5+b1_amd64.deb ...\n",
      "Unpacking bzip2 (1.0.8-5+b1) ...\n",
      "Selecting previously unselected package manpages.\n",
      "Preparing to unpack .../006-manpages_6.03-2_all.deb ...\n",
      "Unpacking manpages (6.03-2) ...\n",
      "Selecting previously unselected package xz-utils.\n",
      "Preparing to unpack .../007-xz-utils_5.4.1-0.2_amd64.deb ...\n",
      "Unpacking xz-utils (5.4.1-0.2) ...\n",
      "Selecting previously unselected package binutils-common:amd64.\n",
      "Preparing to unpack .../008-binutils-common_2.40-2_amd64.deb ...\n",
      "Unpacking binutils-common:amd64 (2.40-2) ...\n",
      "Selecting previously unselected package libbinutils:amd64.\n",
      "Preparing to unpack .../009-libbinutils_2.40-2_amd64.deb ...\n",
      "Unpacking libbinutils:amd64 (2.40-2) ...\n",
      "Selecting previously unselected package libctf-nobfd0:amd64.\n",
      "Preparing to unpack .../010-libctf-nobfd0_2.40-2_amd64.deb ...\n",
      "Unpacking libctf-nobfd0:amd64 (2.40-2) ...\n",
      "Selecting previously unselected package libctf0:amd64.\n",
      "Preparing to unpack .../011-libctf0_2.40-2_amd64.deb ...\n",
      "Unpacking libctf0:amd64 (2.40-2) ...\n",
      "Selecting previously unselected package libgprofng0:amd64.\n",
      "Preparing to unpack .../012-libgprofng0_2.40-2_amd64.deb ...\n",
      "Unpacking libgprofng0:amd64 (2.40-2) ...\n",
      "Selecting previously unselected package libjansson4:amd64.\n",
      "Preparing to unpack .../013-libjansson4_2.14-2_amd64.deb ...\n",
      "Unpacking libjansson4:amd64 (2.14-2) ...\n",
      "Selecting previously unselected package binutils-x86-64-linux-gnu.\n",
      "Preparing to unpack .../014-binutils-x86-64-linux-gnu_2.40-2_amd64.deb ...\n",
      "Unpacking binutils-x86-64-linux-gnu (2.40-2) ...\n",
      "Selecting previously unselected package binutils.\n",
      "Preparing to unpack .../015-binutils_2.40-2_amd64.deb ...\n",
      "Unpacking binutils (2.40-2) ...\n",
      "Selecting previously unselected package libc-dev-bin.\n",
      "Preparing to unpack .../016-libc-dev-bin_2.36-9+deb12u7_amd64.deb ...\n",
      "Unpacking libc-dev-bin (2.36-9+deb12u7) ...\n",
      "Selecting previously unselected package linux-libc-dev:amd64.\n",
      "Preparing to unpack .../017-linux-libc-dev_6.1.90-1_amd64.deb ...\n",
      "Unpacking linux-libc-dev:amd64 (6.1.90-1) ...\n",
      "Selecting previously unselected package libcrypt-dev:amd64.\n",
      "Preparing to unpack .../018-libcrypt-dev_1%3a4.4.33-2_amd64.deb ...\n",
      "Unpacking libcrypt-dev:amd64 (1:4.4.33-2) ...\n",
      "Selecting previously unselected package libtirpc-dev:amd64.\n",
      "Preparing to unpack .../019-libtirpc-dev_1.3.3+ds-1_amd64.deb ...\n",
      "Unpacking libtirpc-dev:amd64 (1.3.3+ds-1) ...\n",
      "Selecting previously unselected package libnsl-dev:amd64.\n",
      "Preparing to unpack .../020-libnsl-dev_1.3.0-2_amd64.deb ...\n",
      "Unpacking libnsl-dev:amd64 (1.3.0-2) ...\n",
      "Selecting previously unselected package rpcsvc-proto.\n",
      "Preparing to unpack .../021-rpcsvc-proto_1.4.3-1_amd64.deb ...\n",
      "Unpacking rpcsvc-proto (1.4.3-1) ...\n",
      "Selecting previously unselected package libc6-dev:amd64.\n",
      "Preparing to unpack .../022-libc6-dev_2.36-9+deb12u7_amd64.deb ...\n",
      "Unpacking libc6-dev:amd64 (2.36-9+deb12u7) ...\n",
      "Selecting previously unselected package libisl23:amd64.\n",
      "Preparing to unpack .../023-libisl23_0.25-1.1_amd64.deb ...\n",
      "Unpacking libisl23:amd64 (0.25-1.1) ...\n",
      "Selecting previously unselected package libmpfr6:amd64.\n",
      "Preparing to unpack .../024-libmpfr6_4.2.0-1_amd64.deb ...\n",
      "Unpacking libmpfr6:amd64 (4.2.0-1) ...\n",
      "Selecting previously unselected package libmpc3:amd64.\n",
      "Preparing to unpack .../025-libmpc3_1.3.1-1_amd64.deb ...\n",
      "Unpacking libmpc3:amd64 (1.3.1-1) ...\n",
      "Selecting previously unselected package cpp-12.\n",
      "Preparing to unpack .../026-cpp-12_12.2.0-14_amd64.deb ...\n",
      "Unpacking cpp-12 (12.2.0-14) ...\n",
      "Selecting previously unselected package cpp.\n",
      "Preparing to unpack .../027-cpp_4%3a12.2.0-3_amd64.deb ...\n",
      "Unpacking cpp (4:12.2.0-3) ...\n",
      "Selecting previously unselected package libcc1-0:amd64.\n",
      "Preparing to unpack .../028-libcc1-0_12.2.0-14_amd64.deb ...\n",
      "Unpacking libcc1-0:amd64 (12.2.0-14) ...\n",
      "Selecting previously unselected package libgomp1:amd64.\n",
      "Preparing to unpack .../029-libgomp1_12.2.0-14_amd64.deb ...\n",
      "Unpacking libgomp1:amd64 (12.2.0-14) ...\n",
      "Selecting previously unselected package libitm1:amd64.\n",
      "Preparing to unpack .../030-libitm1_12.2.0-14_amd64.deb ...\n",
      "Unpacking libitm1:amd64 (12.2.0-14) ...\n",
      "Selecting previously unselected package libatomic1:amd64.\n",
      "Preparing to unpack .../031-libatomic1_12.2.0-14_amd64.deb ...\n",
      "Unpacking libatomic1:amd64 (12.2.0-14) ...\n",
      "Selecting previously unselected package libasan8:amd64.\n",
      "Preparing to unpack .../032-libasan8_12.2.0-14_amd64.deb ...\n",
      "Unpacking libasan8:amd64 (12.2.0-14) ...\n",
      "Selecting previously unselected package liblsan0:amd64.\n",
      "Preparing to unpack .../033-liblsan0_12.2.0-14_amd64.deb ...\n",
      "Unpacking liblsan0:amd64 (12.2.0-14) ...\n",
      "Selecting previously unselected package libtsan2:amd64.\n",
      "Preparing to unpack .../034-libtsan2_12.2.0-14_amd64.deb ...\n",
      "Unpacking libtsan2:amd64 (12.2.0-14) ...\n",
      "Selecting previously unselected package libubsan1:amd64.\n",
      "Preparing to unpack .../035-libubsan1_12.2.0-14_amd64.deb ...\n",
      "Unpacking libubsan1:amd64 (12.2.0-14) ...\n",
      "Selecting previously unselected package libquadmath0:amd64.\n",
      "Preparing to unpack .../036-libquadmath0_12.2.0-14_amd64.deb ...\n",
      "Unpacking libquadmath0:amd64 (12.2.0-14) ...\n",
      "Selecting previously unselected package libgcc-12-dev:amd64.\n",
      "Preparing to unpack .../037-libgcc-12-dev_12.2.0-14_amd64.deb ...\n",
      "Unpacking libgcc-12-dev:amd64 (12.2.0-14) ...\n",
      "Selecting previously unselected package gcc-12.\n",
      "Preparing to unpack .../038-gcc-12_12.2.0-14_amd64.deb ...\n",
      "Unpacking gcc-12 (12.2.0-14) ...\n",
      "Selecting previously unselected package gcc.\n",
      "Preparing to unpack .../039-gcc_4%3a12.2.0-3_amd64.deb ...\n",
      "Unpacking gcc (4:12.2.0-3) ...\n",
      "Selecting previously unselected package libstdc++-12-dev:amd64.\n",
      "Preparing to unpack .../040-libstdc++-12-dev_12.2.0-14_amd64.deb ...\n",
      "Unpacking libstdc++-12-dev:amd64 (12.2.0-14) ...\n",
      "Selecting previously unselected package g++-12.\n",
      "Preparing to unpack .../041-g++-12_12.2.0-14_amd64.deb ...\n",
      "Unpacking g++-12 (12.2.0-14) ...\n",
      "Selecting previously unselected package g++.\n",
      "Preparing to unpack .../042-g++_4%3a12.2.0-3_amd64.deb ...\n",
      "Unpacking g++ (4:12.2.0-3) ...\n",
      "Selecting previously unselected package make.\n",
      "Preparing to unpack .../043-make_4.3-4.1_amd64.deb ...\n",
      "Unpacking make (4.3-4.1) ...\n",
      "Selecting previously unselected package libdpkg-perl.\n",
      "Preparing to unpack .../044-libdpkg-perl_1.21.22_all.deb ...\n",
      "Unpacking libdpkg-perl (1.21.22) ...\n",
      "Selecting previously unselected package patch.\n",
      "Preparing to unpack .../045-patch_2.7.6-7_amd64.deb ...\n",
      "Unpacking patch (2.7.6-7) ...\n",
      "Selecting previously unselected package dpkg-dev.\n",
      "Preparing to unpack .../046-dpkg-dev_1.21.22_all.deb ...\n",
      "Unpacking dpkg-dev (1.21.22) ...\n",
      "Selecting previously unselected package build-essential.\n",
      "Preparing to unpack .../047-build-essential_12.9_amd64.deb ...\n",
      "Unpacking build-essential (12.9) ...\n",
      "Selecting previously unselected package libassuan0:amd64.\n",
      "Preparing to unpack .../048-libassuan0_2.5.5-5_amd64.deb ...\n",
      "Unpacking libassuan0:amd64 (2.5.5-5) ...\n",
      "Selecting previously unselected package gpgconf.\n",
      "Preparing to unpack .../049-gpgconf_2.2.40-1.1_amd64.deb ...\n",
      "Unpacking gpgconf (2.2.40-1.1) ...\n",
      "Selecting previously unselected package libksba8:amd64.\n",
      "Preparing to unpack .../050-libksba8_1.6.3-2_amd64.deb ...\n",
      "Unpacking libksba8:amd64 (1.6.3-2) ...\n",
      "Selecting previously unselected package libsasl2-modules-db:amd64.\n",
      "Preparing to unpack .../051-libsasl2-modules-db_2.1.28+dfsg-10_amd64.deb ...\n",
      "Unpacking libsasl2-modules-db:amd64 (2.1.28+dfsg-10) ...\n",
      "Selecting previously unselected package libsasl2-2:amd64.\n",
      "Preparing to unpack .../052-libsasl2-2_2.1.28+dfsg-10_amd64.deb ...\n",
      "Unpacking libsasl2-2:amd64 (2.1.28+dfsg-10) ...\n",
      "Selecting previously unselected package libldap-2.5-0:amd64.\n",
      "Preparing to unpack .../053-libldap-2.5-0_2.5.13+dfsg-5_amd64.deb ...\n",
      "Unpacking libldap-2.5-0:amd64 (2.5.13+dfsg-5) ...\n",
      "Selecting previously unselected package libnpth0:amd64.\n",
      "Preparing to unpack .../054-libnpth0_1.6-3_amd64.deb ...\n",
      "Unpacking libnpth0:amd64 (1.6-3) ...\n",
      "Selecting previously unselected package dirmngr.\n",
      "Preparing to unpack .../055-dirmngr_2.2.40-1.1_amd64.deb ...\n",
      "Unpacking dirmngr (2.2.40-1.1) ...\n",
      "Selecting previously unselected package libfakeroot:amd64.\n",
      "Preparing to unpack .../056-libfakeroot_1.31-1.2_amd64.deb ...\n",
      "Unpacking libfakeroot:amd64 (1.31-1.2) ...\n",
      "Selecting previously unselected package fakeroot.\n",
      "Preparing to unpack .../057-fakeroot_1.31-1.2_amd64.deb ...\n",
      "Unpacking fakeroot (1.31-1.2) ...\n",
      "Selecting previously unselected package fonts-dejavu-core.\n",
      "Preparing to unpack .../058-fonts-dejavu-core_2.37-6_all.deb ...\n",
      "Unpacking fonts-dejavu-core (2.37-6) ...\n",
      "Selecting previously unselected package fontconfig-config.\n",
      "Preparing to unpack .../059-fontconfig-config_2.14.1-4_amd64.deb ...\n",
      "Unpacking fontconfig-config (2.14.1-4) ...\n",
      "Selecting previously unselected package gnupg-l10n.\n",
      "Preparing to unpack .../060-gnupg-l10n_2.2.40-1.1_all.deb ...\n",
      "Unpacking gnupg-l10n (2.2.40-1.1) ...\n",
      "Selecting previously unselected package gnupg-utils.\n",
      "Preparing to unpack .../061-gnupg-utils_2.2.40-1.1_amd64.deb ...\n",
      "Unpacking gnupg-utils (2.2.40-1.1) ...\n",
      "Selecting previously unselected package gpg.\n",
      "Preparing to unpack .../062-gpg_2.2.40-1.1_amd64.deb ...\n",
      "Unpacking gpg (2.2.40-1.1) ...\n",
      "Selecting previously unselected package pinentry-curses.\n",
      "Preparing to unpack .../063-pinentry-curses_1.2.1-1_amd64.deb ...\n",
      "Unpacking pinentry-curses (1.2.1-1) ...\n",
      "Selecting previously unselected package gpg-agent.\n",
      "Preparing to unpack .../064-gpg-agent_2.2.40-1.1_amd64.deb ...\n",
      "Unpacking gpg-agent (2.2.40-1.1) ...\n",
      "Selecting previously unselected package gpg-wks-client.\n",
      "Preparing to unpack .../065-gpg-wks-client_2.2.40-1.1_amd64.deb ...\n",
      "Unpacking gpg-wks-client (2.2.40-1.1) ...\n",
      "Selecting previously unselected package gpg-wks-server.\n",
      "Preparing to unpack .../066-gpg-wks-server_2.2.40-1.1_amd64.deb ...\n",
      "Unpacking gpg-wks-server (2.2.40-1.1) ...\n",
      "Selecting previously unselected package gpgsm.\n",
      "Preparing to unpack .../067-gpgsm_2.2.40-1.1_amd64.deb ...\n",
      "Unpacking gpgsm (2.2.40-1.1) ...\n",
      "Selecting previously unselected package gnupg.\n",
      "Preparing to unpack .../068-gnupg_2.2.40-1.1_all.deb ...\n",
      "Unpacking gnupg (2.2.40-1.1) ...\n",
      "Selecting previously unselected package libabsl20220623:amd64.\n",
      "Preparing to unpack .../069-libabsl20220623_20220623.1-1_amd64.deb ...\n",
      "Unpacking libabsl20220623:amd64 (20220623.1-1) ...\n",
      "Selecting previously unselected package libalgorithm-diff-perl.\n",
      "Preparing to unpack .../070-libalgorithm-diff-perl_1.201-1_all.deb ...\n",
      "Unpacking libalgorithm-diff-perl (1.201-1) ...\n",
      "Selecting previously unselected package libalgorithm-diff-xs-perl:amd64.\n",
      "Preparing to unpack .../071-libalgorithm-diff-xs-perl_0.04-8+b1_amd64.deb ...\n",
      "Unpacking libalgorithm-diff-xs-perl:amd64 (0.04-8+b1) ...\n",
      "Selecting previously unselected package libalgorithm-merge-perl.\n",
      "Preparing to unpack .../072-libalgorithm-merge-perl_0.08-5_all.deb ...\n",
      "Unpacking libalgorithm-merge-perl (0.08-5) ...\n",
      "Selecting previously unselected package libaom3:amd64.\n",
      "Preparing to unpack .../073-libaom3_3.6.0-1_amd64.deb ...\n",
      "Unpacking libaom3:amd64 (3.6.0-1) ...\n",
      "Selecting previously unselected package libdav1d6:amd64.\n",
      "Preparing to unpack .../074-libdav1d6_1.0.0-2+deb12u1_amd64.deb ...\n",
      "Unpacking libdav1d6:amd64 (1.0.0-2+deb12u1) ...\n",
      "Selecting previously unselected package libgav1-1:amd64.\n",
      "Preparing to unpack .../075-libgav1-1_0.18.0-1+b1_amd64.deb ...\n",
      "Unpacking libgav1-1:amd64 (0.18.0-1+b1) ...\n",
      "Selecting previously unselected package librav1e0:amd64.\n",
      "Preparing to unpack .../076-librav1e0_0.5.1-6_amd64.deb ...\n",
      "Unpacking librav1e0:amd64 (0.5.1-6) ...\n",
      "Selecting previously unselected package libsvtav1enc1:amd64.\n",
      "Preparing to unpack .../077-libsvtav1enc1_1.4.1+dfsg-1_amd64.deb ...\n",
      "Unpacking libsvtav1enc1:amd64 (1.4.1+dfsg-1) ...\n",
      "Selecting previously unselected package libjpeg62-turbo:amd64.\n",
      "Preparing to unpack .../078-libjpeg62-turbo_1%3a2.1.5-2_amd64.deb ...\n",
      "Unpacking libjpeg62-turbo:amd64 (1:2.1.5-2) ...\n",
      "Selecting previously unselected package libyuv0:amd64.\n",
      "Preparing to unpack .../079-libyuv0_0.0~git20230123.b2528b0-1_amd64.deb ...\n",
      "Unpacking libyuv0:amd64 (0.0~git20230123.b2528b0-1) ...\n",
      "Selecting previously unselected package libavif15:amd64.\n",
      "Preparing to unpack .../080-libavif15_0.11.1-1_amd64.deb ...\n",
      "Unpacking libavif15:amd64 (0.11.1-1) ...\n",
      "Selecting previously unselected package libbrotli1:amd64.\n",
      "Preparing to unpack .../081-libbrotli1_1.0.9-2+b6_amd64.deb ...\n",
      "Unpacking libbrotli1:amd64 (1.0.9-2+b6) ...\n",
      "Selecting previously unselected package libbsd0:amd64.\n",
      "Preparing to unpack .../082-libbsd0_0.11.7-2_amd64.deb ...\n",
      "Unpacking libbsd0:amd64 (0.11.7-2) ...\n",
      "Selecting previously unselected package libpng16-16:amd64.\n",
      "Preparing to unpack .../083-libpng16-16_1.6.39-2_amd64.deb ...\n",
      "Unpacking libpng16-16:amd64 (1.6.39-2) ...\n",
      "Selecting previously unselected package libfreetype6:amd64.\n",
      "Preparing to unpack .../084-libfreetype6_2.12.1+dfsg-5_amd64.deb ...\n",
      "Unpacking libfreetype6:amd64 (2.12.1+dfsg-5) ...\n",
      "Selecting previously unselected package libfontconfig1:amd64.\n",
      "Preparing to unpack .../085-libfontconfig1_2.14.1-4_amd64.deb ...\n",
      "Unpacking libfontconfig1:amd64 (2.14.1-4) ...\n",
      "Selecting previously unselected package libde265-0:amd64.\n",
      "Preparing to unpack .../086-libde265-0_1.0.11-1+deb12u2_amd64.deb ...\n",
      "Unpacking libde265-0:amd64 (1.0.11-1+deb12u2) ...\n",
      "Selecting previously unselected package libnuma1:amd64.\n",
      "Preparing to unpack .../087-libnuma1_2.0.16-1_amd64.deb ...\n",
      "Unpacking libnuma1:amd64 (2.0.16-1) ...\n",
      "Selecting previously unselected package libx265-199:amd64.\n",
      "Preparing to unpack .../088-libx265-199_3.5-2+b1_amd64.deb ...\n",
      "Unpacking libx265-199:amd64 (3.5-2+b1) ...\n",
      "Selecting previously unselected package libheif1:amd64.\n",
      "Preparing to unpack .../089-libheif1_1.15.1-1_amd64.deb ...\n",
      "Unpacking libheif1:amd64 (1.15.1-1) ...\n",
      "Selecting previously unselected package libdeflate0:amd64.\n",
      "Preparing to unpack .../090-libdeflate0_1.14-1_amd64.deb ...\n",
      "Unpacking libdeflate0:amd64 (1.14-1) ...\n",
      "Selecting previously unselected package libjbig0:amd64.\n",
      "Preparing to unpack .../091-libjbig0_2.1-6.1_amd64.deb ...\n",
      "Unpacking libjbig0:amd64 (2.1-6.1) ...\n",
      "Selecting previously unselected package liblerc4:amd64.\n",
      "Preparing to unpack .../092-liblerc4_4.0.0+ds-2_amd64.deb ...\n",
      "Unpacking liblerc4:amd64 (4.0.0+ds-2) ...\n",
      "Selecting previously unselected package libwebp7:amd64.\n",
      "Preparing to unpack .../093-libwebp7_1.2.4-0.2+deb12u1_amd64.deb ...\n",
      "Unpacking libwebp7:amd64 (1.2.4-0.2+deb12u1) ...\n",
      "Selecting previously unselected package libtiff6:amd64.\n",
      "Preparing to unpack .../094-libtiff6_4.5.0-6+deb12u1_amd64.deb ...\n",
      "Unpacking libtiff6:amd64 (4.5.0-6+deb12u1) ...\n",
      "Selecting previously unselected package libxau6:amd64.\n",
      "Preparing to unpack .../095-libxau6_1%3a1.0.9-1_amd64.deb ...\n",
      "Unpacking libxau6:amd64 (1:1.0.9-1) ...\n",
      "Selecting previously unselected package libxdmcp6:amd64.\n",
      "Preparing to unpack .../096-libxdmcp6_1%3a1.1.2-3_amd64.deb ...\n",
      "Unpacking libxdmcp6:amd64 (1:1.1.2-3) ...\n",
      "Selecting previously unselected package libxcb1:amd64.\n",
      "Preparing to unpack .../097-libxcb1_1.15-1_amd64.deb ...\n",
      "Unpacking libxcb1:amd64 (1.15-1) ...\n",
      "Selecting previously unselected package libx11-data.\n",
      "Preparing to unpack .../098-libx11-data_2%3a1.8.4-2+deb12u2_all.deb ...\n",
      "Unpacking libx11-data (2:1.8.4-2+deb12u2) ...\n",
      "Selecting previously unselected package libx11-6:amd64.\n",
      "Preparing to unpack .../099-libx11-6_2%3a1.8.4-2+deb12u2_amd64.deb ...\n",
      "Unpacking libx11-6:amd64 (2:1.8.4-2+deb12u2) ...\n",
      "Selecting previously unselected package libxpm4:amd64.\n",
      "Preparing to unpack .../100-libxpm4_1%3a3.5.12-1.1+deb12u1_amd64.deb ...\n",
      "Unpacking libxpm4:amd64 (1:3.5.12-1.1+deb12u1) ...\n",
      "Selecting previously unselected package libgd3:amd64.\n",
      "Preparing to unpack .../101-libgd3_2.3.3-9_amd64.deb ...\n",
      "Unpacking libgd3:amd64 (2.3.3-9) ...\n",
      "Selecting previously unselected package libc-devtools.\n",
      "Preparing to unpack .../102-libc-devtools_2.36-9+deb12u7_amd64.deb ...\n",
      "Unpacking libc-devtools (2.36-9+deb12u7) ...\n",
      "Selecting previously unselected package libfile-fcntllock-perl.\n",
      "Preparing to unpack .../103-libfile-fcntllock-perl_0.22-4+b1_amd64.deb ...\n",
      "Unpacking libfile-fcntllock-perl (0.22-4+b1) ...\n",
      "Selecting previously unselected package libldap-common.\n",
      "Preparing to unpack .../104-libldap-common_2.5.13+dfsg-5_all.deb ...\n",
      "Unpacking libldap-common (2.5.13+dfsg-5) ...\n",
      "Selecting previously unselected package libsasl2-modules:amd64.\n",
      "Preparing to unpack .../105-libsasl2-modules_2.1.28+dfsg-10_amd64.deb ...\n",
      "Unpacking libsasl2-modules:amd64 (2.1.28+dfsg-10) ...\n",
      "Selecting previously unselected package manpages-dev.\n",
      "Preparing to unpack .../106-manpages-dev_6.03-2_all.deb ...\n",
      "Unpacking manpages-dev (6.03-2) ...\n",
      "Setting up libksba8:amd64 (1.6.3-2) ...\n",
      "Setting up libaom3:amd64 (3.6.0-1) ...\n",
      "Setting up libabsl20220623:amd64 (20220623.1-1) ...\n",
      "Setting up libxau6:amd64 (1:1.0.9-1) ...\n",
      "Setting up liblerc4:amd64 (4.0.0+ds-2) ...\n",
      "Setting up manpages (6.03-2) ...\n",
      "Setting up libbrotli1:amd64 (1.0.9-2+b6) ...\n",
      "Setting up libsasl2-modules:amd64 (2.1.28+dfsg-10) ...\n",
      "Setting up binutils-common:amd64 (2.40-2) ...\n",
      "Setting up libdeflate0:amd64 (1.14-1) ...\n",
      "Setting up linux-libc-dev:amd64 (6.1.90-1) ...\n",
      "Setting up libctf-nobfd0:amd64 (2.40-2) ...\n",
      "Setting up libnpth0:amd64 (1.6-3) ...\n",
      "Setting up libsvtav1enc1:amd64 (1.4.1+dfsg-1) ...\n",
      "Setting up libassuan0:amd64 (2.5.5-5) ...\n",
      "Setting up libgomp1:amd64 (12.2.0-14) ...\n",
      "Setting up bzip2 (1.0.8-5+b1) ...\n",
      "Setting up libldap-common (2.5.13+dfsg-5) ...\n",
      "Setting up libjbig0:amd64 (2.1-6.1) ...\n",
      "Setting up librav1e0:amd64 (0.5.1-6) ...\n",
      "Setting up libfakeroot:amd64 (1.31-1.2) ...\n",
      "Setting up libjansson4:amd64 (2.14-2) ...\n",
      "Setting up libsasl2-modules-db:amd64 (2.1.28+dfsg-10) ...\n",
      "Setting up fakeroot (1.31-1.2) ...\n",
      "update-alternatives: using /usr/bin/fakeroot-sysv to provide /usr/bin/fakeroot (fakeroot) in auto mode\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/fakeroot.1.gz because associated file /usr/share/man/man1/fakeroot-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/faked.1.gz because associated file /usr/share/man/man1/faked-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/es/man1/fakeroot.1.gz because associated file /usr/share/man/es/man1/fakeroot-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/es/man1/faked.1.gz because associated file /usr/share/man/es/man1/faked-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/fr/man1/fakeroot.1.gz because associated file /usr/share/man/fr/man1/fakeroot-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/fr/man1/faked.1.gz because associated file /usr/share/man/fr/man1/faked-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/sv/man1/fakeroot.1.gz because associated file /usr/share/man/sv/man1/fakeroot-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/sv/man1/faked.1.gz because associated file /usr/share/man/sv/man1/faked-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "Setting up perl-modules-5.36 (5.36.0-7+deb12u1) ...\n",
      "Setting up libtirpc-dev:amd64 (1.3.3+ds-1) ...\n",
      "Setting up rpcsvc-proto (1.4.3-1) ...\n",
      "Setting up libjpeg62-turbo:amd64 (1:2.1.5-2) ...\n",
      "Setting up libx11-data (2:1.8.4-2+deb12u2) ...\n",
      "Setting up make (4.3-4.1) ...\n",
      "Setting up libmpfr6:amd64 (4.2.0-1) ...\n",
      "Setting up gnupg-l10n (2.2.40-1.1) ...\n",
      "Setting up xz-utils (5.4.1-0.2) ...\n",
      "update-alternatives: using /usr/bin/xz to provide /usr/bin/lzma (lzma) in auto mode\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzma.1.gz because associated file /usr/share/man/man1/xz.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/unlzma.1.gz because associated file /usr/share/man/man1/unxz.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzcat.1.gz because associated file /usr/share/man/man1/xzcat.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzmore.1.gz because associated file /usr/share/man/man1/xzmore.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzless.1.gz because associated file /usr/share/man/man1/xzless.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzdiff.1.gz because associated file /usr/share/man/man1/xzdiff.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzcmp.1.gz because associated file /usr/share/man/man1/xzcmp.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzgrep.1.gz because associated file /usr/share/man/man1/xzgrep.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzegrep.1.gz because associated file /usr/share/man/man1/xzegrep.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzfgrep.1.gz because associated file /usr/share/man/man1/xzfgrep.1.gz (of link group lzma) doesn't exist\n",
      "Setting up libquadmath0:amd64 (12.2.0-14) ...\n",
      "Setting up libpng16-16:amd64 (1.6.39-2) ...\n",
      "Setting up libmpc3:amd64 (1.3.1-1) ...\n",
      "Setting up libatomic1:amd64 (12.2.0-14) ...\n",
      "Setting up patch (2.7.6-7) ...\n",
      "Setting up fonts-dejavu-core (2.37-6) ...\n",
      "Setting up libgdbm-compat4:amd64 (1.23-3) ...\n",
      "Setting up libgav1-1:amd64 (0.18.0-1+b1) ...\n",
      "Setting up libdav1d6:amd64 (1.0.0-2+deb12u1) ...\n",
      "Setting up libsasl2-2:amd64 (2.1.28+dfsg-10) ...\n",
      "Setting up libwebp7:amd64 (1.2.4-0.2+deb12u1) ...\n",
      "Setting up libubsan1:amd64 (12.2.0-14) ...\n",
      "Setting up libnuma1:amd64 (2.0.16-1) ...\n",
      "Setting up libnsl-dev:amd64 (1.3.0-2) ...\n",
      "Setting up libcrypt-dev:amd64 (1:4.4.33-2) ...\n",
      "Setting up libtiff6:amd64 (4.5.0-6+deb12u1) ...\n",
      "Setting up libasan8:amd64 (12.2.0-14) ...\n",
      "Setting up gpgconf (2.2.40-1.1) ...\n",
      "Setting up libtsan2:amd64 (12.2.0-14) ...\n",
      "Setting up libbinutils:amd64 (2.40-2) ...\n",
      "Setting up libisl23:amd64 (0.25-1.1) ...\n",
      "Setting up libde265-0:amd64 (1.0.11-1+deb12u2) ...\n",
      "Setting up libc-dev-bin (2.36-9+deb12u7) ...\n",
      "Setting up libbsd0:amd64 (0.11.7-2) ...\n",
      "Setting up libyuv0:amd64 (0.0~git20230123.b2528b0-1) ...\n",
      "Setting up libcc1-0:amd64 (12.2.0-14) ...\n",
      "Setting up libperl5.36:amd64 (5.36.0-7+deb12u1) ...\n",
      "Setting up liblocale-gettext-perl (1.07-5) ...\n",
      "Setting up gpg (2.2.40-1.1) ...\n",
      "Setting up liblsan0:amd64 (12.2.0-14) ...\n",
      "Setting up libitm1:amd64 (12.2.0-14) ...\n",
      "Setting up gnupg-utils (2.2.40-1.1) ...\n",
      "Setting up libctf0:amd64 (2.40-2) ...\n",
      "Setting up pinentry-curses (1.2.1-1) ...\n",
      "Setting up manpages-dev (6.03-2) ...\n",
      "Setting up libxdmcp6:amd64 (1:1.1.2-3) ...\n",
      "Setting up cpp-12 (12.2.0-14) ...\n",
      "Setting up libxcb1:amd64 (1.15-1) ...\n",
      "Setting up gpg-agent (2.2.40-1.1) ...\n",
      "Setting up libavif15:amd64 (0.11.1-1) ...\n",
      "Setting up fontconfig-config (2.14.1-4) ...\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (TERM is not set, so the dialog frontend is not usable.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "Setting up gpgsm (2.2.40-1.1) ...\n",
      "Setting up libldap-2.5-0:amd64 (2.5.13+dfsg-5) ...\n",
      "Setting up dirmngr (2.2.40-1.1) ...\n",
      "Setting up perl (5.36.0-7+deb12u1) ...\n",
      "Setting up libgprofng0:amd64 (2.40-2) ...\n",
      "Setting up libfreetype6:amd64 (2.12.1+dfsg-5) ...\n",
      "Setting up libgcc-12-dev:amd64 (12.2.0-14) ...\n",
      "Setting up libdpkg-perl (1.21.22) ...\n",
      "Setting up libx265-199:amd64 (3.5-2+b1) ...\n",
      "Setting up gpg-wks-server (2.2.40-1.1) ...\n",
      "Setting up cpp (4:12.2.0-3) ...\n",
      "Setting up libc6-dev:amd64 (2.36-9+deb12u7) ...\n",
      "Setting up libx11-6:amd64 (2:1.8.4-2+deb12u2) ...\n",
      "Setting up libfontconfig1:amd64 (2.14.1-4) ...\n",
      "Setting up binutils-x86-64-linux-gnu (2.40-2) ...\n",
      "Setting up libxpm4:amd64 (1:3.5.12-1.1+deb12u1) ...\n",
      "Setting up gpg-wks-client (2.2.40-1.1) ...\n",
      "Setting up libstdc++-12-dev:amd64 (12.2.0-14) ...\n",
      "Setting up libfile-fcntllock-perl (0.22-4+b1) ...\n",
      "Setting up libalgorithm-diff-perl (1.201-1) ...\n",
      "Setting up libheif1:amd64 (1.15.1-1) ...\n",
      "Setting up binutils (2.40-2) ...\n",
      "Setting up dpkg-dev (1.21.22) ...\n",
      "Setting up gcc-12 (12.2.0-14) ...\n",
      "Setting up libgd3:amd64 (2.3.3-9) ...\n",
      "Setting up gnupg (2.2.40-1.1) ...\n",
      "Setting up libalgorithm-diff-xs-perl:amd64 (0.04-8+b1) ...\n",
      "Setting up libc-devtools (2.36-9+deb12u7) ...\n",
      "Setting up libalgorithm-merge-perl (0.08-5) ...\n",
      "Setting up g++-12 (12.2.0-14) ...\n",
      "Setting up gcc (4:12.2.0-3) ...\n",
      "Setting up g++ (4:12.2.0-3) ...\n",
      "update-alternatives: using /usr/bin/g++ to provide /usr/bin/c++ (c++) in auto mode\n",
      "Setting up build-essential (12.9) ...\n",
      "Processing triggers for libc-bin (2.36-9+deb12u7) ...\n",
      "Removing intermediate container a40bd41874d4\n",
      " ---> 22e3c695a0fd\n",
      "Step 3/7 : RUN pip install --upgrade pip\n",
      " ---> Running in 346217a8806a\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.10/site-packages (23.0.1)\n",
      "Collecting pip\n",
      "  Downloading pip-24.1.1-py3-none-any.whl (1.8 MB)\n",
      "      1.8/1.8 MB 7.9 MB/s eta 0:00:00\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.0.1\n",
      "    Uninstalling pip-23.0.1:\n",
      "      Successfully uninstalled pip-23.0.1\n",
      "Successfully installed pip-24.1.1\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container 346217a8806a\n",
      " ---> 682b64206a8e\n",
      "Step 4/7 : COPY requirements.txt  requirements.txt\n",
      " ---> d77ba441d6bc\n",
      "Step 5/7 : RUN pip install -r requirements.txt\n",
      " ---> Running in d857acae7924\n",
      "Collecting absl-py==1.4.0 (from -r requirements.txt (line 1))\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting aiofiles==22.1.0 (from -r requirements.txt (line 2))\n",
      "  Downloading aiofiles-22.1.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting aiohttp==3.9.5 (from -r requirements.txt (line 3))\n",
      "  Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting aiohttp-cors==0.7.0 (from -r requirements.txt (line 4))\n",
      "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting aiosignal==1.3.1 (from -r requirements.txt (line 5))\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting aiosqlite (from -r requirements.txt (line 6))\n",
      "  Downloading aiosqlite-0.20.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting ansicolors==1.1.8 (from -r requirements.txt (line 7))\n",
      "  Downloading ansicolors-1.1.8-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting apache-beam==2.56.0 (from -r requirements.txt (line 8))\n",
      "  Downloading apache_beam-2.56.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting appdirs==1.4.4 (from -r requirements.txt (line 9))\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting astunparse==1.6.3 (from -r requirements.txt (line 10))\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting async-timeout==4.0.3 (from -r requirements.txt (line 11))\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting atpublic==4.1.0 (from -r requirements.txt (line 12))\n",
      "  Downloading atpublic-4.1.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting Babel==2.15.0 (from -r requirements.txt (line 13))\n",
      "  Downloading Babel-2.15.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backcall==0.2.0 (from -r requirements.txt (line 14))\n",
      "  Downloading backcall-0.2.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting backports.tarfile==1.2.0 (from -r requirements.txt (line 15))\n",
      "  Downloading backports.tarfile-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting bidict==0.23.1 (from -r requirements.txt (line 16))\n",
      "  Downloading bidict-0.23.1-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting bigframes==0.22.0 (from -r requirements.txt (line 17))\n",
      "  Downloading bigframes-0.22.0-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting blessed==1.20.0 (from -r requirements.txt (line 18))\n",
      "  Downloading blessed-1.20.0-py2.py3-none-any.whl.metadata (13 kB)\n",
      "Collecting brotlipy==0.7.0 (from -r requirements.txt (line 19))\n",
      "  Downloading brotlipy-0.7.0-cp35-abi3-manylinux2010_x86_64.whl.metadata (2.9 kB)\n",
      "Collecting cachetools==5.3.3 (from -r requirements.txt (line 20))\n",
      "  Downloading cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting click==8.1.7 (from -r requirements.txt (line 21))\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting click-plugins==1.1.1 (from -r requirements.txt (line 22))\n",
      "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting cligj==0.7.2 (from -r requirements.txt (line 23))\n",
      "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting cloudpickle==2.2.1 (from -r requirements.txt (line 24))\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting colorful==0.5.6 (from -r requirements.txt (line 25))\n",
      "  Downloading colorful-0.5.6-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting contourpy==1.2.1 (from -r requirements.txt (line 26))\n",
      "  Downloading contourpy-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting crcmod==1.7 (from -r requirements.txt (line 27))\n",
      "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
      "      89.7/89.7 kB 1.5 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting cycler==0.12.1 (from -r requirements.txt (line 28))\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting Cython==3.0.10 (from -r requirements.txt (line 29))\n",
      "  Downloading Cython-3.0.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
      "Collecting dacite==1.8.1 (from -r requirements.txt (line 30))\n",
      "  Downloading dacite-1.8.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting dataproc_jupyter_plugin==0.1.79 (from -r requirements.txt (line 31))\n",
      "  Downloading dataproc_jupyter_plugin-0.1.79-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting db-dtypes==1.2.0 (from -r requirements.txt (line 32))\n",
      "  Downloading db_dtypes-1.2.0-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting Deprecated==1.2.14 (from -r requirements.txt (line 33))\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting dill==0.3.1.1 (from -r requirements.txt (line 34))\n",
      "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
      "      152.0/152.0 kB 3.1 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting distlib==0.3.8 (from -r requirements.txt (line 35))\n",
      "  Downloading distlib-0.3.8-py2.py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting dm-tree==0.1.8 (from -r requirements.txt (line 36))\n",
      "  Downloading dm_tree-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
      "Collecting dnspython==2.6.1 (from -r requirements.txt (line 37))\n",
      "  Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting docker==4.4.4 (from -r requirements.txt (line 38))\n",
      "  Downloading docker-4.4.4-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting docopt==0.6.2 (from -r requirements.txt (line 39))\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting docstring_parser==0.16 (from -r requirements.txt (line 40))\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting email_validator==2.1.1 (from -r requirements.txt (line 41))\n",
      "  Downloading email_validator-2.1.1-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting Farama-Notifications==0.0.4 (from -r requirements.txt (line 42))\n",
      "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
      "Collecting fastavro==1.9.4 (from -r requirements.txt (line 43))\n",
      "  Downloading fastavro-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting fasteners==0.19 (from -r requirements.txt (line 44))\n",
      "  Downloading fasteners-0.19-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting filelock==3.15.1 (from -r requirements.txt (line 45))\n",
      "  Downloading filelock-3.15.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting fiona==1.9.6 (from -r requirements.txt (line 46))\n",
      "  Downloading fiona-1.9.6-cp310-cp310-manylinux2014_x86_64.whl.metadata (50 kB)\n",
      "      50.2/50.2 kB 4.4 MB/s eta 0:00:00\n",
      "Collecting flatbuffers==24.3.25 (from -r requirements.txt (line 47))\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting fonttools==4.53.0 (from -r requirements.txt (line 48))\n",
      "  Downloading fonttools-4.53.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (162 kB)\n",
      "      162.2/162.2 kB 8.7 MB/s eta 0:00:00\n",
      "Collecting frozenlist==1.4.1 (from -r requirements.txt (line 49))\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting fsspec==2024.6.0 (from -r requirements.txt (line 50))\n",
      "  Downloading fsspec-2024.6.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting gast==0.4.0 (from -r requirements.txt (line 51))\n",
      "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting gcsfs==2024.6.0 (from -r requirements.txt (line 52))\n",
      "  Downloading gcsfs-2024.6.0-py2.py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting geopandas==0.14.4 (from -r requirements.txt (line 53))\n",
      "  Downloading geopandas-0.14.4-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting gitdb==4.0.11 (from -r requirements.txt (line 54))\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting GitPython==3.1.43 (from -r requirements.txt (line 55))\n",
      "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting google-api-core==2.19.0 (from -r requirements.txt (line 56))\n",
      "  Downloading google_api_core-2.19.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-api-python-client==1.12.11 (from -r requirements.txt (line 57))\n",
      "  Downloading google_api_python_client-1.12.11-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting google-apitools==0.5.31 (from -r requirements.txt (line 58))\n",
      "  Downloading google-apitools-0.5.31.tar.gz (173 kB)\n",
      "      173.5/173.5 kB 11.3 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting google-auth==2.30.0 (from -r requirements.txt (line 59))\n",
      "  Downloading google_auth-2.30.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth-httplib2==0.2.0 (from -r requirements.txt (line 60))\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-auth-oauthlib==1.0.0 (from -r requirements.txt (line 61))\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-cloud-aiplatform==1.55.0 (from -r requirements.txt (line 62))\n",
      "  Downloading google_cloud_aiplatform-1.55.0-py2.py3-none-any.whl.metadata (31 kB)\n",
      "Collecting google-cloud-artifact-registry==1.11.3 (from -r requirements.txt (line 63))\n",
      "  Downloading google_cloud_artifact_registry-1.11.3-py2.py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting google-cloud-bigquery==3.24.0 (from -r requirements.txt (line 64))\n",
      "  Downloading google_cloud_bigquery-3.24.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting google-cloud-bigquery-connection==1.15.3 (from -r requirements.txt (line 65))\n",
      "  Downloading google_cloud_bigquery_connection-1.15.3-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting google-cloud-bigquery-storage==2.25.0 (from -r requirements.txt (line 66))\n",
      "  Downloading google_cloud_bigquery_storage-2.25.0-py2.py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting google-cloud-bigtable==2.24.0 (from -r requirements.txt (line 67))\n",
      "  Downloading google_cloud_bigtable-2.24.0-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting google-cloud-core==2.4.1 (from -r requirements.txt (line 68))\n",
      "  Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-cloud-datastore==2.19.0 (from -r requirements.txt (line 69))\n",
      "  Downloading google_cloud_datastore-2.19.0-py2.py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting google-cloud-dlp==3.18.0 (from -r requirements.txt (line 70))\n",
      "  Downloading google_cloud_dlp-3.18.0-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting google-cloud-functions==1.16.3 (from -r requirements.txt (line 71))\n",
      "  Downloading google_cloud_functions-1.16.3-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting google-cloud-iam==2.15.0 (from -r requirements.txt (line 72))\n",
      "  Downloading google_cloud_iam-2.15.0-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting google-cloud-jupyter-config==0.0.10 (from -r requirements.txt (line 73))\n",
      "  Downloading google_cloud_jupyter_config-0.0.10.tar.gz (9.7 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting google-cloud-language==2.13.3 (from -r requirements.txt (line 74))\n",
      "  Downloading google_cloud_language-2.13.3-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting google-cloud-monitoring==2.21.0 (from -r requirements.txt (line 75))\n",
      "  Downloading google_cloud_monitoring-2.21.0-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-cloud-pubsub==2.21.5 (from -r requirements.txt (line 76))\n",
      "  Downloading google_cloud_pubsub-2.21.5-py2.py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting google-cloud-pubsublite==1.10.0 (from -r requirements.txt (line 77))\n",
      "  Downloading google_cloud_pubsublite-1.10.0-py2.py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting google-cloud-recommendations-ai==0.10.10 (from -r requirements.txt (line 78))\n",
      "  Downloading google_cloud_recommendations_ai-0.10.10-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting google-cloud-resource-manager==1.12.3 (from -r requirements.txt (line 79))\n",
      "  Downloading google_cloud_resource_manager-1.12.3-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting google-cloud-spanner==3.47.0 (from -r requirements.txt (line 80))\n",
      "  Downloading google_cloud_spanner-3.47.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting google-cloud-storage==2.14.0 (from -r requirements.txt (line 81))\n",
      "  Downloading google_cloud_storage-2.14.0-py2.py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting google-cloud-videointelligence==2.13.3 (from -r requirements.txt (line 82))\n",
      "  Downloading google_cloud_videointelligence-2.13.3-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-cloud-vision==3.7.2 (from -r requirements.txt (line 83))\n",
      "  Downloading google_cloud_vision-3.7.2-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting google-crc32c==1.5.0 (from -r requirements.txt (line 84))\n",
      "  Downloading google_crc32c-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
      "Collecting google-pasta==0.2.0 (from -r requirements.txt (line 85))\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting google-resumable-media==2.7.1 (from -r requirements.txt (line 86))\n",
      "  Downloading google_resumable_media-2.7.1-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting googleapis-common-protos==1.63.1 (from -r requirements.txt (line 87))\n",
      "  Downloading googleapis_common_protos-1.63.1-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting gpustat==1.0.0 (from -r requirements.txt (line 88))\n",
      "  Downloading gpustat-1.0.0.tar.gz (90 kB)\n",
      "      90.5/90.5 kB 7.4 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting greenlet==3.0.3 (from -r requirements.txt (line 89))\n",
      "  Downloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting grpc-google-iam-v1==0.13.0 (from -r requirements.txt (line 90))\n",
      "  Downloading grpc_google_iam_v1-0.13.0-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting grpc-interceptor==0.15.4 (from -r requirements.txt (line 91))\n",
      "  Downloading grpc_interceptor-0.15.4-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting grpcio==1.64.1 (from -r requirements.txt (line 92))\n",
      "  Downloading grpcio-1.64.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting grpcio-status==1.48.2 (from -r requirements.txt (line 93))\n",
      "  Downloading grpcio_status-1.48.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting gviz-api==1.10.0 (from -r requirements.txt (line 94))\n",
      "  Downloading gviz_api-1.10.0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting gymnasium==0.28.1 (from -r requirements.txt (line 95))\n",
      "  Downloading gymnasium-0.28.1-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting h11==0.14.0 (from -r requirements.txt (line 96))\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting h5py==3.11.0 (from -r requirements.txt (line 97))\n",
      "  Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting hdfs==2.7.3 (from -r requirements.txt (line 98))\n",
      "  Downloading hdfs-2.7.3.tar.gz (43 kB)\n",
      "      43.5/43.5 kB 4.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting htmlmin==0.1.12 (from -r requirements.txt (line 99))\n",
      "  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting httpcore==1.0.5 (from -r requirements.txt (line 100))\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting httplib2==0.22.0 (from -r requirements.txt (line 101))\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting httptools==0.6.1 (from -r requirements.txt (line 102))\n",
      "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting httpx==0.27.0 (from -r requirements.txt (line 103))\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting humanize==4.9.0 (from -r requirements.txt (line 104))\n",
      "  Downloading humanize-4.9.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting hypertune==1.1.0 (from -r requirements.txt (line 105))\n",
      "  Downloading hypertune-1.1.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting ibis-framework==7.1.0 (from -r requirements.txt (line 106))\n",
      "  Downloading ibis_framework-7.1.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting ImageHash==4.3.1 (from -r requirements.txt (line 107))\n",
      "  Downloading ImageHash-4.3.1-py2.py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting imageio==2.34.1 (from -r requirements.txt (line 108))\n",
      "  Downloading imageio-2.34.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting iniconfig==2.0.0 (from -r requirements.txt (line 109))\n",
      "  Downloading iniconfig-2.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting jaraco.classes==3.4.0 (from -r requirements.txt (line 110))\n",
      "  Downloading jaraco.classes-3.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting jaraco.context==5.3.0 (from -r requirements.txt (line 111))\n",
      "  Downloading jaraco.context-5.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting jaraco.functools==4.0.1 (from -r requirements.txt (line 112))\n",
      "  Downloading jaraco.functools-4.0.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting jax-jumpy==1.0.0 (from -r requirements.txt (line 113))\n",
      "  Downloading jax_jumpy-1.0.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting jeepney==0.8.0 (from -r requirements.txt (line 114))\n",
      "  Downloading jeepney-0.8.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting joblib==1.4.2 (from -r requirements.txt (line 115))\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting Js2Py==0.74 (from -r requirements.txt (line 116))\n",
      "  Downloading Js2Py-0.74-py3-none-any.whl.metadata (868 bytes)\n",
      "Collecting json5==0.9.25 (from -r requirements.txt (line 117))\n",
      "  Downloading json5-0.9.25-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting jsonpickle==3.2.2 (from -r requirements.txt (line 118))\n",
      "  Downloading jsonpickle-3.2.2-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting jupyter-http-over-ws==0.0.8 (from -r requirements.txt (line 119))\n",
      "  Downloading jupyter_http_over_ws-0.0.8-py2.py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting jupyter-server-mathjax==0.2.6 (from -r requirements.txt (line 120))\n",
      "  Downloading jupyter_server_mathjax-0.2.6-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting jupyter-ydoc==0.2.5 (from -r requirements.txt (line 121))\n",
      "  Downloading jupyter_ydoc-0.2.5-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting jupyter_server_fileid==0.9.2 (from -r requirements.txt (line 122))\n",
      "  Downloading jupyter_server_fileid-0.9.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting jupyter_server_proxy==4.2.0 (from -r requirements.txt (line 123))\n",
      "  Downloading jupyter_server_proxy-4.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting jupyter_server_ydoc==0.8.0 (from -r requirements.txt (line 124))\n",
      "  Downloading jupyter_server_ydoc-0.8.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting jupyterlab_git==0.44.0 (from -r requirements.txt (line 125))\n",
      "  Downloading jupyterlab_git-0.44.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting jupyterlab_server==2.27.2 (from -r requirements.txt (line 126))\n",
      "  Downloading jupyterlab_server-2.27.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting jupyterlab_widgets==3.0.11 (from -r requirements.txt (line 127))\n",
      "  Downloading jupyterlab_widgets-3.0.11-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting jupytext==1.16.2 (from -r requirements.txt (line 128))\n",
      "  Downloading jupytext-1.16.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting keras (from -r requirements.txt (line 129))\n",
      "  Downloading keras-3.4.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting keras-tuner (from -r requirements.txt (line 130))\n",
      "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting kernels-mixer (from -r requirements.txt (line 131))\n",
      "  Downloading kernels_mixer-0.0.13.tar.gz (13 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting keyring==25.2.1 (from -r requirements.txt (line 132))\n",
      "  Downloading keyring-25.2.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting keyrings.google-artifactregistry-auth==1.1.2 (from -r requirements.txt (line 133))\n",
      "  Downloading keyrings.google_artifactregistry_auth-1.1.2-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting kfp==2.5.0 (from -r requirements.txt (line 134))\n",
      "  Downloading kfp-2.5.0.tar.gz (425 kB)\n",
      "      425.4/425.4 kB 8.3 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting kfp-pipeline-spec==0.2.2 (from -r requirements.txt (line 135))\n",
      "  Downloading kfp_pipeline_spec-0.2.2-py3-none-any.whl.metadata (295 bytes)\n",
      "Collecting kfp-server-api==2.0.5 (from -r requirements.txt (line 136))\n",
      "  Downloading kfp-server-api-2.0.5.tar.gz (63 kB)\n",
      "      63.4/63.4 kB 6.0 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting kiwisolver==1.4.5 (from -r requirements.txt (line 137))\n",
      "  Downloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting kt-legacy==1.0.5 (from -r requirements.txt (line 138))\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
      "Collecting kubernetes==12.0.1 (from -r requirements.txt (line 139))\n",
      "  Downloading kubernetes-12.0.1-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting lazy_loader==0.4 (from -r requirements.txt (line 140))\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting libclang==18.1.1 (from -r requirements.txt (line 141))\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting linkify-it-py==2.0.3 (from -r requirements.txt (line 142))\n",
      "  Downloading linkify_it_py-2.0.3-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting llvmlite==0.41.1 (from -r requirements.txt (line 143))\n",
      "  Downloading llvmlite-0.41.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Collecting lxml==5.2.2 (from -r requirements.txt (line 144))\n",
      "  Downloading lxml-5.2.2-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting lz4==4.3.3 (from -r requirements.txt (line 145))\n",
      "  Downloading lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting Markdown==3.6 (from -r requirements.txt (line 146))\n",
      "  Downloading Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting markdown-it-py==3.0.0 (from -r requirements.txt (line 147))\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting matplotlib==3.7.3 (from -r requirements.txt (line 148))\n",
      "  Downloading matplotlib-3.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n",
      "Collecting mdit-py-plugins==0.4.1 (from -r requirements.txt (line 149))\n",
      "  Downloading mdit_py_plugins-0.4.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting mdurl==0.1.2 (from -r requirements.txt (line 150))\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting memray==1.12.0 (from -r requirements.txt (line 151))\n",
      "  Downloading memray-1.12.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (19 kB)\n",
      "Collecting ml-metadata==1.15.0 (from -r requirements.txt (line 152))\n",
      "  Downloading ml_metadata-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting ml-pipelines-sdk==1.15.1 (from -r requirements.txt (line 153))\n",
      "  Downloading ml_pipelines_sdk-1.15.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting more-itertools==10.3.0 (from -r requirements.txt (line 154))\n",
      "  Downloading more_itertools-10.3.0-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting msgpack==1.0.8 (from -r requirements.txt (line 155))\n",
      "  Downloading msgpack-1.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting multidict==6.0.5 (from -r requirements.txt (line 156))\n",
      "  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting multimethod==1.11.2 (from -r requirements.txt (line 157))\n",
      "  Downloading multimethod-1.11.2-py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting multipledispatch==1.0.0 (from -r requirements.txt (line 158))\n",
      "  Downloading multipledispatch-1.0.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting namex==0.0.8 (from -r requirements.txt (line 159))\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting nbdime==3.2.0 (from -r requirements.txt (line 160))\n",
      "  Downloading nbdime-3.2.0-py2.py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting networkx==3.3 (from -r requirements.txt (line 161))\n",
      "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting nltk==3.8.1 (from -r requirements.txt (line 162))\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting numba==0.58.1 (from -r requirements.txt (line 163))\n",
      "  Downloading numba-0.58.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting numpy==1.24.3 (from -r requirements.txt (line 164))\n",
      "  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.5.39 (from -r requirements.txt (line 165))\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.5.39-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-ml-py==11.495.46 (from -r requirements.txt (line 166))\n",
      "  Downloading nvidia_ml_py-11.495.46-py3-none-any.whl.metadata (776 bytes)\n",
      "Collecting oauth2client==4.1.3 (from -r requirements.txt (line 167))\n",
      "  Downloading oauth2client-4.1.3-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting oauthlib==3.2.2 (from -r requirements.txt (line 168))\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting objsize==0.7.0 (from -r requirements.txt (line 169))\n",
      "  Downloading objsize-0.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting opencensus==0.11.4 (from -r requirements.txt (line 170))\n",
      "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting opencensus-context==0.1.3 (from -r requirements.txt (line 171))\n",
      "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting opentelemetry-api==1.25.0 (from -r requirements.txt (line 172))\n",
      "  Downloading opentelemetry_api-1.25.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp==1.25.0 (from -r requirements.txt (line 173))\n",
      "  Downloading opentelemetry_exporter_otlp-1.25.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.25.0 (from -r requirements.txt (line 174))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.25.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc==1.25.0 (from -r requirements.txt (line 175))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http==1.25.0 (from -r requirements.txt (line 176))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_http-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-proto==1.25.0 (from -r requirements.txt (line 177))\n",
      "  Downloading opentelemetry_proto-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-sdk==1.25.0 (from -r requirements.txt (line 178))\n",
      "  Downloading opentelemetry_sdk-1.25.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.46b0 (from -r requirements.txt (line 179))\n",
      "  Downloading opentelemetry_semantic_conventions-0.46b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opt-einsum==3.3.0 (from -r requirements.txt (line 180))\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting optree==0.11.0 (from -r requirements.txt (line 181))\n",
      "  Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (45 kB)\n",
      "      45.4/45.4 kB 4.5 MB/s eta 0:00:00\n",
      "Collecting orjson==3.10.5 (from -r requirements.txt (line 182))\n",
      "  Downloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "      49.7/49.7 kB 4.7 MB/s eta 0:00:00\n",
      "Collecting pandas==1.5.3 (from -r requirements.txt (line 183))\n",
      "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting pandas-profiling==3.6.6 (from -r requirements.txt (line 184))\n",
      "  Downloading pandas_profiling-3.6.6-py2.py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting papermill==2.6.0 (from -r requirements.txt (line 185))\n",
      "  Downloading papermill-2.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting parsy==2.1 (from -r requirements.txt (line 186))\n",
      "  Downloading parsy-2.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting patsy==0.5.6 (from -r requirements.txt (line 187))\n",
      "  Downloading patsy-0.5.6-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting pendulum==3.0.0 (from -r requirements.txt (line 188))\n",
      "  Downloading pendulum-3.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
      "Collecting pillow==10.3.0 (from -r requirements.txt (line 189))\n",
      "  Downloading pillow-10.3.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting pins==0.8.6 (from -r requirements.txt (line 190))\n",
      "  Downloading pins-0.8.6-py2.py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting plotly==5.22.0 (from -r requirements.txt (line 191))\n",
      "  Downloading plotly-5.22.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting portalocker==2.10.0 (from -r requirements.txt (line 192))\n",
      "  Downloading portalocker-2.10.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting portpicker==1.6.0 (from -r requirements.txt (line 193))\n",
      "  Downloading portpicker-1.6.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting prettytable==3.10.0 (from -r requirements.txt (line 194))\n",
      "  Downloading prettytable-3.10.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting proto-plus==1.23.0 (from -r requirements.txt (line 195))\n",
      "  Downloading proto_plus-1.23.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf==3.20.3 (from -r requirements.txt (line 196))\n",
      "  Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (679 bytes)\n",
      "Collecting psutil==5.9.3 (from -r requirements.txt (line 197))\n",
      "  Downloading psutil-5.9.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Collecting py-spy==0.3.14 (from -r requirements.txt (line 198))\n",
      "  Downloading py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (16 kB)\n",
      "Collecting pyarrow==10.0.1 (from -r requirements.txt (line 199))\n",
      "  Downloading pyarrow-10.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting pyarrow-hotfix==0.6 (from -r requirements.txt (line 200))\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting pyasn1==0.6.0 (from -r requirements.txt (line 201))\n",
      "  Downloading pyasn1-0.6.0-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting pyasn1_modules==0.4.0 (from -r requirements.txt (line 202))\n",
      "  Downloading pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting pydantic==1.10.16 (from -r requirements.txt (line 203))\n",
      "  Downloading pydantic-1.10.16-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (151 kB)\n",
      "      151.1/151.1 kB 14.9 MB/s eta 0:00:00\n",
      "Collecting pydata-google-auth==1.8.2 (from -r requirements.txt (line 204))\n",
      "  Downloading pydata_google_auth-1.8.2-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pydot==1.4.2 (from -r requirements.txt (line 205))\n",
      "  Downloading pydot-1.4.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting pyfarmhash==0.3.2 (from -r requirements.txt (line 206))\n",
      "  Downloading pyfarmhash-0.3.2.tar.gz (99 kB)\n",
      "      99.9/99.9 kB 9.9 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pyjsparser==2.7.1 (from -r requirements.txt (line 207))\n",
      "  Downloading pyjsparser-2.7.1.tar.gz (24 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting PyJWT==2.8.0 (from -r requirements.txt (line 208))\n",
      "  Downloading PyJWT-2.8.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting pymongo==4.7.3 (from -r requirements.txt (line 209))\n",
      "  Downloading pymongo-4.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
      "Collecting pyparsing==3.1.2 (from -r requirements.txt (line 210))\n",
      "  Downloading pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting pyproj==3.6.1 (from -r requirements.txt (line 211))\n",
      "  Downloading pyproj-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting pytest==8.2.2 (from -r requirements.txt (line 212))\n",
      "  Downloading pytest-8.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting python-dotenv==1.0.1 (from -r requirements.txt (line 213))\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting python-multipart==0.0.9 (from -r requirements.txt (line 214))\n",
      "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pytz==2024.1 (from -r requirements.txt (line 215))\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting PyWavelets==1.6.0 (from -r requirements.txt (line 216))\n",
      "  Downloading pywavelets-1.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting ray==2.24.0 (from -r requirements.txt (line 217))\n",
      "  Downloading ray-2.24.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting ray-cpp==2.24.0 (from -r requirements.txt (line 218))\n",
      "  Downloading ray_cpp-2.24.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (6.0 kB)\n",
      "Collecting redis==5.0.6 (from -r requirements.txt (line 219))\n",
      "  Downloading redis-5.0.6-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting regex==2024.5.15 (from -r requirements.txt (line 220))\n",
      "  Downloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "      40.9/40.9 kB 4.4 MB/s eta 0:00:00\n",
      "Collecting requests-oauthlib==2.0.0 (from -r requirements.txt (line 221))\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting requests-toolbelt==0.10.1 (from -r requirements.txt (line 222))\n",
      "  Downloading requests_toolbelt-0.10.1-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting retrying==1.3.4 (from -r requirements.txt (line 223))\n",
      "  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting rich==13.7.1 (from -r requirements.txt (line 224))\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting rouge_score==0.1.2 (from -r requirements.txt (line 225))\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting rsa==4.9 (from -r requirements.txt (line 226))\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting sacrebleu==2.4.2 (from -r requirements.txt (line 227))\n",
      "  Downloading sacrebleu-2.4.2-py3-none-any.whl.metadata (58 kB)\n",
      "      58.0/58.0 kB 4.7 MB/s eta 0:00:00\n",
      "Collecting scikit-image==0.23.2 (from -r requirements.txt (line 228))\n",
      "  Downloading scikit_image-0.23.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Collecting scikit-learn==1.5.0 (from -r requirements.txt (line 229))\n",
      "  Downloading scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting scipy==1.11.4 (from -r requirements.txt (line 230))\n",
      "  Downloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "      60.4/60.4 kB 5.1 MB/s eta 0:00:00\n",
      "Collecting seaborn==0.12.2 (from -r requirements.txt (line 231))\n",
      "  Downloading seaborn-0.12.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting SecretStorage==3.3.3 (from -r requirements.txt (line 232))\n",
      "  Downloading SecretStorage-3.3.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting shapely==2.0.4 (from -r requirements.txt (line 233))\n",
      "  Downloading shapely-2.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting shellingham==1.5.4 (from -r requirements.txt (line 234))\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting simpervisor==1.0.0 (from -r requirements.txt (line 235))\n",
      "  Downloading simpervisor-1.0.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting smart-open==7.0.4 (from -r requirements.txt (line 236))\n",
      "  Downloading smart_open-7.0.4-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting smmap==5.0.1 (from -r requirements.txt (line 237))\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting SQLAlchemy==2.0.30 (from -r requirements.txt (line 238))\n",
      "  Downloading SQLAlchemy-2.0.30-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting sqlglot==19.9.0 (from -r requirements.txt (line 239))\n",
      "  Downloading sqlglot-19.9.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting sqlparse==0.5.0 (from -r requirements.txt (line 240))\n",
      "  Downloading sqlparse-0.5.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting starlette==0.37.2 (from -r requirements.txt (line 241))\n",
      "  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting statsmodels==0.14.2 (from -r requirements.txt (line 242))\n",
      "  Downloading statsmodels-0.14.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting struct2tensor (from -r requirements.txt (line 243))\n",
      "  Downloading struct2tensor-0.46.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting tabulate==0.9.0 (from -r requirements.txt (line 244))\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting tangled-up-in-unicode==0.2.0 (from -r requirements.txt (line 245))\n",
      "  Downloading tangled_up_in_unicode-0.2.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting tenacity==8.3.0 (from -r requirements.txt (line 246))\n",
      "  Downloading tenacity-8.3.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting tensorboard==2.15.2 (from -r requirements.txt (line 247))\n",
      "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting tensorboard-data-server==0.7.2 (from -r requirements.txt (line 248))\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting tensorboard_plugin_profile==2.15.1 (from -r requirements.txt (line 249))\n",
      "  Downloading tensorboard_plugin_profile-2.15.1-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting tensorboardX==2.6.2.2 (from -r requirements.txt (line 250))\n",
      "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting tensorflow==2.15.1 (from -r requirements.txt (line 251))\n",
      "  Downloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting tensorflow-data-validation (from -r requirements.txt (line 252))\n",
      "  Downloading tensorflow_data_validation-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting tensorflow-estimator==2.15.0 (from -r requirements.txt (line 253))\n",
      "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting tensorflow-hub==0.15.0 (from -r requirements.txt (line 254))\n",
      "  Downloading tensorflow_hub-0.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem==0.37.0 (from -r requirements.txt (line 255))\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Collecting tensorflow-metadata (from -r requirements.txt (line 256))\n",
      "  Downloading tensorflow_metadata-1.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting tensorflow-serving-api (from -r requirements.txt (line 257))\n",
      "  Downloading tensorflow_serving_api-2.16.1-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorflow-transform (from -r requirements.txt (line 258))\n",
      "  Downloading tensorflow_transform-1.15.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting tensorflow_model_analysis (from -r requirements.txt (line 259))\n",
      "  Downloading tensorflow_model_analysis-0.46.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting tensorrt==10.1.0 (from -r requirements.txt (line 260))\n",
      "  Downloading tensorrt-10.1.0.tar.gz (16 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting tensorrt-cu12==10.1.0 (from -r requirements.txt (line 261))\n",
      "  Downloading tensorrt-cu12-10.1.0.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting tensorrt-cu12-bindings==10.1.0 (from -r requirements.txt (line 262))\n",
      "  Downloading tensorrt_cu12_bindings-10.1.0-cp310-none-manylinux_2_17_x86_64.whl.metadata (627 bytes)\n",
      "Collecting tensorrt-cu12-libs==10.1.0 (from -r requirements.txt (line 263))\n",
      "  Downloading tensorrt_cu12_libs-10.1.0.tar.gz (630 bytes)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting termcolor==2.4.0 (from -r requirements.txt (line 264))\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting textual==0.67.1 (from -r requirements.txt (line 265))\n",
      "  Downloading textual-0.67.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting tf_keras (from -r requirements.txt (line 266))\n",
      "  Downloading tf_keras-2.16.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting tfx==1.15.1 (from -r requirements.txt (line 267))\n",
      "  Downloading tfx-1.15.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting tfx-bsl==1.15.1 (from -r requirements.txt (line 268))\n",
      "  Downloading tfx_bsl-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting threadpoolctl==3.5.0 (from -r requirements.txt (line 269))\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting tifffile==2024.5.22 (from -r requirements.txt (line 270))\n",
      "  Downloading tifffile-2024.5.22-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting time-machine==2.14.1 (from -r requirements.txt (line 271))\n",
      "  Downloading time_machine-2.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Collecting tomli==2.0.1 (from -r requirements.txt (line 272))\n",
      "  Downloading tomli-2.0.1-py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting toolz==0.12.1 (from -r requirements.txt (line 273))\n",
      "  Downloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting typeguard==4.3.0 (from -r requirements.txt (line 274))\n",
      "  Downloading typeguard-4.3.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting typer==0.12.3 (from -r requirements.txt (line 275))\n",
      "  Downloading typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting tzdata==2024.1 (from -r requirements.txt (line 276))\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting tzlocal==5.2 (from -r requirements.txt (line 277))\n",
      "  Downloading tzlocal-5.2-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting uc-micro-py==1.0.3 (from -r requirements.txt (line 278))\n",
      "  Downloading uc_micro_py-1.0.3-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting ujson==5.10.0 (from -r requirements.txt (line 279))\n",
      "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
      "Collecting uritemplate==3.0.1 (from -r requirements.txt (line 280))\n",
      "  Downloading uritemplate-3.0.1-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting urllib3==1.26.18 (from -r requirements.txt (line 281))\n",
      "  Downloading urllib3-1.26.18-py2.py3-none-any.whl.metadata (48 kB)\n",
      "      48.9/48.9 kB 3.7 MB/s eta 0:00:00\n",
      "Collecting uvicorn==0.30.1 (from -r requirements.txt (line 282))\n",
      "  Downloading uvicorn-0.30.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting uvloop==0.19.0 (from -r requirements.txt (line 283))\n",
      "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting virtualenv==20.26.2 (from -r requirements.txt (line 284))\n",
      "  Downloading virtualenv-20.26.2-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting visions==0.7.5 (from -r requirements.txt (line 285))\n",
      "  Downloading visions-0.7.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting watchfiles==0.22.0 (from -r requirements.txt (line 286))\n",
      "  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets==12.0 (from -r requirements.txt (line 287))\n",
      "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting Werkzeug==3.0.3 (from -r requirements.txt (line 288))\n",
      "  Downloading werkzeug-3.0.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting wordcloud==1.9.3 (from -r requirements.txt (line 289))\n",
      "  Downloading wordcloud-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting wrapt==1.14.1 (from -r requirements.txt (line 290))\n",
      "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting wurlitzer==3.1.1 (from -r requirements.txt (line 291))\n",
      "  Downloading wurlitzer-3.1.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting xxhash==3.4.1 (from -r requirements.txt (line 292))\n",
      "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting y-py==0.6.2 (from -r requirements.txt (line 293))\n",
      "  Downloading y_py-0.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting yarg==0.1.9 (from -r requirements.txt (line 294))\n",
      "  Downloading yarg-0.1.9-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting yarl==1.9.4 (from -r requirements.txt (line 295))\n",
      "  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting ydata-profiling==4.6.0 (from -r requirements.txt (line 296))\n",
      "  Downloading ydata_profiling-4.6.0-py2.py3-none-any.whl.metadata (20 kB)\n",
      "Collecting ydf==0.5.0 (from -r requirements.txt (line 297))\n",
      "  Downloading ydf-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting ypy-websocket==0.8.4 (from -r requirements.txt (line 298))\n",
      "  Downloading ypy_websocket-0.8.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting zstandard==0.22.0 (from -r requirements.txt (line 299))\n",
      "  Downloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp==3.9.5->-r requirements.txt (line 3))\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting jsonschema<5.0.0,>=4.0.0 (from apache-beam==2.56.0->-r requirements.txt (line 8))\n",
      "  Downloading jsonschema-4.22.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting packaging>=22.0 (from apache-beam==2.56.0->-r requirements.txt (line 8))\n",
      "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting python-dateutil<3,>=2.8.0 (from apache-beam==2.56.0->-r requirements.txt (line 8))\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting requests<3.0.0,>=2.24.0 (from apache-beam==2.56.0->-r requirements.txt (line 8))\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typing-extensions>=3.7.0 (from apache-beam==2.56.0->-r requirements.txt (line 8))\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/site-packages (from astunparse==1.6.3->-r requirements.txt (line 10)) (0.43.0)\n",
      "Collecting six<2.0,>=1.6.1 (from astunparse==1.6.3->-r requirements.txt (line 10))\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting ipywidgets>=7.7.1 (from bigframes==0.22.0->-r requirements.txt (line 17))\n",
      "  Downloading ipywidgets-8.1.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting wcwidth>=0.1.4 (from blessed==1.20.0->-r requirements.txt (line 18))\n",
      "  Downloading wcwidth-0.2.13-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting cffi>=1.0.0 (from brotlipy==0.7.0->-r requirements.txt (line 19))\n",
      "  Downloading cffi-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting jupyter-server<3,>=2.7.3 (from dataproc_jupyter_plugin==0.1.79->-r requirements.txt (line 31))\n",
      "  Downloading jupyter_server-2.14.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting websocket-client>=0.32.0 (from docker==4.4.4->-r requirements.txt (line 38))\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting idna>=2.0.0 (from email_validator==2.1.1->-r requirements.txt (line 41))\n",
      "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting certifi (from fiona==1.9.6->-r requirements.txt (line 46))\n",
      "  Downloading certifi-2024.6.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting decorator>4.1.2 (from gcsfs==2024.6.0->-r requirements.txt (line 52))\n",
      "  Downloading decorator-5.1.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting traitlets (from google-cloud-jupyter-config==0.0.10->-r requirements.txt (line 73))\n",
      "  Downloading traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting overrides<8.0.0,>=6.0.1 (from google-cloud-pubsublite==1.10.0->-r requirements.txt (line 77))\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting anyio (from httpx==0.27.0->-r requirements.txt (line 103))\n",
      "  Downloading anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting sniffio (from httpx==0.27.0->-r requirements.txt (line 103))\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting notebook>=5.0 (from jupyter-http-over-ws==0.0.8->-r requirements.txt (line 119))\n",
      "  Downloading notebook-7.2.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting tornado>=4.5 (from jupyter-http-over-ws==0.0.8->-r requirements.txt (line 119))\n",
      "  Downloading tornado-6.4.1-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting jupyter-events>=0.5.0 (from jupyter_server_fileid==0.9.2->-r requirements.txt (line 122))\n",
      "  Downloading jupyter_events-0.10.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting nbformat (from jupyterlab_git==0.44.0->-r requirements.txt (line 125))\n",
      "  Downloading nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting pexpect (from jupyterlab_git==0.44.0->-r requirements.txt (line 125))\n",
      "  Downloading pexpect-4.9.0-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting jinja2>=3.0.3 (from jupyterlab_server==2.27.2->-r requirements.txt (line 126))\n",
      "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting pyyaml (from jupytext==1.16.2->-r requirements.txt (line 128))\n",
      "  Downloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting importlib-metadata>=4.11.4 (from keyring==25.2.1->-r requirements.txt (line 132))\n",
      "  Downloading importlib_metadata-8.0.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting pluggy (from keyrings.google-artifactregistry-auth==1.1.2->-r requirements.txt (line 133))\n",
      "  Downloading pluggy-1.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.10/site-packages (from kubernetes==12.0.1->-r requirements.txt (line 139)) (65.5.1)\n",
      "Collecting colorama (from nbdime==3.2.0->-r requirements.txt (line 160))\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting pygments (from nbdime==3.2.0->-r requirements.txt (line 160))\n",
      "  Downloading pygments-2.18.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting tqdm (from nltk==3.8.1->-r requirements.txt (line 162))\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "      57.6/57.6 kB 5.9 MB/s eta 0:00:00\n",
      "Collecting importlib-metadata>=4.11.4 (from keyring==25.2.1->-r requirements.txt (line 132))\n",
      "  Downloading importlib_metadata-7.1.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting nbclient>=0.2.0 (from papermill==2.6.0->-r requirements.txt (line 185))\n",
      "  Downloading nbclient-0.10.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting entrypoints (from papermill==2.6.0->-r requirements.txt (line 185))\n",
      "  Downloading entrypoints-0.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting importlib-resources>=1.3 (from pins==0.8.6->-r requirements.txt (line 190))\n",
      "  Downloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting exceptiongroup>=1.0.0rc8 (from pytest==8.2.2->-r requirements.txt (line 212))\n",
      "  Downloading exceptiongroup-1.2.1-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting cryptography>=2.0 (from SecretStorage==3.3.3->-r requirements.txt (line 232))\n",
      "  Downloading cryptography-42.0.8-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow==2.15.1->-r requirements.txt (line 251))\n",
      "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting keras (from -r requirements.txt (line 129))\n",
      "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting tensorflow-serving-api (from -r requirements.txt (line 257))\n",
      "  Downloading tensorflow_serving_api-2.15.1-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting platformdirs<5,>=3.9.1 (from virtualenv==20.26.2->-r requirements.txt (line 284))\n",
      "  Downloading platformdirs-4.2.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from Werkzeug==3.0.3->-r requirements.txt (line 288))\n",
      "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting phik<0.13,>=0.11.1 (from ydata-profiling==4.6.0->-r requirements.txt (line 296))\n",
      "  Downloading phik-0.12.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting ipython<8,>=7 (from tensorflow_model_analysis->-r requirements.txt (line 259))\n",
      "  Downloading ipython-7.34.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting ipywidgets>=7.7.1 (from bigframes==0.22.0->-r requirements.txt (line 17))\n",
      "  Downloading ipywidgets-7.8.1-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "INFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tf_keras (from -r requirements.txt (line 266))\n",
      "  Downloading tf_keras-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting pycparser (from cffi>=1.0.0->brotlipy==0.7.0->-r requirements.txt (line 19))\n",
      "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting zipp>=0.5 (from importlib-metadata>=4.11.4->keyring==25.2.1->-r requirements.txt (line 132))\n",
      "  Downloading zipp-3.19.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting jedi>=0.16 (from ipython<8,>=7->tensorflow_model_analysis->-r requirements.txt (line 259))\n",
      "  Downloading jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting pickleshare (from ipython<8,>=7->tensorflow_model_analysis->-r requirements.txt (line 259))\n",
      "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 (from ipython<8,>=7->tensorflow_model_analysis->-r requirements.txt (line 259))\n",
      "  Downloading prompt_toolkit-3.0.47-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting matplotlib-inline (from ipython<8,>=7->tensorflow_model_analysis->-r requirements.txt (line 259))\n",
      "  Downloading matplotlib_inline-0.1.7-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting comm>=0.1.3 (from ipywidgets>=7.7.1->bigframes==0.22.0->-r requirements.txt (line 17))\n",
      "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting ipython-genutils~=0.2.0 (from ipywidgets>=7.7.1->bigframes==0.22.0->-r requirements.txt (line 17))\n",
      "  Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl.metadata (755 bytes)\n",
      "Collecting widgetsnbextension~=3.6.6 (from ipywidgets>=7.7.1->bigframes==0.22.0->-r requirements.txt (line 17))\n",
      "  Downloading widgetsnbextension-3.6.6-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "INFO: pip is looking at multiple versions of ipywidgets to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting ipywidgets>=7.7.1 (from bigframes==0.22.0->-r requirements.txt (line 17))\n",
      "  Downloading ipywidgets-7.8.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "  Downloading ipywidgets-7.7.5-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting ipykernel>=4.5.1 (from ipywidgets>=7.7.1->bigframes==0.22.0->-r requirements.txt (line 17))\n",
      "  Downloading ipykernel-6.29.4-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting ipywidgets>=7.7.1 (from bigframes==0.22.0->-r requirements.txt (line 17))\n",
      "  Downloading ipywidgets-7.7.4-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "  Downloading ipywidgets-7.7.3-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "  Downloading ipywidgets-7.7.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "  Downloading ipywidgets-7.7.1-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema<5.0.0,>=4.0.0->apache-beam==2.56.0->-r requirements.txt (line 8))\n",
      "  Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema<5.0.0,>=4.0.0->apache-beam==2.56.0->-r requirements.txt (line 8))\n",
      "  Downloading referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema<5.0.0,>=4.0.0->apache-beam==2.56.0->-r requirements.txt (line 8))\n",
      "  Downloading rpds_py-0.18.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.5.0->jupyter_server_fileid==0.9.2->-r requirements.txt (line 122))\n",
      "  Downloading python_json_logger-2.0.7-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting rfc3339-validator (from jupyter-events>=0.5.0->jupyter_server_fileid==0.9.2->-r requirements.txt (line 122))\n",
      "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.5.0->jupyter_server_fileid==0.9.2->-r requirements.txt (line 122))\n",
      "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting argon2-cffi>=21.1 (from jupyter-server<3,>=2.7.3->dataproc_jupyter_plugin==0.1.79->-r requirements.txt (line 31))\n",
      "  Downloading argon2_cffi-23.1.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting jupyter-client>=7.4.4 (from jupyter-server<3,>=2.7.3->dataproc_jupyter_plugin==0.1.79->-r requirements.txt (line 31))\n",
      "  Downloading jupyter_client-8.6.2-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting jupyter-core!=5.0.*,>=4.12 (from jupyter-server<3,>=2.7.3->dataproc_jupyter_plugin==0.1.79->-r requirements.txt (line 31))\n",
      "  Downloading jupyter_core-5.7.2-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.7.3->dataproc_jupyter_plugin==0.1.79->-r requirements.txt (line 31))\n",
      "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting nbconvert>=6.4.4 (from jupyter-server<3,>=2.7.3->dataproc_jupyter_plugin==0.1.79->-r requirements.txt (line 31))\n",
      "  Downloading nbconvert-7.16.4-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting prometheus-client>=0.9 (from jupyter-server<3,>=2.7.3->dataproc_jupyter_plugin==0.1.79->-r requirements.txt (line 31))\n",
      "  Downloading prometheus_client-0.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting pyzmq>=24 (from jupyter-server<3,>=2.7.3->dataproc_jupyter_plugin==0.1.79->-r requirements.txt (line 31))\n",
      "  Downloading pyzmq-26.0.3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting send2trash>=1.8.2 (from jupyter-server<3,>=2.7.3->dataproc_jupyter_plugin==0.1.79->-r requirements.txt (line 31))\n",
      "  Downloading Send2Trash-1.8.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting terminado>=0.8.3 (from jupyter-server<3,>=2.7.3->dataproc_jupyter_plugin==0.1.79->-r requirements.txt (line 31))\n",
      "  Downloading terminado-0.18.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting fastjsonschema>=2.15 (from nbformat->jupyterlab_git==0.44.0->-r requirements.txt (line 125))\n",
      "  Downloading fastjsonschema-2.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting jupyterlab<4.3,>=4.2.0 (from notebook>=5.0->jupyter-http-over-ws==0.0.8->-r requirements.txt (line 119))\n",
      "  Downloading jupyterlab-4.2.3-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting notebook-shim<0.3,>=0.2 (from notebook>=5.0->jupyter-http-over-ws==0.0.8->-r requirements.txt (line 119))\n",
      "  Downloading notebook_shim-0.2.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting ptyprocess>=0.5 (from pexpect->jupyterlab_git==0.44.0->-r requirements.txt (line 125))\n",
      "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3.0.0,>=2.24.0->apache-beam==2.56.0->-r requirements.txt (line 8))\n",
      "  Downloading charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Collecting argon2-cffi-bindings (from argon2-cffi>=21.1->jupyter-server<3,>=2.7.3->dataproc_jupyter_plugin==0.1.79->-r requirements.txt (line 31))\n",
      "  Downloading argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting debugpy>=1.6.5 (from ipykernel>=4.5.1->ipywidgets>=7.7.1->bigframes==0.22.0->-r requirements.txt (line 17))\n",
      "  Downloading debugpy-1.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting nest-asyncio (from ipykernel>=4.5.1->ipywidgets>=7.7.1->bigframes==0.22.0->-r requirements.txt (line 17))\n",
      "  Downloading nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting parso<0.9.0,>=0.8.3 (from jedi>=0.16->ipython<8,>=7->tensorflow_model_analysis->-r requirements.txt (line 259))\n",
      "  Downloading parso-0.8.4-py2.py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.5.0->jupyter_server_fileid==0.9.2->-r requirements.txt (line 122))\n",
      "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.5.0->jupyter_server_fileid==0.9.2->-r requirements.txt (line 122))\n",
      "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jsonpointer>1.13 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.5.0->jupyter_server_fileid==0.9.2->-r requirements.txt (line 122))\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.5.0->jupyter_server_fileid==0.9.2->-r requirements.txt (line 122))\n",
      "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting webcolors>=1.11 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.5.0->jupyter_server_fileid==0.9.2->-r requirements.txt (line 122))\n",
      "  Downloading webcolors-24.6.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting async-lru>=1.0.0 (from jupyterlab<4.3,>=4.2.0->notebook>=5.0->jupyter-http-over-ws==0.0.8->-r requirements.txt (line 119))\n",
      "  Downloading async_lru-2.0.4-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting jupyter-lsp>=2.0.0 (from jupyterlab<4.3,>=4.2.0->notebook>=5.0->jupyter-http-over-ws==0.0.8->-r requirements.txt (line 119))\n",
      "  Downloading jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting beautifulsoup4 (from nbconvert>=6.4.4->jupyter-server<3,>=2.7.3->dataproc_jupyter_plugin==0.1.79->-r requirements.txt (line 31))\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting bleach!=5.0.0 (from nbconvert>=6.4.4->jupyter-server<3,>=2.7.3->dataproc_jupyter_plugin==0.1.79->-r requirements.txt (line 31))\n",
      "  Downloading bleach-6.1.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting defusedxml (from nbconvert>=6.4.4->jupyter-server<3,>=2.7.3->dataproc_jupyter_plugin==0.1.79->-r requirements.txt (line 31))\n",
      "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting jupyterlab-pygments (from nbconvert>=6.4.4->jupyter-server<3,>=2.7.3->dataproc_jupyter_plugin==0.1.79->-r requirements.txt (line 31))\n",
      "  Downloading jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting mistune<4,>=2.0.3 (from nbconvert>=6.4.4->jupyter-server<3,>=2.7.3->dataproc_jupyter_plugin==0.1.79->-r requirements.txt (line 31))\n",
      "  Downloading mistune-3.0.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting pandocfilters>=1.4.1 (from nbconvert>=6.4.4->jupyter-server<3,>=2.7.3->dataproc_jupyter_plugin==0.1.79->-r requirements.txt (line 31))\n",
      "  Downloading pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting tinycss2 (from nbconvert>=6.4.4->jupyter-server<3,>=2.7.3->dataproc_jupyter_plugin==0.1.79->-r requirements.txt (line 31))\n",
      "  Downloading tinycss2-1.3.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting webencodings (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.7.3->dataproc_jupyter_plugin==0.1.79->-r requirements.txt (line 31))\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.7.3->dataproc_jupyter_plugin==0.1.79->-r requirements.txt (line 31))\n",
      "  Downloading soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.5.0->jupyter_server_fileid==0.9.2->-r requirements.txt (line 122))\n",
      "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.5.0->jupyter_server_fileid==0.9.2->-r requirements.txt (line 122))\n",
      "  Downloading types_python_dateutil-2.9.0.20240316-py3-none-any.whl.metadata (1.8 kB)\n",
      "Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "    126.5/126.5 kB 12.9 MB/s eta 0:00:00\n",
      "Downloading aiofiles-22.1.0-py3-none-any.whl (14 kB)\n",
      "Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "    1.2/1.2 MB 19.8 MB/s eta 0:00:00\n",
      "Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading ansicolors-1.1.8-py2.py3-none-any.whl (13 kB)\n",
      "Downloading apache_beam-2.56.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.5 MB)\n",
      "    14.5/14.5 MB 52.9 MB/s eta 0:00:00\n",
      "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading atpublic-4.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading Babel-2.15.0-py3-none-any.whl (9.6 MB)\n",
      "    9.6/9.6 MB 56.7 MB/s eta 0:00:00\n",
      "Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading backports.tarfile-1.2.0-py3-none-any.whl (30 kB)\n",
      "Downloading bidict-0.23.1-py3-none-any.whl (32 kB)\n",
      "Downloading bigframes-0.22.0-py2.py3-none-any.whl (441 kB)\n",
      "    441.2/441.2 kB 32.9 MB/s eta 0:00:00\n",
      "Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n",
      "    58.4/58.4 kB 4.9 MB/s eta 0:00:00\n",
      "Downloading brotlipy-0.7.0-cp35-abi3-manylinux2010_x86_64.whl (1.1 MB)\n",
      "    1.1/1.1 MB 57.3 MB/s eta 0:00:00\n",
      "Downloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "    97.9/97.9 kB 9.5 MB/s eta 0:00:00\n",
      "Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
      "Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
      "Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Downloading colorful-0.5.6-py2.py3-none-any.whl (201 kB)\n",
      "    201.4/201.4 kB 20.9 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (305 kB)\n",
      "    305.2/305.2 kB 23.4 MB/s eta 0:00:00\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading Cython-3.0.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "    3.6/3.6 MB 59.4 MB/s eta 0:00:00\n",
      "Downloading dacite-1.8.1-py3-none-any.whl (14 kB)\n",
      "Downloading dataproc_jupyter_plugin-0.1.79-py3-none-any.whl (4.2 MB)\n",
      "    4.2/4.2 MB 61.0 MB/s eta 0:00:00\n",
      "Downloading db_dtypes-1.2.0-py2.py3-none-any.whl (14 kB)\n",
      "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
      "    468.9/468.9 kB 25.6 MB/s eta 0:00:00\n",
      "Downloading dm_tree-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (152 kB)\n",
      "    152.8/152.8 kB 14.5 MB/s eta 0:00:00\n",
      "Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
      "    307.7/307.7 kB 28.3 MB/s eta 0:00:00\n",
      "Downloading docker-4.4.4-py2.py3-none-any.whl (147 kB)\n",
      "    147.0/147.0 kB 12.6 MB/s eta 0:00:00\n",
      "Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading email_validator-2.1.1-py3-none-any.whl (30 kB)\n",
      "Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
      "Downloading fastavro-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "    3.1/3.1 MB 77.8 MB/s eta 0:00:00\n",
      "Downloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
      "Downloading filelock-3.15.1-py3-none-any.whl (15 kB)\n",
      "Downloading fiona-1.9.6-cp310-cp310-manylinux2014_x86_64.whl (15.7 MB)\n",
      "    15.7/15.7 MB 46.5 MB/s eta 0:00:00\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading fonttools-4.53.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "    4.6/4.6 MB 64.9 MB/s eta 0:00:00\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "    239.5/239.5 kB 22.5 MB/s eta 0:00:00\n",
      "Downloading fsspec-2024.6.0-py3-none-any.whl (176 kB)\n",
      "    176.9/176.9 kB 17.7 MB/s eta 0:00:00\n",
      "Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Downloading gcsfs-2024.6.0-py2.py3-none-any.whl (34 kB)\n",
      "Downloading geopandas-0.14.4-py3-none-any.whl (1.1 MB)\n",
      "    1.1/1.1 MB 58.7 MB/s eta 0:00:00\n",
      "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "    62.7/62.7 kB 6.7 MB/s eta 0:00:00\n",
      "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "    207.3/207.3 kB 19.5 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.19.0-py3-none-any.whl (139 kB)\n",
      "    139.0/139.0 kB 13.7 MB/s eta 0:00:00\n",
      "Downloading google_api_python_client-1.12.11-py2.py3-none-any.whl (62 kB)\n",
      "    62.1/62.1 kB 5.3 MB/s eta 0:00:00\n",
      "Downloading google_auth-2.30.0-py2.py3-none-any.whl (193 kB)\n",
      "    193.7/193.7 kB 18.3 MB/s eta 0:00:00\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Downloading google_cloud_aiplatform-1.55.0-py2.py3-none-any.whl (5.1 MB)\n",
      "    5.1/5.1 MB 48.8 MB/s eta 0:00:00\n",
      "Downloading google_cloud_artifact_registry-1.11.3-py2.py3-none-any.whl (185 kB)\n",
      "    185.6/185.6 kB 15.2 MB/s eta 0:00:00\n",
      "Downloading google_cloud_bigquery-3.24.0-py2.py3-none-any.whl (238 kB)\n",
      "    238.5/238.5 kB 19.3 MB/s eta 0:00:00\n",
      "Downloading google_cloud_bigquery_connection-1.15.3-py2.py3-none-any.whl (58 kB)\n",
      "    58.1/58.1 kB 5.1 MB/s eta 0:00:00\n",
      "Downloading google_cloud_bigquery_storage-2.25.0-py2.py3-none-any.whl (199 kB)\n",
      "    199.8/199.8 kB 16.3 MB/s eta 0:00:00\n",
      "Downloading google_cloud_bigtable-2.24.0-py2.py3-none-any.whl (373 kB)\n",
      "    373.7/373.7 kB 24.9 MB/s eta 0:00:00\n",
      "Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\n",
      "Downloading google_cloud_datastore-2.19.0-py2.py3-none-any.whl (176 kB)\n",
      "    176.4/176.4 kB 16.0 MB/s eta 0:00:00\n",
      "Downloading google_cloud_dlp-3.18.0-py2.py3-none-any.whl (180 kB)\n",
      "    180.3/180.3 kB 14.2 MB/s eta 0:00:00\n",
      "Downloading google_cloud_functions-1.16.3-py2.py3-none-any.whl (132 kB)\n",
      "    132.3/132.3 kB 14.4 MB/s eta 0:00:00\n",
      "Downloading google_cloud_iam-2.15.0-py2.py3-none-any.whl (205 kB)\n",
      "    205.2/205.2 kB 15.2 MB/s eta 0:00:00\n",
      "Downloading google_cloud_language-2.13.3-py2.py3-none-any.whl (143 kB)\n",
      "    143.7/143.7 kB 11.6 MB/s eta 0:00:00\n",
      "Downloading google_cloud_monitoring-2.21.0-py2.py3-none-any.whl (344 kB)\n",
      "    344.9/344.9 kB 27.1 MB/s eta 0:00:00\n",
      "Downloading google_cloud_pubsub-2.21.5-py2.py3-none-any.whl (273 kB)\n",
      "    273.2/273.2 kB 21.8 MB/s eta 0:00:00\n",
      "Downloading google_cloud_pubsublite-1.10.0-py2.py3-none-any.whl (299 kB)\n",
      "    299.2/299.2 kB 22.3 MB/s eta 0:00:00\n",
      "Downloading google_cloud_recommendations_ai-0.10.10-py2.py3-none-any.whl (180 kB)\n",
      "    180.3/180.3 kB 17.7 MB/s eta 0:00:00\n",
      "Downloading google_cloud_resource_manager-1.12.3-py2.py3-none-any.whl (333 kB)\n",
      "    333.7/333.7 kB 26.3 MB/s eta 0:00:00\n",
      "Downloading google_cloud_spanner-3.47.0-py2.py3-none-any.whl (384 kB)\n",
      "    384.6/384.6 kB 31.9 MB/s eta 0:00:00\n",
      "Downloading google_cloud_storage-2.14.0-py2.py3-none-any.whl (121 kB)\n",
      "    121.6/121.6 kB 11.0 MB/s eta 0:00:00\n",
      "Downloading google_cloud_videointelligence-2.13.3-py2.py3-none-any.whl (240 kB)\n",
      "    240.4/240.4 kB 26.1 MB/s eta 0:00:00\n",
      "Downloading google_cloud_vision-3.7.2-py2.py3-none-any.whl (459 kB)\n",
      "    459.6/459.6 kB 33.7 MB/s eta 0:00:00\n",
      "Downloading google_crc32c-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "    57.5/57.5 kB 5.9 MB/s eta 0:00:00\n",
      "Downloading google_resumable_media-2.7.1-py2.py3-none-any.whl (81 kB)\n",
      "    81.2/81.2 kB 5.4 MB/s eta 0:00:00\n",
      "Downloading googleapis_common_protos-1.63.1-py2.py3-none-any.whl (229 kB)\n",
      "    229.2/229.2 kB 20.0 MB/s eta 0:00:00\n",
      "Downloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (616 kB)\n",
      "    616.0/616.0 kB 39.8 MB/s eta 0:00:00\n",
      "Downloading grpc_google_iam_v1-0.13.0-py2.py3-none-any.whl (25 kB)\n",
      "Downloading grpc_interceptor-0.15.4-py3-none-any.whl (20 kB)\n",
      "Downloading grpcio-1.64.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n",
      "    5.6/5.6 MB 50.4 MB/s eta 0:00:00\n",
      "Downloading grpcio_status-1.48.2-py3-none-any.whl (14 kB)\n",
      "Downloading gviz_api-1.10.0-py2.py3-none-any.whl (13 kB)\n",
      "Downloading gymnasium-0.28.1-py3-none-any.whl (925 kB)\n",
      "    925.5/925.5 kB 18.1 MB/s eta 0:00:00\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "    58.3/58.3 kB 5.2 MB/s eta 0:00:00\n",
      "Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "    5.3/5.3 MB 47.9 MB/s eta 0:00:00\n",
      "Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "    77.9/77.9 kB 8.5 MB/s eta 0:00:00\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "    96.9/96.9 kB 11.2 MB/s eta 0:00:00\n",
      "Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
      "    341.4/341.4 kB 24.5 MB/s eta 0:00:00\n",
      "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "    75.6/75.6 kB 6.9 MB/s eta 0:00:00\n",
      "Downloading humanize-4.9.0-py3-none-any.whl (126 kB)\n",
      "    126.8/126.8 kB 11.9 MB/s eta 0:00:00\n",
      "Downloading hypertune-1.1.0-py3-none-any.whl (22 kB)\n",
      "Downloading ibis_framework-7.1.0-py3-none-any.whl (1.7 MB)\n",
      "    1.7/1.7 MB 61.2 MB/s eta 0:00:00\n",
      "Downloading ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n",
      "    296.5/296.5 kB 26.0 MB/s eta 0:00:00\n",
      "Downloading imageio-2.34.1-py3-none-any.whl (313 kB)\n",
      "    313.5/313.5 kB 28.4 MB/s eta 0:00:00\n",
      "Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading jaraco.classes-3.4.0-py3-none-any.whl (6.8 kB)\n",
      "Downloading jaraco.context-5.3.0-py3-none-any.whl (6.5 kB)\n",
      "Downloading jaraco.functools-4.0.1-py3-none-any.whl (9.8 kB)\n",
      "Downloading jax_jumpy-1.0.0-py3-none-any.whl (20 kB)\n",
      "Downloading jeepney-0.8.0-py3-none-any.whl (48 kB)\n",
      "    48.4/48.4 kB 5.0 MB/s eta 0:00:00\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "    301.8/301.8 kB 28.9 MB/s eta 0:00:00\n",
      "Downloading Js2Py-0.74-py3-none-any.whl (1.0 MB)\n",
      "    1.0/1.0 MB 57.2 MB/s eta 0:00:00\n",
      "Downloading json5-0.9.25-py3-none-any.whl (30 kB)\n",
      "Downloading jsonpickle-3.2.2-py3-none-any.whl (41 kB)\n",
      "    41.8/41.8 kB 5.2 MB/s eta 0:00:00\n",
      "Downloading jupyter_http_over_ws-0.0.8-py2.py3-none-any.whl (18 kB)\n",
      "Downloading jupyter_server_mathjax-0.2.6-py3-none-any.whl (3.1 MB)\n",
      "    3.1/3.1 MB 58.5 MB/s eta 0:00:00\n",
      "Downloading jupyter_ydoc-0.2.5-py3-none-any.whl (6.2 kB)\n",
      "Downloading jupyter_server_fileid-0.9.2-py3-none-any.whl (16 kB)\n",
      "Downloading jupyter_server_proxy-4.2.0-py3-none-any.whl (34 kB)\n",
      "Downloading jupyter_server_ydoc-0.8.0-py3-none-any.whl (11 kB)\n",
      "Downloading jupyterlab_git-0.44.0-py3-none-any.whl (684 kB)\n",
      "    684.2/684.2 kB 44.4 MB/s eta 0:00:00\n",
      "Downloading jupyterlab_server-2.27.2-py3-none-any.whl (59 kB)\n",
      "    59.4/59.4 kB 6.5 MB/s eta 0:00:00\n",
      "Downloading jupyterlab_widgets-3.0.11-py3-none-any.whl (214 kB)\n",
      "    214.4/214.4 kB 23.1 MB/s eta 0:00:00\n",
      "Downloading jupytext-1.16.2-py3-none-any.whl (153 kB)\n",
      "    153.2/153.2 kB 15.6 MB/s eta 0:00:00\n",
      "Downloading keyring-25.2.1-py3-none-any.whl (38 kB)\n",
      "Downloading keyrings.google_artifactregistry_auth-1.1.2-py3-none-any.whl (10 kB)\n",
      "Downloading kfp_pipeline_spec-0.2.2-py3-none-any.whl (20 kB)\n",
      "Downloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "    1.6/1.6 MB 66.5 MB/s eta 0:00:00\n",
      "Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Downloading kubernetes-12.0.1-py2.py3-none-any.whl (1.7 MB)\n",
      "    1.7/1.7 MB 58.9 MB/s eta 0:00:00\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "    24.5/24.5 MB 48.0 MB/s eta 0:00:00\n",
      "Downloading linkify_it_py-2.0.3-py3-none-any.whl (19 kB)\n",
      "Downloading llvmlite-0.41.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.6 MB)\n",
      "    43.6/43.6 MB 36.8 MB/s eta 0:00:00\n",
      "Downloading lxml-5.2.2-cp310-cp310-manylinux_2_28_x86_64.whl (5.0 MB)\n",
      "    5.0/5.0 MB 59.4 MB/s eta 0:00:00\n",
      "Downloading lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "    1.3/1.3 MB 58.6 MB/s eta 0:00:00\n",
      "Downloading Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "    105.4/105.4 kB 10.9 MB/s eta 0:00:00\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "    87.5/87.5 kB 8.6 MB/s eta 0:00:00\n",
      "Downloading matplotlib-3.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "    11.6/11.6 MB 59.0 MB/s eta 0:00:00\n",
      "Downloading mdit_py_plugins-0.4.1-py3-none-any.whl (54 kB)\n",
      "    54.8/54.8 kB 4.2 MB/s eta 0:00:00\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading memray-1.12.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.5 MB)\n",
      "    3.5/3.5 MB 57.2 MB/s eta 0:00:00\n",
      "Downloading ml_metadata-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.5 MB)\n",
      "    7.5/7.5 MB 61.8 MB/s eta 0:00:00\n",
      "Downloading ml_pipelines_sdk-1.15.1-py3-none-any.whl (1.8 MB)\n",
      "    1.8/1.8 MB 58.5 MB/s eta 0:00:00\n",
      "Downloading more_itertools-10.3.0-py3-none-any.whl (59 kB)\n",
      "    59.2/59.2 kB 5.0 MB/s eta 0:00:00\n",
      "Downloading msgpack-1.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (385 kB)\n",
      "    385.1/385.1 kB 23.9 MB/s eta 0:00:00\n",
      "Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "    124.3/124.3 kB 11.6 MB/s eta 0:00:00\n",
      "Downloading multimethod-1.11.2-py3-none-any.whl (10 kB)\n",
      "Downloading multipledispatch-1.0.0-py3-none-any.whl (12 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading nbdime-3.2.0-py2.py3-none-any.whl (5.3 MB)\n",
      "    5.3/5.3 MB 63.1 MB/s eta 0:00:00\n",
      "Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "    1.7/1.7 MB 61.9 MB/s eta 0:00:00\n",
      "Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "    1.5/1.5 MB 57.7 MB/s eta 0:00:00\n",
      "Downloading numba-0.58.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.6 MB)\n",
      "    3.6/3.6 MB 54.1 MB/s eta 0:00:00\n",
      "Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "    17.3/17.3 MB 52.9 MB/s eta 0:00:00\n",
      "Downloading nvidia_cuda_runtime_cu12-12.5.39-py3-none-manylinux2014_x86_64.whl (895 kB)\n",
      "    895.1/895.1 kB 38.6 MB/s eta 0:00:00\n",
      "Downloading nvidia_ml_py-11.495.46-py3-none-any.whl (25 kB)\n",
      "Downloading oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
      "    98.2/98.2 kB 9.4 MB/s eta 0:00:00\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "    151.7/151.7 kB 13.8 MB/s eta 0:00:00\n",
      "Downloading objsize-0.7.0-py3-none-any.whl (11 kB)\n",
      "Downloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
      "    128.2/128.2 kB 13.7 MB/s eta 0:00:00\n",
      "Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
      "Downloading opentelemetry_api-1.25.0-py3-none-any.whl (59 kB)\n",
      "    59.9/59.9 kB 6.1 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_exporter_otlp-1.25.0-py3-none-any.whl (7.0 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.25.0-py3-none-any.whl (17 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.25.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_http-1.25.0-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_proto-1.25.0-py3-none-any.whl (52 kB)\n",
      "    52.5/52.5 kB 4.9 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_sdk-1.25.0-py3-none-any.whl (107 kB)\n",
      "    107.0/107.0 kB 10.1 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_semantic_conventions-0.46b0-py3-none-any.whl (130 kB)\n",
      "    130.5/130.5 kB 12.9 MB/s eta 0:00:00\n",
      "Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "    65.5/65.5 kB 5.9 MB/s eta 0:00:00\n",
      "Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n",
      "    311.2/311.2 kB 24.6 MB/s eta 0:00:00\n",
      "Downloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
      "    145.0/145.0 kB 13.2 MB/s eta 0:00:00\n",
      "Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "    12.1/12.1 MB 58.6 MB/s eta 0:00:00\n",
      "Downloading pandas_profiling-3.6.6-py2.py3-none-any.whl (324 kB)\n",
      "    324.4/324.4 kB 26.6 MB/s eta 0:00:00\n",
      "Downloading papermill-2.6.0-py3-none-any.whl (38 kB)\n",
      "Downloading parsy-2.1-py3-none-any.whl (9.1 kB)\n",
      "Downloading patsy-0.5.6-py2.py3-none-any.whl (233 kB)\n",
      "    233.9/233.9 kB 21.5 MB/s eta 0:00:00\n",
      "Downloading pendulum-3.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (384 kB)\n",
      "    384.9/384.9 kB 31.5 MB/s eta 0:00:00\n",
      "Downloading pillow-10.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "    4.5/4.5 MB 60.8 MB/s eta 0:00:00\n",
      "Downloading pins-0.8.6-py2.py3-none-any.whl (114 kB)\n",
      "    114.2/114.2 kB 10.1 MB/s eta 0:00:00\n",
      "Downloading plotly-5.22.0-py3-none-any.whl (16.4 MB)\n",
      "    16.4/16.4 MB 49.6 MB/s eta 0:00:00\n",
      "Downloading portalocker-2.10.0-py3-none-any.whl (18 kB)\n",
      "Downloading portpicker-1.6.0-py3-none-any.whl (16 kB)\n",
      "Downloading prettytable-3.10.0-py3-none-any.whl (28 kB)\n",
      "Downloading proto_plus-1.23.0-py3-none-any.whl (48 kB)\n",
      "    48.8/48.8 kB 4.3 MB/s eta 0:00:00\n",
      "Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "    1.1/1.1 MB 46.2 MB/s eta 0:00:00\n",
      "Downloading psutil-5.9.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (292 kB)\n",
      "    292.3/292.3 kB 20.5 MB/s eta 0:00:00\n",
      "Downloading py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n",
      "    3.0/3.0 MB 80.3 MB/s eta 0:00:00\n",
      "Downloading pyarrow-10.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.9 MB)\n",
      "    35.9/35.9 MB 42.5 MB/s eta 0:00:00\n",
      "Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
      "    85.3/85.3 kB 9.7 MB/s eta 0:00:00\n",
      "Downloading pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "    181.2/181.2 kB 16.8 MB/s eta 0:00:00\n",
      "Downloading pydantic-1.10.16-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "    3.1/3.1 MB 54.2 MB/s eta 0:00:00\n",
      "Downloading pydata_google_auth-1.8.2-py2.py3-none-any.whl (15 kB)\n",
      "Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Downloading PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
      "Downloading pymongo-4.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (669 kB)\n",
      "    669.1/669.1 kB 27.6 MB/s eta 0:00:00\n",
      "Downloading pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "    103.2/103.2 kB 8.9 MB/s eta 0:00:00\n",
      "Downloading pyproj-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "    8.3/8.3 MB 65.6 MB/s eta 0:00:00\n",
      "Downloading pytest-8.2.2-py3-none-any.whl (339 kB)\n",
      "    339.9/339.9 kB 27.0 MB/s eta 0:00:00\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "    505.5/505.5 kB 34.7 MB/s eta 0:00:00\n",
      "Downloading pywavelets-1.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "    4.5/4.5 MB 61.6 MB/s eta 0:00:00\n",
      "Downloading ray-2.24.0-cp310-cp310-manylinux2014_x86_64.whl (65.9 MB)\n",
      "    65.9/65.9 MB 25.8 MB/s eta 0:00:00\n",
      "Downloading ray_cpp-2.24.0-cp310-cp310-manylinux2014_x86_64.whl (27.5 MB)\n",
      "    27.5/27.5 MB 45.1 MB/s eta 0:00:00\n",
      "Downloading redis-5.0.6-py3-none-any.whl (252 kB)\n",
      "    252.0/252.0 kB 19.6 MB/s eta 0:00:00\n",
      "Downloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (775 kB)\n",
      "    775.1/775.1 kB 41.9 MB/s eta 0:00:00\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading requests_toolbelt-0.10.1-py2.py3-none-any.whl (54 kB)\n",
      "    54.5/54.5 kB 5.0 MB/s eta 0:00:00\n",
      "Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
      "Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "    240.7/240.7 kB 19.4 MB/s eta 0:00:00\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n",
      "    106.7/106.7 kB 10.5 MB/s eta 0:00:00\n",
      "Downloading scikit_image-0.23.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.7 MB)\n",
      "    14.7/14.7 MB 56.5 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
      "    13.3/13.3 MB 57.3 MB/s eta 0:00:00\n",
      "Downloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
      "    36.4/36.4 MB 41.7 MB/s eta 0:00:00\n",
      "Downloading seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
      "    293.3/293.3 kB 24.6 MB/s eta 0:00:00\n",
      "Downloading SecretStorage-3.3.3-py3-none-any.whl (15 kB)\n",
      "Downloading shapely-2.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "    2.5/2.5 MB 58.2 MB/s eta 0:00:00\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading simpervisor-1.0.0-py3-none-any.whl (8.3 kB)\n",
      "Downloading smart_open-7.0.4-py3-none-any.whl (61 kB)\n",
      "    61.2/61.2 kB 6.1 MB/s eta 0:00:00\n",
      "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Downloading SQLAlchemy-2.0.30-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "    3.1/3.1 MB 65.9 MB/s eta 0:00:00\n",
      "Downloading sqlglot-19.9.0-py3-none-any.whl (336 kB)\n",
      "    336.2/336.2 kB 29.7 MB/s eta 0:00:00\n",
      "Downloading sqlparse-0.5.0-py3-none-any.whl (43 kB)\n",
      "    44.0/44.0 kB 4.1 MB/s eta 0:00:00\n",
      "Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
      "    71.9/71.9 kB 8.2 MB/s eta 0:00:00\n",
      "Downloading statsmodels-0.14.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
      "    10.8/10.8 MB 59.0 MB/s eta 0:00:00\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading tangled_up_in_unicode-0.2.0-py3-none-any.whl (4.7 MB)\n",
      "    4.7/4.7 MB 59.3 MB/s eta 0:00:00\n",
      "Downloading tenacity-8.3.0-py3-none-any.whl (25 kB)\n",
      "Downloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
      "    5.5/5.5 MB 60.9 MB/s eta 0:00:00\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "    6.6/6.6 MB 44.7 MB/s eta 0:00:00\n",
      "Downloading tensorboard_plugin_profile-2.15.1-py3-none-any.whl (5.6 MB)\n",
      "    5.6/5.6 MB 45.4 MB/s eta 0:00:00\n",
      "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "    101.7/101.7 kB 10.9 MB/s eta 0:00:00\n",
      "Downloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
      "    475.2/475.2 MB 3.9 MB/s eta 0:00:00\n",
      "Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
      "    442.0/442.0 kB 29.1 MB/s eta 0:00:00\n",
      "Downloading tensorflow_hub-0.15.0-py2.py3-none-any.whl (85 kB)\n",
      "    85.4/85.4 kB 6.4 MB/s eta 0:00:00\n",
      "Downloading tensorflow_io_gcs_filesystem-0.37.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "    5.1/5.1 MB 44.3 MB/s eta 0:00:00\n",
      "Downloading tensorrt_cu12_bindings-10.1.0-cp310-none-manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "    1.1/1.1 MB 26.1 MB/s eta 0:00:00\n",
      "Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading textual-0.67.1-py3-none-any.whl (561 kB)\n",
      "    561.2/561.2 kB 37.8 MB/s eta 0:00:00\n",
      "Downloading tfx-1.15.1-py3-none-any.whl (3.0 MB)\n",
      "    3.0/3.0 MB 42.6 MB/s eta 0:00:00\n",
      "Downloading tfx_bsl-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.5 MB)\n",
      "    22.5/22.5 MB 35.9 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading tifffile-2024.5.22-py3-none-any.whl (225 kB)\n",
      "    225.5/225.5 kB 15.8 MB/s eta 0:00:00\n",
      "Downloading time_machine-2.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34 kB)\n",
      "Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\n",
      "Downloading toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "    56.1/56.1 kB 4.7 MB/s eta 0:00:00\n",
      "Downloading typeguard-4.3.0-py3-none-any.whl (35 kB)\n",
      "Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "    47.2/47.2 kB 3.7 MB/s eta 0:00:00\n",
      "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "    345.4/345.4 kB 23.7 MB/s eta 0:00:00\n",
      "Downloading tzlocal-5.2-py3-none-any.whl (17 kB)\n",
      "Downloading uc_micro_py-1.0.3-py3-none-any.whl (6.2 kB)\n",
      "Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
      "    53.6/53.6 kB 4.8 MB/s eta 0:00:00\n",
      "Downloading uritemplate-3.0.1-py2.py3-none-any.whl (15 kB)\n",
      "Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
      "    143.8/143.8 kB 15.0 MB/s eta 0:00:00\n",
      "Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
      "    62.4/62.4 kB 5.3 MB/s eta 0:00:00\n",
      "Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
      "    3.4/3.4 MB 44.5 MB/s eta 0:00:00\n",
      "Downloading virtualenv-20.26.2-py3-none-any.whl (3.9 MB)\n",
      "    3.9/3.9 MB 44.7 MB/s eta 0:00:00\n",
      "Downloading visions-0.7.5-py3-none-any.whl (102 kB)\n",
      "    102.7/102.7 kB 8.7 MB/s eta 0:00:00\n",
      "Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "    1.2/1.2 MB 42.6 MB/s eta 0:00:00\n",
      "Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "    130.2/130.2 kB 12.1 MB/s eta 0:00:00\n",
      "Downloading werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
      "    227.3/227.3 kB 18.2 MB/s eta 0:00:00\n",
      "Downloading wordcloud-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511 kB)\n",
      "    511.1/511.1 kB 28.6 MB/s eta 0:00:00\n",
      "Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
      "    77.9/77.9 kB 8.1 MB/s eta 0:00:00\n",
      "Downloading wurlitzer-3.1.1-py3-none-any.whl (8.6 kB)\n",
      "Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "    194.1/194.1 kB 17.0 MB/s eta 0:00:00\n",
      "Downloading y_py-0.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "    1.7/1.7 MB 45.3 MB/s eta 0:00:00\n",
      "Downloading yarg-0.1.9-py2.py3-none-any.whl (19 kB)\n",
      "Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "    301.6/301.6 kB 23.0 MB/s eta 0:00:00\n",
      "Downloading ydata_profiling-4.6.0-py2.py3-none-any.whl (357 kB)\n",
      "    357.5/357.5 kB 29.2 MB/s eta 0:00:00\n",
      "Downloading ydf-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.3 MB)\n",
      "    9.3/9.3 MB 44.1 MB/s eta 0:00:00\n",
      "Downloading ypy_websocket-0.8.4-py3-none-any.whl (10 kB)\n",
      "Downloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "    5.4/5.4 MB 44.0 MB/s eta 0:00:00\n",
      "Downloading aiosqlite-0.20.0-py3-none-any.whl (15 kB)\n",
      "Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "    1.7/1.7 MB 45.8 MB/s eta 0:00:00\n",
      "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
      "    129.1/129.1 kB 9.6 MB/s eta 0:00:00\n",
      "Downloading struct2tensor-0.46.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.0 MB)\n",
      "    3.0/3.0 MB 41.7 MB/s eta 0:00:00\n",
      "Downloading tensorflow_data_validation-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.0 MB)\n",
      "    19.0/19.0 MB 35.3 MB/s eta 0:00:00\n",
      "Downloading tensorflow_metadata-1.15.0-py3-none-any.whl (28 kB)\n",
      "Downloading tensorflow_serving_api-2.15.1-py2.py3-none-any.whl (26 kB)\n",
      "Downloading tensorflow_transform-1.15.0-py3-none-any.whl (451 kB)\n",
      "    451.2/451.2 kB 33.5 MB/s eta 0:00:00\n",
      "Downloading tensorflow_model_analysis-0.46.0-py3-none-any.whl (1.9 MB)\n",
      "    1.9/1.9 MB 47.6 MB/s eta 0:00:00\n",
      "Downloading tf_keras-2.15.1-py3-none-any.whl (1.7 MB)\n",
      "    1.7/1.7 MB 46.0 MB/s eta 0:00:00\n",
      "Downloading anyio-4.4.0-py3-none-any.whl (86 kB)\n",
      "    86.8/86.8 kB 10.3 MB/s eta 0:00:00\n",
      "Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "    60.8/60.8 kB 6.6 MB/s eta 0:00:00\n",
      "Downloading certifi-2024.6.2-py3-none-any.whl (164 kB)\n",
      "    164.4/164.4 kB 16.3 MB/s eta 0:00:00\n",
      "Downloading cffi-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (443 kB)\n",
      "    443.9/443.9 kB 30.5 MB/s eta 0:00:00\n",
      "Downloading cryptography-42.0.8-cp39-abi3-manylinux_2_28_x86_64.whl (3.9 MB)\n",
      "    3.9/3.9 MB 46.0 MB/s eta 0:00:00\n",
      "Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
      "Downloading exceptiongroup-1.2.1-py3-none-any.whl (16 kB)\n",
      "Downloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "    66.8/66.8 kB 6.3 MB/s eta 0:00:00\n",
      "Downloading importlib_metadata-7.1.0-py3-none-any.whl (24 kB)\n",
      "Downloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Downloading ipython-7.34.0-py3-none-any.whl (793 kB)\n",
      "    793.8/793.8 kB 35.5 MB/s eta 0:00:00\n",
      "Downloading ipywidgets-7.7.1-py2.py3-none-any.whl (123 kB)\n",
      "    123.4/123.4 kB 11.6 MB/s eta 0:00:00\n",
      "Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "    133.3/133.3 kB 14.7 MB/s eta 0:00:00\n",
      "Downloading jsonschema-4.22.0-py3-none-any.whl (88 kB)\n",
      "    88.3/88.3 kB 10.2 MB/s eta 0:00:00\n",
      "Downloading jupyter_events-0.10.0-py3-none-any.whl (18 kB)\n",
      "Downloading jupyter_server-2.14.1-py3-none-any.whl (383 kB)\n",
      "    383.4/383.4 kB 30.2 MB/s eta 0:00:00\n",
      "Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "    2.2/2.2 MB 39.0 MB/s eta 0:00:00\n",
      "Downloading nbclient-0.10.0-py3-none-any.whl (25 kB)\n",
      "Downloading nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "    78.5/78.5 kB 7.5 MB/s eta 0:00:00\n",
      "Downloading notebook-7.2.1-py3-none-any.whl (5.0 MB)\n",
      "    5.0/5.0 MB 44.3 MB/s eta 0:00:00\n",
      "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading packaging-24.1-py3-none-any.whl (53 kB)\n",
      "    54.0/54.0 kB 6.1 MB/s eta 0:00:00\n",
      "Downloading pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\n",
      "    63.8/63.8 kB 6.6 MB/s eta 0:00:00\n",
      "Downloading phik-0.12.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (686 kB)\n",
      "    686.1/686.1 kB 36.1 MB/s eta 0:00:00\n",
      "Downloading platformdirs-4.2.2-py3-none-any.whl (18 kB)\n",
      "Downloading pluggy-1.5.0-py3-none-any.whl (20 kB)\n",
      "Downloading pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
      "    1.2/1.2 MB 44.1 MB/s eta 0:00:00\n",
      "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "    229.9/229.9 kB 21.1 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\n",
      "    705.5/705.5 kB 37.9 MB/s eta 0:00:00\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "    64.9/64.9 kB 7.2 MB/s eta 0:00:00\n",
      "Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading tornado-6.4.1-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (436 kB)\n",
      "    436.8/436.8 kB 31.8 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "    78.3/78.3 kB 7.8 MB/s eta 0:00:00\n",
      "Downloading traitlets-5.14.3-py3-none-any.whl (85 kB)\n",
      "    85.4/85.4 kB 7.9 MB/s eta 0:00:00\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
      "Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "    58.8/58.8 kB 6.0 MB/s eta 0:00:00\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
      "Downloading argon2_cffi-23.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "    142.1/142.1 kB 16.2 MB/s eta 0:00:00\n",
      "Downloading fastjsonschema-2.20.0-py3-none-any.whl (23 kB)\n",
      "Downloading ipykernel-6.29.4-py3-none-any.whl (117 kB)\n",
      "    117.1/117.1 kB 12.5 MB/s eta 0:00:00\n",
      "Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
      "Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
      "    1.6/1.6 MB 44.3 MB/s eta 0:00:00\n",
      "Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
      "Downloading jupyter_client-8.6.2-py3-none-any.whl (105 kB)\n",
      "    105.9/105.9 kB 9.1 MB/s eta 0:00:00\n",
      "Downloading jupyter_core-5.7.2-py3-none-any.whl (28 kB)\n",
      "Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
      "Downloading jupyterlab-4.2.3-py3-none-any.whl (11.6 MB)\n",
      "    11.6/11.6 MB 37.0 MB/s eta 0:00:00\n",
      "Downloading matplotlib_inline-0.1.7-py3-none-any.whl (9.9 kB)\n",
      "Downloading nbconvert-7.16.4-py3-none-any.whl (257 kB)\n",
      "    257.4/257.4 kB 24.9 MB/s eta 0:00:00\n",
      "Downloading notebook_shim-0.2.4-py3-none-any.whl (13 kB)\n",
      "Downloading prometheus_client-0.20.0-py3-none-any.whl (54 kB)\n",
      "    54.5/54.5 kB 5.6 MB/s eta 0:00:00\n",
      "Downloading prompt_toolkit-3.0.47-py3-none-any.whl (386 kB)\n",
      "    386.4/386.4 kB 32.1 MB/s eta 0:00:00\n",
      "Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
      "Downloading python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)\n",
      "Downloading pyzmq-26.0.3-cp310-cp310-manylinux_2_28_x86_64.whl (919 kB)\n",
      "    919.8/919.8 kB 39.0 MB/s eta 0:00:00\n",
      "Downloading referencing-0.35.1-py3-none-any.whl (26 kB)\n",
      "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Downloading rpds_py-0.18.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "    1.1/1.1 MB 43.0 MB/s eta 0:00:00\n",
      "Downloading Send2Trash-1.8.3-py3-none-any.whl (18 kB)\n",
      "Downloading terminado-0.18.1-py3-none-any.whl (14 kB)\n",
      "Downloading widgetsnbextension-3.6.6-py2.py3-none-any.whl (1.6 MB)\n",
      "    1.6/1.6 MB 43.7 MB/s eta 0:00:00\n",
      "Downloading zipp-3.19.2-py3-none-any.whl (9.0 kB)\n",
      "Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
      "Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "    117.6/117.6 kB 12.0 MB/s eta 0:00:00\n",
      "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
      "Downloading async_lru-2.0.4-py3-none-any.whl (6.1 kB)\n",
      "Downloading bleach-6.1.0-py3-none-any.whl (162 kB)\n",
      "    162.8/162.8 kB 19.4 MB/s eta 0:00:00\n",
      "Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
      "Downloading debugpy-1.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "    3.0/3.0 MB 44.0 MB/s eta 0:00:00\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
      "    69.1/69.1 kB 7.7 MB/s eta 0:00:00\n",
      "Downloading mistune-3.0.2-py3-none-any.whl (47 kB)\n",
      "    48.0/48.0 kB 4.5 MB/s eta 0:00:00\n",
      "Downloading pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\n",
      "Downloading parso-0.8.4-py2.py3-none-any.whl (103 kB)\n",
      "    103.7/103.7 kB 10.4 MB/s eta 0:00:00\n",
      "Downloading webcolors-24.6.0-py3-none-any.whl (14 kB)\n",
      "Downloading argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)\n",
      "    86.2/86.2 kB 10.6 MB/s eta 0:00:00\n",
      "Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "    147.9/147.9 kB 17.2 MB/s eta 0:00:00\n",
      "Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "Downloading jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n",
      "Downloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
      "Downloading tinycss2-1.3.0-py3-none-any.whl (22 kB)\n",
      "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
      "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
      "    66.4/66.4 kB 8.2 MB/s eta 0:00:00\n",
      "Downloading soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Downloading types_python_dateutil-2.9.0.20240316-py3-none-any.whl (9.7 kB)\n",
      "Building wheels for collected packages: crcmod, dill, docopt, google-apitools, google-cloud-jupyter-config, gpustat, hdfs, htmlmin, kfp, kfp-server-api, pyfarmhash, pyjsparser, rouge_score, tensorrt, tensorrt-cu12, tensorrt-cu12-libs, kernels-mixer\n",
      "  Building wheel for crcmod (setup.py): started\n",
      "  Building wheel for crcmod (setup.py): finished with status 'done'\n",
      "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=30829 sha256=898bb2b83f67fa82398150c342bbf9ed7843d55f492b12abd08d012f872f59ca\n",
      "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
      "  Building wheel for dill (setup.py): started\n",
      "  Building wheel for dill (setup.py): finished with status 'done'\n",
      "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78541 sha256=1327ce2711bf276276e1223c1a59d5805cf0255cd4bce38a8ca97c96bb609b38\n",
      "  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n",
      "  Building wheel for docopt (setup.py): started\n",
      "  Building wheel for docopt (setup.py): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=7482689ee0bb9b9d8e777d8211fbf9d0377e9f5cb2edf658f940b58bf47b7ab7\n",
      "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
      "  Building wheel for google-apitools (setup.py): started\n",
      "  Building wheel for google-apitools (setup.py): finished with status 'done'\n",
      "  Created wheel for google-apitools: filename=google_apitools-0.5.31-py3-none-any.whl size=131015 sha256=24028184085efc45938d8ac4fef88e7e9ad481b8259099cb713e1790d8f7c6ab\n",
      "  Stored in directory: /root/.cache/pip/wheels/04/b7/e0/9712f8c23a5da3d9d16fb88216b897bf60e85b12f5470f26ee\n",
      "  Building wheel for google-cloud-jupyter-config (setup.py): started\n",
      "  Building wheel for google-cloud-jupyter-config (setup.py): finished with status 'done'\n",
      "  Created wheel for google-cloud-jupyter-config: filename=google_cloud_jupyter_config-0.0.10-py2.py3-none-any.whl size=12007 sha256=6d343fe5228129c912a91bc64d3a8eb691ce3726404c1a501774fadd5f17dbfd\n",
      "  Stored in directory: /root/.cache/pip/wheels/39/de/c4/83340c241465da688cbfe2a7040deabb36b4eed6e7e863f368\n",
      "  Building wheel for gpustat (setup.py): started\n",
      "  Building wheel for gpustat (setup.py): finished with status 'done'\n",
      "  Created wheel for gpustat: filename=gpustat-1.0.0-py3-none-any.whl size=19863 sha256=f8af88d9e5ce433db8bb4d9e2b45c7ee114204adf9b994eebb1dbc0ead5608ac\n",
      "  Stored in directory: /root/.cache/pip/wheels/d2/48/27/33e31726d2001b997a11c23a7c76f7a48d8d96851f14ef0cd2\n",
      "  Building wheel for hdfs (setup.py): started\n",
      "  Building wheel for hdfs (setup.py): finished with status 'done'\n",
      "  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34324 sha256=e1d0752823cdf9d744491ddc6bfe37cc023958711ae0caa18f76a51f8f607d2b\n",
      "  Stored in directory: /root/.cache/pip/wheels/e5/8d/b6/99c1c0a3ac5788c866b0ecd3f48b0134a5910e6ed26011800b\n",
      "  Building wheel for htmlmin (setup.py): started\n",
      "  Building wheel for htmlmin (setup.py): finished with status 'done'\n",
      "  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27080 sha256=5a8da8728113e9bf949b1fc1da5980d750309ff113fb957f6ad84e08eb678827\n",
      "  Stored in directory: /root/.cache/pip/wheels/dd/91/29/a79cecb328d01739e64017b6fb9a1ab9d8cb1853098ec5966d\n",
      "  Building wheel for kfp (setup.py): started\n",
      "  Building wheel for kfp (setup.py): finished with status 'done'\n",
      "  Created wheel for kfp: filename=kfp-2.5.0-py3-none-any.whl size=585425 sha256=d946dbddde193e32247d11b1deb067151254f4101941e568c3aac9bfd8906127\n",
      "  Stored in directory: /root/.cache/pip/wheels/e4/fc/d8/a8b70c6fd81161556bb6659d7bd77080f0d2de9a66d067af5b\n",
      "  Building wheel for kfp-server-api (setup.py): started\n",
      "  Building wheel for kfp-server-api (setup.py): finished with status 'done'\n",
      "  Created wheel for kfp-server-api: filename=kfp_server_api-2.0.5-py3-none-any.whl size=114733 sha256=102ef6cbe05f4e872d719029730272b8c811b7773ce25fa1d6b6840e04e00e45\n",
      "  Stored in directory: /root/.cache/pip/wheels/ac/4f/f0/2f622aadcbf8921fb72d24f52efaffacc235f863c195c289c5\n",
      "  Building wheel for pyfarmhash (setup.py): started\n",
      "  Building wheel for pyfarmhash (setup.py): finished with status 'done'\n",
      "  Created wheel for pyfarmhash: filename=pyfarmhash-0.3.2-cp310-cp310-linux_x86_64.whl size=96694 sha256=88f7fef86418fd5fee3f6d3583a6e746d649ac5099dba1b2d0deb1605a63b2e3\n",
      "  Stored in directory: /root/.cache/pip/wheels/e0/08/da/f66b1f3258fe3f1e767b2136c5444dbfa9fa3f7944cc5e1983\n",
      "  Building wheel for pyjsparser (setup.py): started\n",
      "  Building wheel for pyjsparser (setup.py): finished with status 'done'\n",
      "  Created wheel for pyjsparser: filename=pyjsparser-2.7.1-py3-none-any.whl size=25984 sha256=c67ae82e3c2204337ab4fd6fe41961dd14365a347be9ac4afbdcbc0f69475e31\n",
      "  Stored in directory: /root/.cache/pip/wheels/5e/81/26/5956478df303e2bf5a85a5df595bb307bd25948a4bab69f7c7\n",
      "  Building wheel for rouge_score (setup.py): started\n",
      "  Building wheel for rouge_score (setup.py): finished with status 'done'\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=a9fb4d9be7ce14af0e8ec7fcac69edd3eaa21dfaab510c98a2d2aca99f8000b4\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "  Building wheel for tensorrt (setup.py): started\n",
      "  Building wheel for tensorrt (setup.py): finished with status 'done'\n",
      "  Created wheel for tensorrt: filename=tensorrt-10.1.0-py2.py3-none-any.whl size=16332 sha256=701161ac898da3e772f966ad36ea23ddfd98d304bcf4c0daf8e054997058149d\n",
      "  Stored in directory: /root/.cache/pip/wheels/f5/55/f5/a1836546c0d92da062e9365a0323953f5e6a0a5f51d46da503\n",
      "  Building wheel for tensorrt-cu12 (setup.py): started\n",
      "  Building wheel for tensorrt-cu12 (setup.py): finished with status 'done'\n",
      "  Created wheel for tensorrt-cu12: filename=tensorrt_cu12-10.1.0-py2.py3-none-any.whl size=17554 sha256=634b6a317dfd005717d8152c58c7ba092a25c2e33fd397fc3c60d37bd21a9686\n",
      "  Stored in directory: /root/.cache/pip/wheels/15/96/43/6559f5cfe251d64e7a7b49efb429ae5258eff95976e5f12312\n",
      "  Building wheel for tensorrt-cu12-libs (pyproject.toml): started\n",
      "  Building wheel for tensorrt-cu12-libs (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for tensorrt-cu12-libs: filename=tensorrt_cu12_libs-10.1.0-py2.py3-none-manylinux_2_17_x86_64.whl size=1056270840 sha256=1ad13c26b3f441267a746df6859e44eb0e8da78d4382458d1fd2eb7675abd49f\n",
      "  Stored in directory: /root/.cache/pip/wheels/18/d0/78/3c2ad1c46e9434a528a07e9d9b8402a96c9a4d55fa2aca0773\n",
      "  Building wheel for kernels-mixer (setup.py): started\n",
      "  Building wheel for kernels-mixer (setup.py): finished with status 'done'\n",
      "  Created wheel for kernels-mixer: filename=kernels_mixer-0.0.13-py3-none-any.whl size=17112 sha256=26bb90318be97d0e6a268e5053d387e9af25a96520290a0954889ab5481a3948\n",
      "  Stored in directory: /root/.cache/pip/wheels/fe/45/f1/1ad21aec6b13be1dd8dc8404c1596030367a14da5c06970d65\n",
      "Successfully built crcmod dill docopt google-apitools google-cloud-jupyter-config gpustat hdfs htmlmin kfp kfp-server-api pyfarmhash pyjsparser rouge_score tensorrt tensorrt-cu12 tensorrt-cu12-libs kernels-mixer\n",
      "Installing collected packages: y-py, webencodings, wcwidth, tensorrt-cu12-bindings, pytz, pyjsparser, pyfarmhash, py-spy, ptyprocess, pickleshare, opencensus-context, nvidia-ml-py, namex, multipledispatch, libclang, kt-legacy, ipython-genutils, htmlmin, flatbuffers, fastjsonschema, Farama-Notifications, docopt, dm-tree, distlib, crcmod, colorful, backcall, appdirs, ansicolors, zstandard, zipp, xxhash, wurlitzer, wrapt, websockets, websocket-client, webcolors, uvloop, urllib3, uritemplate, uri-template, ujson, uc-micro-py, tzlocal, tzdata, typing-extensions, types-python-dateutil, traitlets, tqdm, tornado, toolz, tomli, tinycss2, threadpoolctl, termcolor, tensorrt-cu12, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, tenacity, tangled-up-in-unicode, tabulate, sqlparse, sqlglot, soupsieve, sniffio, smmap, six, simpervisor, shellingham, send2trash, rpds-py, rfc3986-validator, regex, ray-cpp, pyzmq, pyyaml, python-multipart, python-json-logger, python-dotenv, pyparsing, PyJWT, pygments, pycparser, pyasn1, pyarrow-hotfix, psutil, protobuf, prompt-toolkit, prometheus-client, prettytable, portalocker, pluggy, platformdirs, pillow, pexpect, parsy, parso, pandocfilters, packaging, overrides, orjson, objsize, oauthlib, nvidia-cuda-runtime-cu12, numpy, networkx, nest-asyncio, multimethod, multidict, msgpack, more-itertools, mistune, mdurl, MarkupSafe, Markdown, lz4, lxml, llvmlite, kiwisolver, keras, jupyterlab_widgets, jupyterlab-pygments, jupyter-ydoc, jsonpointer, jsonpickle, json5, joblib, jeepney, iniconfig, importlib-resources, idna, hypertune, humanize, httptools, h11, grpcio, greenlet, google-crc32c, gast, fsspec, frozenlist, fqdn, fonttools, filelock, fasteners, fastavro, exceptiongroup, entrypoints, docstring_parser, dnspython, dill, defusedxml, decorator, debugpy, dacite, Cython, cycler, colorama, cloudpickle, click, charset-normalizer, certifi, cachetools, bidict, backports.tarfile, Babel, attrs, atpublic, async-timeout, aiofiles, absl-py, ydf, yarl, Werkzeug, virtualenv, uvicorn, typeguard, tifffile, terminado, tensorrt-cu12-libs, tensorrt, tensorflow-metadata, tensorflow-hub, tensorboardX, SQLAlchemy, smart-open, shapely, scipy, sacrebleu, rsa, rfc3339-validator, retrying, requests, referencing, redis, PyWavelets, python-dateutil, pytest, pyproj, pymongo, pydot, pydantic, pyasn1_modules, pyarrow, proto-plus, portpicker, plotly, patsy, optree, opt-einsum, opentelemetry-proto, numba, nltk, ml-metadata, ml-dtypes, matplotlib-inline, markdown-it-py, linkify-it-py, lazy_loader, kfp-pipeline-spec, jupyter-core, Js2Py, jinja2, jedi, jax-jumpy, jaraco.functools, jaraco.context, jaraco.classes, importlib-metadata, imageio, httplib2, httpcore, h5py, gviz-api, grpc-interceptor, googleapis-common-protos, google-resumable-media, google-pasta, gitdb, email_validator, Deprecated, contourpy, comm, cligj, click-plugins, cffi, blessed, bleach, beautifulsoup4, async-lru, astunparse, anyio, aiosqlite, aiosignal, ypy-websocket, yarg, watchfiles, time-machine, tensorboard_plugin_profile, starlette, scikit-learn, scikit-image, rouge_score, rich, requests-toolbelt, requests-oauthlib, pandas, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, oauth2client, mdit-py-plugins, matplotlib, kfp-server-api, keras-tuner, jupyter-server-terminals, jupyter-client, jsonschema-specifications, ipython, ImageHash, httpx, hdfs, gymnasium, grpcio-status, gpustat, google-auth, GitPython, fiona, docker, cryptography, brotlipy, arrow, argon2-cffi-bindings, aiohttp, wordcloud, visions, typer, statsmodels, SecretStorage, seaborn, pins, phik, pendulum, opentelemetry-semantic-conventions, kubernetes, jsonschema, isoduration, ipykernel, grpc-google-iam-v1, google-auth-oauthlib, google-auth-httplib2, google-apitools, google-api-core, geopandas, db-dtypes, argon2-cffi, aiohttp-cors, textual, tensorboard, ray, pydata-google-auth, opentelemetry-sdk, opencensus, nbformat, keyring, google-cloud-core, google-api-python-client, apache-beam, ydata-profiling, tensorflow, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, nbclient, ml-pipelines-sdk, memray, keyrings.google-artifactregistry-auth, jupytext, jupyter-events, google-cloud-vision, google-cloud-videointelligence, google-cloud-storage, google-cloud-spanner, google-cloud-resource-manager, google-cloud-recommendations-ai, google-cloud-pubsub, google-cloud-monitoring, google-cloud-language, google-cloud-iam, google-cloud-functions, google-cloud-dlp, google-cloud-datastore, google-cloud-bigtable, google-cloud-bigquery-storage, google-cloud-bigquery-connection, google-cloud-bigquery, google-cloud-artifact-registry, tf_keras, tensorflow-serving-api, struct2tensor, papermill, pandas-profiling, opentelemetry-exporter-otlp, nbconvert, kfp, google-cloud-pubsublite, google-cloud-aiplatform, gcsfs, jupyter-server, tfx-bsl, notebook-shim, jupyterlab_server, jupyter_server_proxy, jupyter-server-mathjax, jupyter_server_fileid, jupyter-lsp, ibis-framework, google-cloud-jupyter-config, tensorflow-transform, tensorflow-data-validation, nbdime, kernels-mixer, jupyterlab, jupyter_server_ydoc, notebook, jupyterlab_git, widgetsnbextension, jupyter-http-over-ws, ipywidgets, tensorflow_model_analysis, bigframes, tfx, dataproc_jupyter_plugin\n",
      "Successfully installed Babel-2.15.0 Cython-3.0.10 Deprecated-1.2.14 Farama-Notifications-0.0.4 GitPython-3.1.43 ImageHash-4.3.1 Js2Py-0.74 Markdown-3.6 MarkupSafe-2.1.5 PyJWT-2.8.0 PyWavelets-1.6.0 SQLAlchemy-2.0.30 SecretStorage-3.3.3 Werkzeug-3.0.3 absl-py-1.4.0 aiofiles-22.1.0 aiohttp-3.9.5 aiohttp-cors-0.7.0 aiosignal-1.3.1 aiosqlite-0.20.0 ansicolors-1.1.8 anyio-4.4.0 apache-beam-2.56.0 appdirs-1.4.4 argon2-cffi-23.1.0 argon2-cffi-bindings-21.2.0 arrow-1.3.0 astunparse-1.6.3 async-lru-2.0.4 async-timeout-4.0.3 atpublic-4.1.0 attrs-23.2.0 backcall-0.2.0 backports.tarfile-1.2.0 beautifulsoup4-4.12.3 bidict-0.23.1 bigframes-0.22.0 bleach-6.1.0 blessed-1.20.0 brotlipy-0.7.0 cachetools-5.3.3 certifi-2024.6.2 cffi-1.16.0 charset-normalizer-3.3.2 click-8.1.7 click-plugins-1.1.1 cligj-0.7.2 cloudpickle-2.2.1 colorama-0.4.6 colorful-0.5.6 comm-0.2.2 contourpy-1.2.1 crcmod-1.7 cryptography-42.0.8 cycler-0.12.1 dacite-1.8.1 dataproc_jupyter_plugin-0.1.79 db-dtypes-1.2.0 debugpy-1.8.2 decorator-5.1.1 defusedxml-0.7.1 dill-0.3.1.1 distlib-0.3.8 dm-tree-0.1.8 dnspython-2.6.1 docker-4.4.4 docopt-0.6.2 docstring_parser-0.16 email_validator-2.1.1 entrypoints-0.4 exceptiongroup-1.2.1 fastavro-1.9.4 fasteners-0.19 fastjsonschema-2.20.0 filelock-3.15.1 fiona-1.9.6 flatbuffers-24.3.25 fonttools-4.53.0 fqdn-1.5.1 frozenlist-1.4.1 fsspec-2024.6.0 gast-0.4.0 gcsfs-2024.6.0 geopandas-0.14.4 gitdb-4.0.11 google-api-core-2.19.0 google-api-python-client-1.12.11 google-apitools-0.5.31 google-auth-2.30.0 google-auth-httplib2-0.2.0 google-auth-oauthlib-1.0.0 google-cloud-aiplatform-1.55.0 google-cloud-artifact-registry-1.11.3 google-cloud-bigquery-3.24.0 google-cloud-bigquery-connection-1.15.3 google-cloud-bigquery-storage-2.25.0 google-cloud-bigtable-2.24.0 google-cloud-core-2.4.1 google-cloud-datastore-2.19.0 google-cloud-dlp-3.18.0 google-cloud-functions-1.16.3 google-cloud-iam-2.15.0 google-cloud-jupyter-config-0.0.10 google-cloud-language-2.13.3 google-cloud-monitoring-2.21.0 google-cloud-pubsub-2.21.5 google-cloud-pubsublite-1.10.0 google-cloud-recommendations-ai-0.10.10 google-cloud-resource-manager-1.12.3 google-cloud-spanner-3.47.0 google-cloud-storage-2.14.0 google-cloud-videointelligence-2.13.3 google-cloud-vision-3.7.2 google-crc32c-1.5.0 google-pasta-0.2.0 google-resumable-media-2.7.1 googleapis-common-protos-1.63.1 gpustat-1.0.0 greenlet-3.0.3 grpc-google-iam-v1-0.13.0 grpc-interceptor-0.15.4 grpcio-1.64.1 grpcio-status-1.48.2 gviz-api-1.10.0 gymnasium-0.28.1 h11-0.14.0 h5py-3.11.0 hdfs-2.7.3 htmlmin-0.1.12 httpcore-1.0.5 httplib2-0.22.0 httptools-0.6.1 httpx-0.27.0 humanize-4.9.0 hypertune-1.1.0 ibis-framework-7.1.0 idna-3.7 imageio-2.34.1 importlib-metadata-7.1.0 importlib-resources-6.4.0 iniconfig-2.0.0 ipykernel-6.29.4 ipython-7.34.0 ipython-genutils-0.2.0 ipywidgets-7.7.1 isoduration-20.11.0 jaraco.classes-3.4.0 jaraco.context-5.3.0 jaraco.functools-4.0.1 jax-jumpy-1.0.0 jedi-0.19.1 jeepney-0.8.0 jinja2-3.1.4 joblib-1.4.2 json5-0.9.25 jsonpickle-3.2.2 jsonpointer-3.0.0 jsonschema-4.22.0 jsonschema-specifications-2023.12.1 jupyter-client-8.6.2 jupyter-core-5.7.2 jupyter-events-0.10.0 jupyter-http-over-ws-0.0.8 jupyter-lsp-2.2.5 jupyter-server-2.14.1 jupyter-server-mathjax-0.2.6 jupyter-server-terminals-0.5.3 jupyter-ydoc-0.2.5 jupyter_server_fileid-0.9.2 jupyter_server_proxy-4.2.0 jupyter_server_ydoc-0.8.0 jupyterlab-4.2.3 jupyterlab-pygments-0.3.0 jupyterlab_git-0.44.0 jupyterlab_server-2.27.2 jupyterlab_widgets-3.0.11 jupytext-1.16.2 keras-2.15.0 keras-tuner-1.4.7 kernels-mixer-0.0.13 keyring-25.2.1 keyrings.google-artifactregistry-auth-1.1.2 kfp-2.5.0 kfp-pipeline-spec-0.2.2 kfp-server-api-2.0.5 kiwisolver-1.4.5 kt-legacy-1.0.5 kubernetes-12.0.1 lazy_loader-0.4 libclang-18.1.1 linkify-it-py-2.0.3 llvmlite-0.41.1 lxml-5.2.2 lz4-4.3.3 markdown-it-py-3.0.0 matplotlib-3.7.3 matplotlib-inline-0.1.7 mdit-py-plugins-0.4.1 mdurl-0.1.2 memray-1.12.0 mistune-3.0.2 ml-dtypes-0.3.2 ml-metadata-1.15.0 ml-pipelines-sdk-1.15.1 more-itertools-10.3.0 msgpack-1.0.8 multidict-6.0.5 multimethod-1.11.2 multipledispatch-1.0.0 namex-0.0.8 nbclient-0.10.0 nbconvert-7.16.4 nbdime-3.2.0 nbformat-5.10.4 nest-asyncio-1.6.0 networkx-3.3 nltk-3.8.1 notebook-7.2.1 notebook-shim-0.2.4 numba-0.58.1 numpy-1.24.3 nvidia-cuda-runtime-cu12-12.5.39 nvidia-ml-py-11.495.46 oauth2client-4.1.3 oauthlib-3.2.2 objsize-0.7.0 opencensus-0.11.4 opencensus-context-0.1.3 opentelemetry-api-1.25.0 opentelemetry-exporter-otlp-1.25.0 opentelemetry-exporter-otlp-proto-common-1.25.0 opentelemetry-exporter-otlp-proto-grpc-1.25.0 opentelemetry-exporter-otlp-proto-http-1.25.0 opentelemetry-proto-1.25.0 opentelemetry-sdk-1.25.0 opentelemetry-semantic-conventions-0.46b0 opt-einsum-3.3.0 optree-0.11.0 orjson-3.10.5 overrides-7.7.0 packaging-24.1 pandas-1.5.3 pandas-profiling-3.6.6 pandocfilters-1.5.1 papermill-2.6.0 parso-0.8.4 parsy-2.1 patsy-0.5.6 pendulum-3.0.0 pexpect-4.9.0 phik-0.12.4 pickleshare-0.7.5 pillow-10.3.0 pins-0.8.6 platformdirs-4.2.2 plotly-5.22.0 pluggy-1.5.0 portalocker-2.10.0 portpicker-1.6.0 prettytable-3.10.0 prometheus-client-0.20.0 prompt-toolkit-3.0.47 proto-plus-1.23.0 protobuf-3.20.3 psutil-5.9.3 ptyprocess-0.7.0 py-spy-0.3.14 pyarrow-10.0.1 pyarrow-hotfix-0.6 pyasn1-0.6.0 pyasn1_modules-0.4.0 pycparser-2.22 pydantic-1.10.16 pydata-google-auth-1.8.2 pydot-1.4.2 pyfarmhash-0.3.2 pygments-2.18.0 pyjsparser-2.7.1 pymongo-4.7.3 pyparsing-3.1.2 pyproj-3.6.1 pytest-8.2.2 python-dateutil-2.9.0.post0 python-dotenv-1.0.1 python-json-logger-2.0.7 python-multipart-0.0.9 pytz-2024.1 pyyaml-6.0.1 pyzmq-26.0.3 ray-2.24.0 ray-cpp-2.24.0 redis-5.0.6 referencing-0.35.1 regex-2024.5.15 requests-2.32.3 requests-oauthlib-2.0.0 requests-toolbelt-0.10.1 retrying-1.3.4 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rich-13.7.1 rouge_score-0.1.2 rpds-py-0.18.1 rsa-4.9 sacrebleu-2.4.2 scikit-image-0.23.2 scikit-learn-1.5.0 scipy-1.11.4 seaborn-0.12.2 send2trash-1.8.3 shapely-2.0.4 shellingham-1.5.4 simpervisor-1.0.0 six-1.16.0 smart-open-7.0.4 smmap-5.0.1 sniffio-1.3.1 soupsieve-2.5 sqlglot-19.9.0 sqlparse-0.5.0 starlette-0.37.2 statsmodels-0.14.2 struct2tensor-0.46.0 tabulate-0.9.0 tangled-up-in-unicode-0.2.0 tenacity-8.3.0 tensorboard-2.15.2 tensorboard-data-server-0.7.2 tensorboardX-2.6.2.2 tensorboard_plugin_profile-2.15.1 tensorflow-2.15.1 tensorflow-data-validation-1.15.1 tensorflow-estimator-2.15.0 tensorflow-hub-0.15.0 tensorflow-io-gcs-filesystem-0.37.0 tensorflow-metadata-1.15.0 tensorflow-serving-api-2.15.1 tensorflow-transform-1.15.0 tensorflow_model_analysis-0.46.0 tensorrt-10.1.0 tensorrt-cu12-10.1.0 tensorrt-cu12-bindings-10.1.0 tensorrt-cu12-libs-10.1.0 termcolor-2.4.0 terminado-0.18.1 textual-0.67.1 tf_keras-2.15.1 tfx-1.15.1 tfx-bsl-1.15.1 threadpoolctl-3.5.0 tifffile-2024.5.22 time-machine-2.14.1 tinycss2-1.3.0 tomli-2.0.1 toolz-0.12.1 tornado-6.4.1 tqdm-4.66.4 traitlets-5.14.3 typeguard-4.3.0 typer-0.12.3 types-python-dateutil-2.9.0.20240316 typing-extensions-4.12.2 tzdata-2024.1 tzlocal-5.2 uc-micro-py-1.0.3 ujson-5.10.0 uri-template-1.3.0 uritemplate-3.0.1 urllib3-1.26.18 uvicorn-0.30.1 uvloop-0.19.0 virtualenv-20.26.2 visions-0.7.5 watchfiles-0.22.0 wcwidth-0.2.13 webcolors-24.6.0 webencodings-0.5.1 websocket-client-1.8.0 websockets-12.0 widgetsnbextension-3.6.6 wordcloud-1.9.3 wrapt-1.14.1 wurlitzer-3.1.1 xxhash-3.4.1 y-py-0.6.2 yarg-0.1.9 yarl-1.9.4 ydata-profiling-4.6.0 ydf-0.5.0 ypy-websocket-0.8.4 zipp-3.19.2 zstandard-0.22.0\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "\u001b[0mRemoving intermediate container d857acae7924\n",
      " ---> 76f75373024d\n",
      "Step 6/7 : COPY src/ src/\n",
      " ---> 44093075c8a6\n",
      "Step 7/7 : ENV PYTHONPATH=\"/pipeline:${PYTHONPATH}\"\n",
      " ---> Running in 82af4a6acc52\n",
      "Removing intermediate container 82af4a6acc52\n",
      " ---> fe08222388e0\n",
      "Successfully built fe08222388e0\n",
      "Successfully tagged gcr.io/supply-chain-twin-349311/chicago-taxi-tips:v09\n",
      "PUSH\n",
      "Pushing gcr.io/supply-chain-twin-349311/chicago-taxi-tips:v09\n",
      "The push refers to repository [gcr.io/supply-chain-twin-349311/chicago-taxi-tips]\n",
      "ea508595a942: Preparing\n",
      "63640fbeda89: Preparing\n",
      "b924177ac7dd: Preparing\n",
      "da6f25375332: Preparing\n",
      "db0f2ef1043a: Preparing\n",
      "2e7e15acc0c5: Preparing\n",
      "874337b0fe22: Preparing\n",
      "3796f8a4e35b: Preparing\n",
      "2da9904b909e: Preparing\n",
      "1387079e86ad: Preparing\n",
      "874337b0fe22: Waiting\n",
      "3796f8a4e35b: Waiting\n",
      "1387079e86ad: Waiting\n",
      "2e7e15acc0c5: Waiting\n",
      "2da9904b909e: Waiting\n",
      "ea508595a942: Pushed\n",
      "2e7e15acc0c5: Layer already exists\n",
      "b924177ac7dd: Pushed\n",
      "874337b0fe22: Layer already exists\n",
      "3796f8a4e35b: Layer already exists\n",
      "2da9904b909e: Layer already exists\n",
      "1387079e86ad: Layer already exists\n",
      "da6f25375332: Pushed\n",
      "db0f2ef1043a: Pushed\n",
      "63640fbeda89: Pushed\n",
      "v09: digest: sha256:850639ea7c70195bcda3902434c3c7373d54972dbfde1cdab9c74203be92ce00 size: 2425\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                                  IMAGES                                                 STATUS\n",
      "e0bc706b-d65f-4cfb-8b64-4eb0741047b4  2024-06-27T07:24:41+00:00  18M33S    gs://supply-chain-twin-349311_cloudbuild/source/1719473081.198917-78831b76eb1846178aecf1692ee0f2c8.tgz  gcr.io/supply-chain-twin-349311/chicago-taxi-tips:v09  SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!gcloud builds submit --tag $TFX_IMAGE_URI . --timeout=120m --machine-type=e2-highcpu-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14360770-1f77-48f8-9059-01ea30c87848",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "155568ca",
   "metadata": {},
   "source": [
    "### Compile pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c1d5ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "copying etl.py -> build/lib\n",
      "copying transformations.py -> build/lib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "!!\n",
      "\n",
      "        ********************************************************************************\n",
      "        Please avoid running ``setup.py`` directly.\n",
      "        Instead, use pypa/build, pypa/installer or other\n",
      "        standards-based tools.\n",
      "\n",
      "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "        ********************************************************************************\n",
      "\n",
      "!!\n",
      "  self.initialize_options()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "installing to /var/tmp/tmpwne5cfgy\n",
      "running install\n",
      "running install_lib\n",
      "copying build/lib/etl.py -> /var/tmp/tmpwne5cfgy\n",
      "copying build/lib/transformations.py -> /var/tmp/tmpwne5cfgy\n",
      "running install_egg_info\n",
      "running egg_info\n",
      "creating tfx_user_code_DataTransformer.egg-info\n",
      "writing tfx_user_code_DataTransformer.egg-info/PKG-INFO\n",
      "writing dependency_links to tfx_user_code_DataTransformer.egg-info/dependency_links.txt\n",
      "writing top-level names to tfx_user_code_DataTransformer.egg-info/top_level.txt\n",
      "writing manifest file 'tfx_user_code_DataTransformer.egg-info/SOURCES.txt'\n",
      "reading manifest file 'tfx_user_code_DataTransformer.egg-info/SOURCES.txt'\n",
      "writing manifest file 'tfx_user_code_DataTransformer.egg-info/SOURCES.txt'\n",
      "Copying tfx_user_code_DataTransformer.egg-info to /var/tmp/tmpwne5cfgy/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3.10.egg-info\n",
      "running install_scripts\n",
      "creating /var/tmp/tmpwne5cfgy/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d.dist-info/WHEEL\n",
      "creating '/var/tmp/tmpjo0g98sg/tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d-py3-none-any.whl' and adding '/var/tmp/tmpwne5cfgy' to it\n",
      "adding 'etl.py'\n",
      "adding 'transformations.py'\n",
      "adding 'tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d.dist-info/METADATA'\n",
      "adding 'tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d.dist-info/WHEEL'\n",
      "adding 'tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d.dist-info/top_level.txt'\n",
      "adding 'tfx_user_code_DataTransformer-0.0+de07c8431e7a29dced215501daf4f187c64541d3189d2529c8a52c51eb6c9d4d.dist-info/RECORD'\n",
      "removing /var/tmp/tmpwne5cfgy\n",
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "copying exporter.py -> build/lib\n",
      "copying task.py -> build/lib\n",
      "copying trainer.py -> build/lib\n",
      "copying runner.py -> build/lib\n",
      "copying model.py -> build/lib\n",
      "copying data.py -> build/lib\n",
      "copying defaults.py -> build/lib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "!!\n",
      "\n",
      "        ********************************************************************************\n",
      "        Please avoid running ``setup.py`` directly.\n",
      "        Instead, use pypa/build, pypa/installer or other\n",
      "        standards-based tools.\n",
      "\n",
      "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "        ********************************************************************************\n",
      "\n",
      "!!\n",
      "  self.initialize_options()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "installing to /var/tmp/tmp3nf8lmrf\n",
      "running install\n",
      "running install_lib\n",
      "copying build/lib/exporter.py -> /var/tmp/tmp3nf8lmrf\n",
      "copying build/lib/data.py -> /var/tmp/tmp3nf8lmrf\n",
      "copying build/lib/model.py -> /var/tmp/tmp3nf8lmrf\n",
      "copying build/lib/runner.py -> /var/tmp/tmp3nf8lmrf\n",
      "copying build/lib/trainer.py -> /var/tmp/tmp3nf8lmrf\n",
      "copying build/lib/task.py -> /var/tmp/tmp3nf8lmrf\n",
      "copying build/lib/defaults.py -> /var/tmp/tmp3nf8lmrf\n",
      "running install_egg_info\n",
      "running egg_info\n",
      "creating tfx_user_code_ModelTrainer.egg-info\n",
      "writing tfx_user_code_ModelTrainer.egg-info/PKG-INFO\n",
      "writing dependency_links to tfx_user_code_ModelTrainer.egg-info/dependency_links.txt\n",
      "writing top-level names to tfx_user_code_ModelTrainer.egg-info/top_level.txt\n",
      "writing manifest file 'tfx_user_code_ModelTrainer.egg-info/SOURCES.txt'\n",
      "reading manifest file 'tfx_user_code_ModelTrainer.egg-info/SOURCES.txt'\n",
      "writing manifest file 'tfx_user_code_ModelTrainer.egg-info/SOURCES.txt'\n",
      "Copying tfx_user_code_ModelTrainer.egg-info to /var/tmp/tmp3nf8lmrf/tfx_user_code_ModelTrainer-0.0+88cee01a077ea7ce1a9871764b3718ea318b1da2b217190de116232b22159367-py3.10.egg-info\n",
      "running install_scripts\n",
      "creating /var/tmp/tmp3nf8lmrf/tfx_user_code_ModelTrainer-0.0+88cee01a077ea7ce1a9871764b3718ea318b1da2b217190de116232b22159367.dist-info/WHEEL\n",
      "creating '/var/tmp/tmppb7gcwwi/tfx_user_code_ModelTrainer-0.0+88cee01a077ea7ce1a9871764b3718ea318b1da2b217190de116232b22159367-py3-none-any.whl' and adding '/var/tmp/tmp3nf8lmrf' to it\n",
      "adding 'data.py'\n",
      "adding 'defaults.py'\n",
      "adding 'exporter.py'\n",
      "adding 'model.py'\n",
      "adding 'runner.py'\n",
      "adding 'task.py'\n",
      "adding 'trainer.py'\n",
      "adding 'tfx_user_code_ModelTrainer-0.0+88cee01a077ea7ce1a9871764b3718ea318b1da2b217190de116232b22159367.dist-info/METADATA'\n",
      "adding 'tfx_user_code_ModelTrainer-0.0+88cee01a077ea7ce1a9871764b3718ea318b1da2b217190de116232b22159367.dist-info/WHEEL'\n",
      "adding 'tfx_user_code_ModelTrainer-0.0+88cee01a077ea7ce1a9871764b3718ea318b1da2b217190de116232b22159367.dist-info/top_level.txt'\n",
      "adding 'tfx_user_code_ModelTrainer-0.0+88cee01a077ea7ce1a9871764b3718ea318b1da2b217190de116232b22159367.dist-info/RECORD'\n",
      "removing /var/tmp/tmp3nf8lmrf\n"
     ]
    }
   ],
   "source": [
    "from src.tfx_pipelines import runner\n",
    "\n",
    "pipeline_definition_file = f'{config.PIPELINE_NAME}.json'\n",
    "pipeline_definition = runner.compile_training_pipeline(pipeline_definition_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6644c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://chicago-taxi-tips-classifier-v09-train-pipeline.json [Content-Type=application/json]...\n",
      "/ [1 files][ 26.8 KiB/ 26.8 KiB]                                                \n",
      "Operation completed over 1 objects/26.8 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "PIPELINES_STORE = f\"gs://{BUCKET}/{DATASET_DISPLAY_NAME}/compiled_pipelines/\"\n",
    "!gsutil cp {pipeline_definition_file} {PIPELINES_STORE}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcb943e",
   "metadata": {
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62c6b0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob created. Resource name: projects/1049330678395/locations/us-central1/pipelineJobs/chicago-taxi-tips-classifier-v09-train-pipeline-20240627084403\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:To use this PipelineJob in another session:\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:pipeline_job = aiplatform.PipelineJob.get('projects/1049330678395/locations/us-central1/pipelineJobs/chicago-taxi-tips-classifier-v09-train-pipeline-20240627084403')\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/chicago-taxi-tips-classifier-v09-train-pipeline-20240627084403?project=1049330678395\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "pipeline_client = aiplatform.init(\n",
    "    project=PROJECT, location=REGION)\n",
    "job= aiplatform.PipelineJob(\n",
    "    display_name='chicago-taxi-tips',\n",
    "    template_path=pipeline_definition_file,\n",
    "    parameter_values={\n",
    "        'learning_rate': 0.003,\n",
    "        'batch_size': 512,\n",
    "        'hidden_units': '128,128',\n",
    "        'num_epochs': 30,\n",
    "    }\n",
    ")\n",
    "job.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888be1fd",
   "metadata": {},
   "source": [
    "### Extracting pipeline runs metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fc28135-b2f7-4d3b-9b92-c18572c008f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chicago-taxi-tips-classifier-v09-train-pipeline\n"
     ]
    }
   ],
   "source": [
    "print(PIPELINE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37ae4aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pipeline_name</th>\n",
       "      <td>chicago-taxi-tips-classifier-v09-train-pipeline</td>\n",
       "      <td>chicago-taxi-tips-classifier-v09-train-pipeline</td>\n",
       "      <td>chicago-taxi-tips-classifier-v09-train-pipeline</td>\n",
       "      <td>chicago-taxi-tips-classifier-v09-train-pipeline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run_name</th>\n",
       "      <td>chicago-taxi-tips-classifier-v09-train-pipelin...</td>\n",
       "      <td>chicago-taxi-tips-classifier-v09-train-pipelin...</td>\n",
       "      <td>chicago-taxi-tips-classifier-v09-train-pipelin...</td>\n",
       "      <td>chicago-taxi-tips-classifier-v09-train-pipelin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param.input:hidden_units</th>\n",
       "      <td>128,128</td>\n",
       "      <td>128,128</td>\n",
       "      <td>128,128</td>\n",
       "      <td>128,128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param.input:batch_size</th>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param.input:learning_rate</th>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param.input:num_epochs</th>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param.vmlmd_lineage_integration</th>\n",
       "      <td>{'pipeline_run_component': {'location_id': 'us...</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>{'pipeline_run_component': {'parent_task_names...</td>\n",
       "      <td>{'pipeline_run_component': {'task_name': 'chic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                 0  \\\n",
       "pipeline_name                      chicago-taxi-tips-classifier-v09-train-pipeline   \n",
       "run_name                         chicago-taxi-tips-classifier-v09-train-pipelin...   \n",
       "param.input:hidden_units                                                   128,128   \n",
       "param.input:batch_size                                                         512   \n",
       "param.input:learning_rate                                                    0.003   \n",
       "param.input:num_epochs                                                          30   \n",
       "param.vmlmd_lineage_integration  {'pipeline_run_component': {'location_id': 'us...   \n",
       "\n",
       "                                                                                 1  \\\n",
       "pipeline_name                      chicago-taxi-tips-classifier-v09-train-pipeline   \n",
       "run_name                         chicago-taxi-tips-classifier-v09-train-pipelin...   \n",
       "param.input:hidden_units                                                   128,128   \n",
       "param.input:batch_size                                                         512   \n",
       "param.input:learning_rate                                                    0.003   \n",
       "param.input:num_epochs                                                          30   \n",
       "param.vmlmd_lineage_integration  {'pipeline_run_component': {'parent_task_names...   \n",
       "\n",
       "                                                                                 2  \\\n",
       "pipeline_name                      chicago-taxi-tips-classifier-v09-train-pipeline   \n",
       "run_name                         chicago-taxi-tips-classifier-v09-train-pipelin...   \n",
       "param.input:hidden_units                                                   128,128   \n",
       "param.input:batch_size                                                         512   \n",
       "param.input:learning_rate                                                    0.003   \n",
       "param.input:num_epochs                                                          30   \n",
       "param.vmlmd_lineage_integration  {'pipeline_run_component': {'parent_task_names...   \n",
       "\n",
       "                                                                                 3  \n",
       "pipeline_name                      chicago-taxi-tips-classifier-v09-train-pipeline  \n",
       "run_name                         chicago-taxi-tips-classifier-v09-train-pipelin...  \n",
       "param.input:hidden_units                                                   128,128  \n",
       "param.input:batch_size                                                         512  \n",
       "param.input:learning_rate                                                    0.003  \n",
       "param.input:num_epochs                                                          30  \n",
       "param.vmlmd_lineage_integration  {'pipeline_run_component': {'task_name': 'chic...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.cloud import aiplatform as vertex_ai\n",
    "\n",
    "pipeline_df = vertex_ai.get_pipeline_df(PIPELINE_NAME)\n",
    "pipeline_df = pipeline_df[pipeline_df.pipeline_name == PIPELINE_NAME]\n",
    "pipeline_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b454fe9",
   "metadata": {},
   "source": [
    "## 3. Execute the pipeline deployment CI/CD steps in Cloud Build\n",
    "\n",
    "The CI/CD routine is defined in the [pipeline-deployment.yaml](build/pipeline-deployment.yaml) file, and consists of the following steps:\n",
    "1. Clone the repository to the build environment.\n",
    "2. Run unit tests.\n",
    "3. Run a local e2e test of the pipeline.\n",
    "4. Build the ML container image for pipeline steps.\n",
    "5. Compile the pipeline.\n",
    "6. Upload the pipeline to Cloud Storage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29688d4d",
   "metadata": {},
   "source": [
    "### Build CI/CD container Image for Cloud Build\n",
    "\n",
    "This is the runtime environment where the steps of testing and deploying the pipeline will be executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e04ec52-4e1a-4eb2-b9f1-ce250252c019",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ls -R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9131888-2a5f-433e-9d2a-26d5f9c75142",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(CICD_IMAGE_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4759b85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcr.io/supply-chain-twin-349311/cicd:latest\n"
     ]
    }
   ],
   "source": [
    "!echo $CICD_IMAGE_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4fc09c3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary archive of 9 file(s) totalling 26.8 KiB before compression.\n",
      "Uploading tarball of [build/.] to [gs://supply-chain-twin-349311_cloudbuild/source/1719496246.867131-112571afb80e469e8c0f76ff3c2b9cc5.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/supply-chain-twin-349311/locations/global/builds/63c7c485-2b52-4e3f-a5cc-941a1ea5ad84].\n",
      "Logs are available at [ https://console.cloud.google.com/cloud-build/builds/63c7c485-2b52-4e3f-a5cc-941a1ea5ad84?project=1049330678395 ].\n",
      "Waiting for build to complete. Polling interval: 1 second(s).\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"63c7c485-2b52-4e3f-a5cc-941a1ea5ad84\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://supply-chain-twin-349311_cloudbuild/source/1719496246.867131-112571afb80e469e8c0f76ff3c2b9cc5.tgz#1719496247243495\n",
      "Copying gs://supply-chain-twin-349311_cloudbuild/source/1719496246.867131-112571afb80e469e8c0f76ff3c2b9cc5.tgz#1719496247243495...\n",
      "/ [1 files][  6.0 KiB/  6.0 KiB]                                                \n",
      "Operation completed over 1 objects/6.0 KiB.\n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon  35.33kB\n",
      "Step 1/6 : FROM python:3.10-slim AS builder\n",
      "3.10-slim: Pulling from library/python\n",
      "2cc3ae149d28: Already exists\n",
      "318623cc513b: Pulling fs layer\n",
      "05ac4be303fa: Pulling fs layer\n",
      "2306c655b011: Pulling fs layer\n",
      "769e3784f667: Pulling fs layer\n",
      "769e3784f667: Waiting\n",
      "318623cc513b: Verifying Checksum\n",
      "318623cc513b: Download complete\n",
      "2306c655b011: Download complete\n",
      "318623cc513b: Pull complete\n",
      "769e3784f667: Verifying Checksum\n",
      "769e3784f667: Download complete\n",
      "05ac4be303fa: Verifying Checksum\n",
      "05ac4be303fa: Download complete\n",
      "05ac4be303fa: Pull complete\n",
      "2306c655b011: Pull complete\n",
      "769e3784f667: Pull complete\n",
      "Digest: sha256:7de57d5840f51e10462ba0eed4c4e8aa26f28b44cedbf0fc8dd7fd77ea59c7d9\n",
      "Status: Downloaded newer image for python:3.10-slim\n",
      " ---> 6b73590883e6\n",
      "Step 2/6 : RUN apt-get update && apt-get install -y     build-essential     && apt-get clean     && rm -rf /var/lib/apt/lists/*\n",
      " ---> Running in 88ae187af46e\n",
      "Get:1 http://deb.debian.org/debian bookworm InRelease [151 kB]\n",
      "Get:2 http://deb.debian.org/debian bookworm-updates InRelease [55.4 kB]\n",
      "Get:3 http://deb.debian.org/debian-security bookworm-security InRelease [48.0 kB]\n",
      "Get:4 http://deb.debian.org/debian bookworm/main amd64 Packages [8786 kB]\n",
      "Get:5 http://deb.debian.org/debian bookworm-updates/main amd64 Packages [13.8 kB]\n",
      "Get:6 http://deb.debian.org/debian-security bookworm-security/main amd64 Packages [161 kB]\n",
      "Fetched 9215 kB in 1s (7235 kB/s)\n",
      "Reading package lists...\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following additional packages will be installed:\n",
      "  binutils binutils-common binutils-x86-64-linux-gnu bzip2 cpp cpp-12 dirmngr\n",
      "  dpkg-dev fakeroot fontconfig-config fonts-dejavu-core g++ g++-12 gcc gcc-12\n",
      "  gnupg gnupg-l10n gnupg-utils gpg gpg-agent gpg-wks-client gpg-wks-server\n",
      "  gpgconf gpgsm libabsl20220623 libalgorithm-diff-perl\n",
      "  libalgorithm-diff-xs-perl libalgorithm-merge-perl libaom3 libasan8\n",
      "  libassuan0 libatomic1 libavif15 libbinutils libbrotli1 libbsd0 libc-dev-bin\n",
      "  libc-devtools libc6-dev libcc1-0 libcrypt-dev libctf-nobfd0 libctf0\n",
      "  libdav1d6 libde265-0 libdeflate0 libdpkg-perl libfakeroot\n",
      "  libfile-fcntllock-perl libfontconfig1 libfreetype6 libgav1-1 libgcc-12-dev\n",
      "  libgd3 libgdbm-compat4 libgomp1 libgprofng0 libheif1 libisl23 libitm1\n",
      "  libjansson4 libjbig0 libjpeg62-turbo libksba8 libldap-2.5-0 libldap-common\n",
      "  liblerc4 liblocale-gettext-perl liblsan0 libmpc3 libmpfr6 libnpth0\n",
      "  libnsl-dev libnuma1 libperl5.36 libpng16-16 libquadmath0 librav1e0\n",
      "  libsasl2-2 libsasl2-modules libsasl2-modules-db libstdc++-12-dev\n",
      "  libsvtav1enc1 libtiff6 libtirpc-dev libtsan2 libubsan1 libwebp7 libx11-6\n",
      "  libx11-data libx265-199 libxau6 libxcb1 libxdmcp6 libxpm4 libyuv0\n",
      "  linux-libc-dev make manpages manpages-dev patch perl perl-modules-5.36\n",
      "  pinentry-curses rpcsvc-proto xz-utils\n",
      "Suggested packages:\n",
      "  binutils-doc bzip2-doc cpp-doc gcc-12-locales cpp-12-doc dbus-user-session\n",
      "  libpam-systemd pinentry-gnome3 tor debian-keyring g++-multilib\n",
      "  g++-12-multilib gcc-12-doc gcc-multilib autoconf automake libtool flex bison\n",
      "  gdb gcc-doc gcc-12-multilib parcimonie xloadimage scdaemon glibc-doc\n",
      "  sensible-utils git bzr libgd-tools libsasl2-modules-gssapi-mit\n",
      "  | libsasl2-modules-gssapi-heimdal libsasl2-modules-ldap libsasl2-modules-otp\n",
      "  libsasl2-modules-sql libstdc++-12-doc make-doc man-browser ed diffutils-doc\n",
      "  perl-doc libterm-readline-gnu-perl | libterm-readline-perl-perl\n",
      "  libtap-harness-archive-perl pinentry-doc\n",
      "The following NEW packages will be installed:\n",
      "  binutils binutils-common binutils-x86-64-linux-gnu build-essential bzip2 cpp\n",
      "  cpp-12 dirmngr dpkg-dev fakeroot fontconfig-config fonts-dejavu-core g++\n",
      "  g++-12 gcc gcc-12 gnupg gnupg-l10n gnupg-utils gpg gpg-agent gpg-wks-client\n",
      "  gpg-wks-server gpgconf gpgsm libabsl20220623 libalgorithm-diff-perl\n",
      "  libalgorithm-diff-xs-perl libalgorithm-merge-perl libaom3 libasan8\n",
      "  libassuan0 libatomic1 libavif15 libbinutils libbrotli1 libbsd0 libc-dev-bin\n",
      "  libc-devtools libc6-dev libcc1-0 libcrypt-dev libctf-nobfd0 libctf0\n",
      "  libdav1d6 libde265-0 libdeflate0 libdpkg-perl libfakeroot\n",
      "  libfile-fcntllock-perl libfontconfig1 libfreetype6 libgav1-1 libgcc-12-dev\n",
      "  libgd3 libgdbm-compat4 libgomp1 libgprofng0 libheif1 libisl23 libitm1\n",
      "  libjansson4 libjbig0 libjpeg62-turbo libksba8 libldap-2.5-0 libldap-common\n",
      "  liblerc4 liblocale-gettext-perl liblsan0 libmpc3 libmpfr6 libnpth0\n",
      "  libnsl-dev libnuma1 libperl5.36 libpng16-16 libquadmath0 librav1e0\n",
      "  libsasl2-2 libsasl2-modules libsasl2-modules-db libstdc++-12-dev\n",
      "  libsvtav1enc1 libtiff6 libtirpc-dev libtsan2 libubsan1 libwebp7 libx11-6\n",
      "  libx11-data libx265-199 libxau6 libxcb1 libxdmcp6 libxpm4 libyuv0\n",
      "  linux-libc-dev make manpages manpages-dev patch perl perl-modules-5.36\n",
      "  pinentry-curses rpcsvc-proto xz-utils\n",
      "0 upgraded, 107 newly installed, 0 to remove and 0 not upgraded.\n",
      "Need to get 98.3 MB of archives.\n",
      "After this operation, 389 MB of additional disk space will be used.\n",
      "Get:1 http://deb.debian.org/debian bookworm/main amd64 perl-modules-5.36 all 5.36.0-7+deb12u1 [2815 kB]\n",
      "Get:2 http://deb.debian.org/debian bookworm/main amd64 libgdbm-compat4 amd64 1.23-3 [48.2 kB]\n",
      "Get:3 http://deb.debian.org/debian bookworm/main amd64 libperl5.36 amd64 5.36.0-7+deb12u1 [4218 kB]\n",
      "Get:4 http://deb.debian.org/debian bookworm/main amd64 perl amd64 5.36.0-7+deb12u1 [239 kB]\n",
      "Get:5 http://deb.debian.org/debian bookworm/main amd64 liblocale-gettext-perl amd64 1.07-5 [15.4 kB]\n",
      "Get:6 http://deb.debian.org/debian bookworm/main amd64 bzip2 amd64 1.0.8-5+b1 [49.8 kB]\n",
      "Get:7 http://deb.debian.org/debian bookworm/main amd64 manpages all 6.03-2 [1332 kB]\n",
      "Get:8 http://deb.debian.org/debian bookworm/main amd64 xz-utils amd64 5.4.1-0.2 [471 kB]\n",
      "Get:9 http://deb.debian.org/debian bookworm/main amd64 binutils-common amd64 2.40-2 [2487 kB]\n",
      "Get:10 http://deb.debian.org/debian bookworm/main amd64 libbinutils amd64 2.40-2 [572 kB]\n",
      "Get:11 http://deb.debian.org/debian bookworm/main amd64 libctf-nobfd0 amd64 2.40-2 [153 kB]\n",
      "Get:12 http://deb.debian.org/debian bookworm/main amd64 libctf0 amd64 2.40-2 [89.8 kB]\n",
      "Get:13 http://deb.debian.org/debian bookworm/main amd64 libgprofng0 amd64 2.40-2 [812 kB]\n",
      "Get:14 http://deb.debian.org/debian bookworm/main amd64 libjansson4 amd64 2.14-2 [40.8 kB]\n",
      "Get:15 http://deb.debian.org/debian bookworm/main amd64 binutils-x86-64-linux-gnu amd64 2.40-2 [2246 kB]\n",
      "Get:16 http://deb.debian.org/debian bookworm/main amd64 binutils amd64 2.40-2 [65.0 kB]\n",
      "Get:17 http://deb.debian.org/debian-security bookworm-security/main amd64 libc-dev-bin amd64 2.36-9+deb12u7 [45.8 kB]\n",
      "Get:18 http://deb.debian.org/debian-security bookworm-security/main amd64 linux-libc-dev amd64 6.1.90-1 [1976 kB]\n",
      "Get:19 http://deb.debian.org/debian bookworm/main amd64 libcrypt-dev amd64 1:4.4.33-2 [118 kB]\n",
      "Get:20 http://deb.debian.org/debian bookworm/main amd64 libtirpc-dev amd64 1.3.3+ds-1 [191 kB]\n",
      "Get:21 http://deb.debian.org/debian bookworm/main amd64 libnsl-dev amd64 1.3.0-2 [66.4 kB]\n",
      "Get:22 http://deb.debian.org/debian bookworm/main amd64 rpcsvc-proto amd64 1.4.3-1 [63.3 kB]\n",
      "Get:23 http://deb.debian.org/debian-security bookworm-security/main amd64 libc6-dev amd64 2.36-9+deb12u7 [1899 kB]\n",
      "Get:24 http://deb.debian.org/debian bookworm/main amd64 libisl23 amd64 0.25-1.1 [683 kB]\n",
      "Get:25 http://deb.debian.org/debian bookworm/main amd64 libmpfr6 amd64 4.2.0-1 [701 kB]\n",
      "Get:26 http://deb.debian.org/debian bookworm/main amd64 libmpc3 amd64 1.3.1-1 [51.5 kB]\n",
      "Get:27 http://deb.debian.org/debian bookworm/main amd64 cpp-12 amd64 12.2.0-14 [9764 kB]\n",
      "Get:28 http://deb.debian.org/debian bookworm/main amd64 cpp amd64 4:12.2.0-3 [6836 B]\n",
      "Get:29 http://deb.debian.org/debian bookworm/main amd64 libcc1-0 amd64 12.2.0-14 [41.7 kB]\n",
      "Get:30 http://deb.debian.org/debian bookworm/main amd64 libgomp1 amd64 12.2.0-14 [116 kB]\n",
      "Get:31 http://deb.debian.org/debian bookworm/main amd64 libitm1 amd64 12.2.0-14 [26.1 kB]\n",
      "Get:32 http://deb.debian.org/debian bookworm/main amd64 libatomic1 amd64 12.2.0-14 [9328 B]\n",
      "Get:33 http://deb.debian.org/debian bookworm/main amd64 libasan8 amd64 12.2.0-14 [2195 kB]\n",
      "Get:34 http://deb.debian.org/debian bookworm/main amd64 liblsan0 amd64 12.2.0-14 [969 kB]\n",
      "Get:35 http://deb.debian.org/debian bookworm/main amd64 libtsan2 amd64 12.2.0-14 [2196 kB]\n",
      "Get:36 http://deb.debian.org/debian bookworm/main amd64 libubsan1 amd64 12.2.0-14 [883 kB]\n",
      "Get:37 http://deb.debian.org/debian bookworm/main amd64 libquadmath0 amd64 12.2.0-14 [144 kB]\n",
      "Get:38 http://deb.debian.org/debian bookworm/main amd64 libgcc-12-dev amd64 12.2.0-14 [2437 kB]\n",
      "Get:39 http://deb.debian.org/debian bookworm/main amd64 gcc-12 amd64 12.2.0-14 [19.3 MB]\n",
      "Get:40 http://deb.debian.org/debian bookworm/main amd64 gcc amd64 4:12.2.0-3 [5216 B]\n",
      "Get:41 http://deb.debian.org/debian bookworm/main amd64 libstdc++-12-dev amd64 12.2.0-14 [2046 kB]\n",
      "Get:42 http://deb.debian.org/debian bookworm/main amd64 g++-12 amd64 12.2.0-14 [10.7 MB]\n",
      "Get:43 http://deb.debian.org/debian bookworm/main amd64 g++ amd64 4:12.2.0-3 [1356 B]\n",
      "Get:44 http://deb.debian.org/debian bookworm/main amd64 make amd64 4.3-4.1 [396 kB]\n",
      "Get:45 http://deb.debian.org/debian bookworm/main amd64 libdpkg-perl all 1.21.22 [603 kB]\n",
      "Get:46 http://deb.debian.org/debian bookworm/main amd64 patch amd64 2.7.6-7 [128 kB]\n",
      "Get:47 http://deb.debian.org/debian bookworm/main amd64 dpkg-dev all 1.21.22 [1353 kB]\n",
      "Get:48 http://deb.debian.org/debian bookworm/main amd64 build-essential amd64 12.9 [7704 B]\n",
      "Get:49 http://deb.debian.org/debian bookworm/main amd64 libassuan0 amd64 2.5.5-5 [48.5 kB]\n",
      "Get:50 http://deb.debian.org/debian bookworm/main amd64 gpgconf amd64 2.2.40-1.1 [564 kB]\n",
      "Get:51 http://deb.debian.org/debian bookworm/main amd64 libksba8 amd64 1.6.3-2 [128 kB]\n",
      "Get:52 http://deb.debian.org/debian bookworm/main amd64 libsasl2-modules-db amd64 2.1.28+dfsg-10 [20.3 kB]\n",
      "Get:53 http://deb.debian.org/debian bookworm/main amd64 libsasl2-2 amd64 2.1.28+dfsg-10 [59.7 kB]\n",
      "Get:54 http://deb.debian.org/debian bookworm/main amd64 libldap-2.5-0 amd64 2.5.13+dfsg-5 [183 kB]\n",
      "Get:55 http://deb.debian.org/debian bookworm/main amd64 libnpth0 amd64 1.6-3 [19.0 kB]\n",
      "Get:56 http://deb.debian.org/debian bookworm/main amd64 dirmngr amd64 2.2.40-1.1 [792 kB]\n",
      "Get:57 http://deb.debian.org/debian bookworm/main amd64 libfakeroot amd64 1.31-1.2 [28.3 kB]\n",
      "Get:58 http://deb.debian.org/debian bookworm/main amd64 fakeroot amd64 1.31-1.2 [66.9 kB]\n",
      "Get:59 http://deb.debian.org/debian bookworm/main amd64 fonts-dejavu-core all 2.37-6 [1068 kB]\n",
      "Get:60 http://deb.debian.org/debian bookworm/main amd64 fontconfig-config amd64 2.14.1-4 [315 kB]\n",
      "Get:61 http://deb.debian.org/debian bookworm/main amd64 gnupg-l10n all 2.2.40-1.1 [1093 kB]\n",
      "Get:62 http://deb.debian.org/debian bookworm/main amd64 gnupg-utils amd64 2.2.40-1.1 [927 kB]\n",
      "Get:63 http://deb.debian.org/debian bookworm/main amd64 gpg amd64 2.2.40-1.1 [949 kB]\n",
      "Get:64 http://deb.debian.org/debian bookworm/main amd64 pinentry-curses amd64 1.2.1-1 [77.4 kB]\n",
      "Get:65 http://deb.debian.org/debian bookworm/main amd64 gpg-agent amd64 2.2.40-1.1 [695 kB]\n",
      "Get:66 http://deb.debian.org/debian bookworm/main amd64 gpg-wks-client amd64 2.2.40-1.1 [541 kB]\n",
      "Get:67 http://deb.debian.org/debian bookworm/main amd64 gpg-wks-server amd64 2.2.40-1.1 [531 kB]\n",
      "Get:68 http://deb.debian.org/debian bookworm/main amd64 gpgsm amd64 2.2.40-1.1 [671 kB]\n",
      "Get:69 http://deb.debian.org/debian bookworm/main amd64 gnupg all 2.2.40-1.1 [846 kB]\n",
      "Get:70 http://deb.debian.org/debian bookworm/main amd64 libabsl20220623 amd64 20220623.1-1 [391 kB]\n",
      "Get:71 http://deb.debian.org/debian bookworm/main amd64 libalgorithm-diff-perl all 1.201-1 [43.3 kB]\n",
      "Get:72 http://deb.debian.org/debian bookworm/main amd64 libalgorithm-diff-xs-perl amd64 0.04-8+b1 [11.4 kB]\n",
      "Get:73 http://deb.debian.org/debian bookworm/main amd64 libalgorithm-merge-perl all 0.08-5 [11.8 kB]\n",
      "Get:74 http://deb.debian.org/debian bookworm/main amd64 libaom3 amd64 3.6.0-1 [1851 kB]\n",
      "Get:75 http://deb.debian.org/debian-security bookworm-security/main amd64 libdav1d6 amd64 1.0.0-2+deb12u1 [513 kB]\n",
      "Get:76 http://deb.debian.org/debian bookworm/main amd64 libgav1-1 amd64 0.18.0-1+b1 [332 kB]\n",
      "Get:77 http://deb.debian.org/debian bookworm/main amd64 librav1e0 amd64 0.5.1-6 [763 kB]\n",
      "Get:78 http://deb.debian.org/debian bookworm/main amd64 libsvtav1enc1 amd64 1.4.1+dfsg-1 [2121 kB]\n",
      "Get:79 http://deb.debian.org/debian bookworm/main amd64 libjpeg62-turbo amd64 1:2.1.5-2 [166 kB]\n",
      "Get:80 http://deb.debian.org/debian bookworm/main amd64 libyuv0 amd64 0.0~git20230123.b2528b0-1 [168 kB]\n",
      "Get:81 http://deb.debian.org/debian bookworm/main amd64 libavif15 amd64 0.11.1-1 [93.8 kB]\n",
      "Get:82 http://deb.debian.org/debian bookworm/main amd64 libbrotli1 amd64 1.0.9-2+b6 [275 kB]\n",
      "Get:83 http://deb.debian.org/debian bookworm/main amd64 libbsd0 amd64 0.11.7-2 [117 kB]\n",
      "Get:84 http://deb.debian.org/debian bookworm/main amd64 libpng16-16 amd64 1.6.39-2 [276 kB]\n",
      "Get:85 http://deb.debian.org/debian bookworm/main amd64 libfreetype6 amd64 2.12.1+dfsg-5 [399 kB]\n",
      "Get:86 http://deb.debian.org/debian bookworm/main amd64 libfontconfig1 amd64 2.14.1-4 [386 kB]\n",
      "Get:87 http://deb.debian.org/debian bookworm/main amd64 libde265-0 amd64 1.0.11-1+deb12u2 [185 kB]\n",
      "Get:88 http://deb.debian.org/debian bookworm/main amd64 libnuma1 amd64 2.0.16-1 [21.0 kB]\n",
      "Get:89 http://deb.debian.org/debian bookworm/main amd64 libx265-199 amd64 3.5-2+b1 [1150 kB]\n",
      "Get:90 http://deb.debian.org/debian bookworm/main amd64 libheif1 amd64 1.15.1-1 [215 kB]\n",
      "Get:91 http://deb.debian.org/debian bookworm/main amd64 libdeflate0 amd64 1.14-1 [61.4 kB]\n",
      "Get:92 http://deb.debian.org/debian bookworm/main amd64 libjbig0 amd64 2.1-6.1 [31.7 kB]\n",
      "Get:93 http://deb.debian.org/debian bookworm/main amd64 liblerc4 amd64 4.0.0+ds-2 [170 kB]\n",
      "Get:94 http://deb.debian.org/debian bookworm/main amd64 libwebp7 amd64 1.2.4-0.2+deb12u1 [286 kB]\n",
      "Get:95 http://deb.debian.org/debian bookworm/main amd64 libtiff6 amd64 4.5.0-6+deb12u1 [316 kB]\n",
      "Get:96 http://deb.debian.org/debian bookworm/main amd64 libxau6 amd64 1:1.0.9-1 [19.7 kB]\n",
      "Get:97 http://deb.debian.org/debian bookworm/main amd64 libxdmcp6 amd64 1:1.1.2-3 [26.3 kB]\n",
      "Get:98 http://deb.debian.org/debian bookworm/main amd64 libxcb1 amd64 1.15-1 [144 kB]\n",
      "Get:99 http://deb.debian.org/debian bookworm/main amd64 libx11-data all 2:1.8.4-2+deb12u2 [292 kB]\n",
      "Get:100 http://deb.debian.org/debian bookworm/main amd64 libx11-6 amd64 2:1.8.4-2+deb12u2 [760 kB]\n",
      "Get:101 http://deb.debian.org/debian bookworm/main amd64 libxpm4 amd64 1:3.5.12-1.1+deb12u1 [48.6 kB]\n",
      "Get:102 http://deb.debian.org/debian bookworm/main amd64 libgd3 amd64 2.3.3-9 [124 kB]\n",
      "Get:103 http://deb.debian.org/debian-security bookworm-security/main amd64 libc-devtools amd64 2.36-9+deb12u7 [53.4 kB]\n",
      "Get:104 http://deb.debian.org/debian bookworm/main amd64 libfile-fcntllock-perl amd64 0.22-4+b1 [34.8 kB]\n",
      "Get:105 http://deb.debian.org/debian bookworm/main amd64 libldap-common all 2.5.13+dfsg-5 [29.3 kB]\n",
      "Get:106 http://deb.debian.org/debian bookworm/main amd64 libsasl2-modules amd64 2.1.28+dfsg-10 [66.6 kB]\n",
      "Get:107 http://deb.debian.org/debian bookworm/main amd64 manpages-dev all 6.03-2 [2030 kB]\n",
      "\u001b[91mdebconf: delaying package configuration, since apt-utils is not installed\n",
      "\u001b[0mFetched 98.3 MB in 1s (190 MB/s)\n",
      "Selecting previously unselected package perl-modules-5.36.\n",
      "(Reading database ... 6697 files and directories currently installed.)\n",
      "Preparing to unpack .../000-perl-modules-5.36_5.36.0-7+deb12u1_all.deb ...\n",
      "Unpacking perl-modules-5.36 (5.36.0-7+deb12u1) ...\n",
      "Selecting previously unselected package libgdbm-compat4:amd64.\n",
      "Preparing to unpack .../001-libgdbm-compat4_1.23-3_amd64.deb ...\n",
      "Unpacking libgdbm-compat4:amd64 (1.23-3) ...\n",
      "Selecting previously unselected package libperl5.36:amd64.\n",
      "Preparing to unpack .../002-libperl5.36_5.36.0-7+deb12u1_amd64.deb ...\n",
      "Unpacking libperl5.36:amd64 (5.36.0-7+deb12u1) ...\n",
      "Selecting previously unselected package perl.\n",
      "Preparing to unpack .../003-perl_5.36.0-7+deb12u1_amd64.deb ...\n",
      "Unpacking perl (5.36.0-7+deb12u1) ...\n",
      "Selecting previously unselected package liblocale-gettext-perl.\n",
      "Preparing to unpack .../004-liblocale-gettext-perl_1.07-5_amd64.deb ...\n",
      "Unpacking liblocale-gettext-perl (1.07-5) ...\n",
      "Selecting previously unselected package bzip2.\n",
      "Preparing to unpack .../005-bzip2_1.0.8-5+b1_amd64.deb ...\n",
      "Unpacking bzip2 (1.0.8-5+b1) ...\n",
      "Selecting previously unselected package manpages.\n",
      "Preparing to unpack .../006-manpages_6.03-2_all.deb ...\n",
      "Unpacking manpages (6.03-2) ...\n",
      "Selecting previously unselected package xz-utils.\n",
      "Preparing to unpack .../007-xz-utils_5.4.1-0.2_amd64.deb ...\n",
      "Unpacking xz-utils (5.4.1-0.2) ...\n",
      "Selecting previously unselected package binutils-common:amd64.\n",
      "Preparing to unpack .../008-binutils-common_2.40-2_amd64.deb ...\n",
      "Unpacking binutils-common:amd64 (2.40-2) ...\n",
      "Selecting previously unselected package libbinutils:amd64.\n",
      "Preparing to unpack .../009-libbinutils_2.40-2_amd64.deb ...\n",
      "Unpacking libbinutils:amd64 (2.40-2) ...\n",
      "Selecting previously unselected package libctf-nobfd0:amd64.\n",
      "Preparing to unpack .../010-libctf-nobfd0_2.40-2_amd64.deb ...\n",
      "Unpacking libctf-nobfd0:amd64 (2.40-2) ...\n",
      "Selecting previously unselected package libctf0:amd64.\n",
      "Preparing to unpack .../011-libctf0_2.40-2_amd64.deb ...\n",
      "Unpacking libctf0:amd64 (2.40-2) ...\n",
      "Selecting previously unselected package libgprofng0:amd64.\n",
      "Preparing to unpack .../012-libgprofng0_2.40-2_amd64.deb ...\n",
      "Unpacking libgprofng0:amd64 (2.40-2) ...\n",
      "Selecting previously unselected package libjansson4:amd64.\n",
      "Preparing to unpack .../013-libjansson4_2.14-2_amd64.deb ...\n",
      "Unpacking libjansson4:amd64 (2.14-2) ...\n",
      "Selecting previously unselected package binutils-x86-64-linux-gnu.\n",
      "Preparing to unpack .../014-binutils-x86-64-linux-gnu_2.40-2_amd64.deb ...\n",
      "Unpacking binutils-x86-64-linux-gnu (2.40-2) ...\n",
      "Selecting previously unselected package binutils.\n",
      "Preparing to unpack .../015-binutils_2.40-2_amd64.deb ...\n",
      "Unpacking binutils (2.40-2) ...\n",
      "Selecting previously unselected package libc-dev-bin.\n",
      "Preparing to unpack .../016-libc-dev-bin_2.36-9+deb12u7_amd64.deb ...\n",
      "Unpacking libc-dev-bin (2.36-9+deb12u7) ...\n",
      "Selecting previously unselected package linux-libc-dev:amd64.\n",
      "Preparing to unpack .../017-linux-libc-dev_6.1.90-1_amd64.deb ...\n",
      "Unpacking linux-libc-dev:amd64 (6.1.90-1) ...\n",
      "Selecting previously unselected package libcrypt-dev:amd64.\n",
      "Preparing to unpack .../018-libcrypt-dev_1%3a4.4.33-2_amd64.deb ...\n",
      "Unpacking libcrypt-dev:amd64 (1:4.4.33-2) ...\n",
      "Selecting previously unselected package libtirpc-dev:amd64.\n",
      "Preparing to unpack .../019-libtirpc-dev_1.3.3+ds-1_amd64.deb ...\n",
      "Unpacking libtirpc-dev:amd64 (1.3.3+ds-1) ...\n",
      "Selecting previously unselected package libnsl-dev:amd64.\n",
      "Preparing to unpack .../020-libnsl-dev_1.3.0-2_amd64.deb ...\n",
      "Unpacking libnsl-dev:amd64 (1.3.0-2) ...\n",
      "Selecting previously unselected package rpcsvc-proto.\n",
      "Preparing to unpack .../021-rpcsvc-proto_1.4.3-1_amd64.deb ...\n",
      "Unpacking rpcsvc-proto (1.4.3-1) ...\n",
      "Selecting previously unselected package libc6-dev:amd64.\n",
      "Preparing to unpack .../022-libc6-dev_2.36-9+deb12u7_amd64.deb ...\n",
      "Unpacking libc6-dev:amd64 (2.36-9+deb12u7) ...\n",
      "Selecting previously unselected package libisl23:amd64.\n",
      "Preparing to unpack .../023-libisl23_0.25-1.1_amd64.deb ...\n",
      "Unpacking libisl23:amd64 (0.25-1.1) ...\n",
      "Selecting previously unselected package libmpfr6:amd64.\n",
      "Preparing to unpack .../024-libmpfr6_4.2.0-1_amd64.deb ...\n",
      "Unpacking libmpfr6:amd64 (4.2.0-1) ...\n",
      "Selecting previously unselected package libmpc3:amd64.\n",
      "Preparing to unpack .../025-libmpc3_1.3.1-1_amd64.deb ...\n",
      "Unpacking libmpc3:amd64 (1.3.1-1) ...\n",
      "Selecting previously unselected package cpp-12.\n",
      "Preparing to unpack .../026-cpp-12_12.2.0-14_amd64.deb ...\n",
      "Unpacking cpp-12 (12.2.0-14) ...\n",
      "Selecting previously unselected package cpp.\n",
      "Preparing to unpack .../027-cpp_4%3a12.2.0-3_amd64.deb ...\n",
      "Unpacking cpp (4:12.2.0-3) ...\n",
      "Selecting previously unselected package libcc1-0:amd64.\n",
      "Preparing to unpack .../028-libcc1-0_12.2.0-14_amd64.deb ...\n",
      "Unpacking libcc1-0:amd64 (12.2.0-14) ...\n",
      "Selecting previously unselected package libgomp1:amd64.\n",
      "Preparing to unpack .../029-libgomp1_12.2.0-14_amd64.deb ...\n",
      "Unpacking libgomp1:amd64 (12.2.0-14) ...\n",
      "Selecting previously unselected package libitm1:amd64.\n",
      "Preparing to unpack .../030-libitm1_12.2.0-14_amd64.deb ...\n",
      "Unpacking libitm1:amd64 (12.2.0-14) ...\n",
      "Selecting previously unselected package libatomic1:amd64.\n",
      "Preparing to unpack .../031-libatomic1_12.2.0-14_amd64.deb ...\n",
      "Unpacking libatomic1:amd64 (12.2.0-14) ...\n",
      "Selecting previously unselected package libasan8:amd64.\n",
      "Preparing to unpack .../032-libasan8_12.2.0-14_amd64.deb ...\n",
      "Unpacking libasan8:amd64 (12.2.0-14) ...\n",
      "Selecting previously unselected package liblsan0:amd64.\n",
      "Preparing to unpack .../033-liblsan0_12.2.0-14_amd64.deb ...\n",
      "Unpacking liblsan0:amd64 (12.2.0-14) ...\n",
      "Selecting previously unselected package libtsan2:amd64.\n",
      "Preparing to unpack .../034-libtsan2_12.2.0-14_amd64.deb ...\n",
      "Unpacking libtsan2:amd64 (12.2.0-14) ...\n",
      "Selecting previously unselected package libubsan1:amd64.\n",
      "Preparing to unpack .../035-libubsan1_12.2.0-14_amd64.deb ...\n",
      "Unpacking libubsan1:amd64 (12.2.0-14) ...\n",
      "Selecting previously unselected package libquadmath0:amd64.\n",
      "Preparing to unpack .../036-libquadmath0_12.2.0-14_amd64.deb ...\n",
      "Unpacking libquadmath0:amd64 (12.2.0-14) ...\n",
      "Selecting previously unselected package libgcc-12-dev:amd64.\n",
      "Preparing to unpack .../037-libgcc-12-dev_12.2.0-14_amd64.deb ...\n",
      "Unpacking libgcc-12-dev:amd64 (12.2.0-14) ...\n",
      "Selecting previously unselected package gcc-12.\n",
      "Preparing to unpack .../038-gcc-12_12.2.0-14_amd64.deb ...\n",
      "Unpacking gcc-12 (12.2.0-14) ...\n",
      "Selecting previously unselected package gcc.\n",
      "Preparing to unpack .../039-gcc_4%3a12.2.0-3_amd64.deb ...\n",
      "Unpacking gcc (4:12.2.0-3) ...\n",
      "Selecting previously unselected package libstdc++-12-dev:amd64.\n",
      "Preparing to unpack .../040-libstdc++-12-dev_12.2.0-14_amd64.deb ...\n",
      "Unpacking libstdc++-12-dev:amd64 (12.2.0-14) ...\n",
      "Selecting previously unselected package g++-12.\n",
      "Preparing to unpack .../041-g++-12_12.2.0-14_amd64.deb ...\n",
      "Unpacking g++-12 (12.2.0-14) ...\n",
      "Selecting previously unselected package g++.\n",
      "Preparing to unpack .../042-g++_4%3a12.2.0-3_amd64.deb ...\n",
      "Unpacking g++ (4:12.2.0-3) ...\n",
      "Selecting previously unselected package make.\n",
      "Preparing to unpack .../043-make_4.3-4.1_amd64.deb ...\n",
      "Unpacking make (4.3-4.1) ...\n",
      "Selecting previously unselected package libdpkg-perl.\n",
      "Preparing to unpack .../044-libdpkg-perl_1.21.22_all.deb ...\n",
      "Unpacking libdpkg-perl (1.21.22) ...\n",
      "Selecting previously unselected package patch.\n",
      "Preparing to unpack .../045-patch_2.7.6-7_amd64.deb ...\n",
      "Unpacking patch (2.7.6-7) ...\n",
      "Selecting previously unselected package dpkg-dev.\n",
      "Preparing to unpack .../046-dpkg-dev_1.21.22_all.deb ...\n",
      "Unpacking dpkg-dev (1.21.22) ...\n",
      "Selecting previously unselected package build-essential.\n",
      "Preparing to unpack .../047-build-essential_12.9_amd64.deb ...\n",
      "Unpacking build-essential (12.9) ...\n",
      "Selecting previously unselected package libassuan0:amd64.\n",
      "Preparing to unpack .../048-libassuan0_2.5.5-5_amd64.deb ...\n",
      "Unpacking libassuan0:amd64 (2.5.5-5) ...\n",
      "Selecting previously unselected package gpgconf.\n",
      "Preparing to unpack .../049-gpgconf_2.2.40-1.1_amd64.deb ...\n",
      "Unpacking gpgconf (2.2.40-1.1) ...\n",
      "Selecting previously unselected package libksba8:amd64.\n",
      "Preparing to unpack .../050-libksba8_1.6.3-2_amd64.deb ...\n",
      "Unpacking libksba8:amd64 (1.6.3-2) ...\n",
      "Selecting previously unselected package libsasl2-modules-db:amd64.\n",
      "Preparing to unpack .../051-libsasl2-modules-db_2.1.28+dfsg-10_amd64.deb ...\n",
      "Unpacking libsasl2-modules-db:amd64 (2.1.28+dfsg-10) ...\n",
      "Selecting previously unselected package libsasl2-2:amd64.\n",
      "Preparing to unpack .../052-libsasl2-2_2.1.28+dfsg-10_amd64.deb ...\n",
      "Unpacking libsasl2-2:amd64 (2.1.28+dfsg-10) ...\n",
      "Selecting previously unselected package libldap-2.5-0:amd64.\n",
      "Preparing to unpack .../053-libldap-2.5-0_2.5.13+dfsg-5_amd64.deb ...\n",
      "Unpacking libldap-2.5-0:amd64 (2.5.13+dfsg-5) ...\n",
      "Selecting previously unselected package libnpth0:amd64.\n",
      "Preparing to unpack .../054-libnpth0_1.6-3_amd64.deb ...\n",
      "Unpacking libnpth0:amd64 (1.6-3) ...\n",
      "Selecting previously unselected package dirmngr.\n",
      "Preparing to unpack .../055-dirmngr_2.2.40-1.1_amd64.deb ...\n",
      "Unpacking dirmngr (2.2.40-1.1) ...\n",
      "Selecting previously unselected package libfakeroot:amd64.\n",
      "Preparing to unpack .../056-libfakeroot_1.31-1.2_amd64.deb ...\n",
      "Unpacking libfakeroot:amd64 (1.31-1.2) ...\n",
      "Selecting previously unselected package fakeroot.\n",
      "Preparing to unpack .../057-fakeroot_1.31-1.2_amd64.deb ...\n",
      "Unpacking fakeroot (1.31-1.2) ...\n",
      "Selecting previously unselected package fonts-dejavu-core.\n",
      "Preparing to unpack .../058-fonts-dejavu-core_2.37-6_all.deb ...\n",
      "Unpacking fonts-dejavu-core (2.37-6) ...\n",
      "Selecting previously unselected package fontconfig-config.\n",
      "Preparing to unpack .../059-fontconfig-config_2.14.1-4_amd64.deb ...\n",
      "Unpacking fontconfig-config (2.14.1-4) ...\n",
      "Selecting previously unselected package gnupg-l10n.\n",
      "Preparing to unpack .../060-gnupg-l10n_2.2.40-1.1_all.deb ...\n",
      "Unpacking gnupg-l10n (2.2.40-1.1) ...\n",
      "Selecting previously unselected package gnupg-utils.\n",
      "Preparing to unpack .../061-gnupg-utils_2.2.40-1.1_amd64.deb ...\n",
      "Unpacking gnupg-utils (2.2.40-1.1) ...\n",
      "Selecting previously unselected package gpg.\n",
      "Preparing to unpack .../062-gpg_2.2.40-1.1_amd64.deb ...\n",
      "Unpacking gpg (2.2.40-1.1) ...\n",
      "Selecting previously unselected package pinentry-curses.\n",
      "Preparing to unpack .../063-pinentry-curses_1.2.1-1_amd64.deb ...\n",
      "Unpacking pinentry-curses (1.2.1-1) ...\n",
      "Selecting previously unselected package gpg-agent.\n",
      "Preparing to unpack .../064-gpg-agent_2.2.40-1.1_amd64.deb ...\n",
      "Unpacking gpg-agent (2.2.40-1.1) ...\n",
      "Selecting previously unselected package gpg-wks-client.\n",
      "Preparing to unpack .../065-gpg-wks-client_2.2.40-1.1_amd64.deb ...\n",
      "Unpacking gpg-wks-client (2.2.40-1.1) ...\n",
      "Selecting previously unselected package gpg-wks-server.\n",
      "Preparing to unpack .../066-gpg-wks-server_2.2.40-1.1_amd64.deb ...\n",
      "Unpacking gpg-wks-server (2.2.40-1.1) ...\n",
      "Selecting previously unselected package gpgsm.\n",
      "Preparing to unpack .../067-gpgsm_2.2.40-1.1_amd64.deb ...\n",
      "Unpacking gpgsm (2.2.40-1.1) ...\n",
      "Selecting previously unselected package gnupg.\n",
      "Preparing to unpack .../068-gnupg_2.2.40-1.1_all.deb ...\n",
      "Unpacking gnupg (2.2.40-1.1) ...\n",
      "Selecting previously unselected package libabsl20220623:amd64.\n",
      "Preparing to unpack .../069-libabsl20220623_20220623.1-1_amd64.deb ...\n",
      "Unpacking libabsl20220623:amd64 (20220623.1-1) ...\n",
      "Selecting previously unselected package libalgorithm-diff-perl.\n",
      "Preparing to unpack .../070-libalgorithm-diff-perl_1.201-1_all.deb ...\n",
      "Unpacking libalgorithm-diff-perl (1.201-1) ...\n",
      "Selecting previously unselected package libalgorithm-diff-xs-perl:amd64.\n",
      "Preparing to unpack .../071-libalgorithm-diff-xs-perl_0.04-8+b1_amd64.deb ...\n",
      "Unpacking libalgorithm-diff-xs-perl:amd64 (0.04-8+b1) ...\n",
      "Selecting previously unselected package libalgorithm-merge-perl.\n",
      "Preparing to unpack .../072-libalgorithm-merge-perl_0.08-5_all.deb ...\n",
      "Unpacking libalgorithm-merge-perl (0.08-5) ...\n",
      "Selecting previously unselected package libaom3:amd64.\n",
      "Preparing to unpack .../073-libaom3_3.6.0-1_amd64.deb ...\n",
      "Unpacking libaom3:amd64 (3.6.0-1) ...\n",
      "Selecting previously unselected package libdav1d6:amd64.\n",
      "Preparing to unpack .../074-libdav1d6_1.0.0-2+deb12u1_amd64.deb ...\n",
      "Unpacking libdav1d6:amd64 (1.0.0-2+deb12u1) ...\n",
      "Selecting previously unselected package libgav1-1:amd64.\n",
      "Preparing to unpack .../075-libgav1-1_0.18.0-1+b1_amd64.deb ...\n",
      "Unpacking libgav1-1:amd64 (0.18.0-1+b1) ...\n",
      "Selecting previously unselected package librav1e0:amd64.\n",
      "Preparing to unpack .../076-librav1e0_0.5.1-6_amd64.deb ...\n",
      "Unpacking librav1e0:amd64 (0.5.1-6) ...\n",
      "Selecting previously unselected package libsvtav1enc1:amd64.\n",
      "Preparing to unpack .../077-libsvtav1enc1_1.4.1+dfsg-1_amd64.deb ...\n",
      "Unpacking libsvtav1enc1:amd64 (1.4.1+dfsg-1) ...\n",
      "Selecting previously unselected package libjpeg62-turbo:amd64.\n",
      "Preparing to unpack .../078-libjpeg62-turbo_1%3a2.1.5-2_amd64.deb ...\n",
      "Unpacking libjpeg62-turbo:amd64 (1:2.1.5-2) ...\n",
      "Selecting previously unselected package libyuv0:amd64.\n",
      "Preparing to unpack .../079-libyuv0_0.0~git20230123.b2528b0-1_amd64.deb ...\n",
      "Unpacking libyuv0:amd64 (0.0~git20230123.b2528b0-1) ...\n",
      "Selecting previously unselected package libavif15:amd64.\n",
      "Preparing to unpack .../080-libavif15_0.11.1-1_amd64.deb ...\n",
      "Unpacking libavif15:amd64 (0.11.1-1) ...\n",
      "Selecting previously unselected package libbrotli1:amd64.\n",
      "Preparing to unpack .../081-libbrotli1_1.0.9-2+b6_amd64.deb ...\n",
      "Unpacking libbrotli1:amd64 (1.0.9-2+b6) ...\n",
      "Selecting previously unselected package libbsd0:amd64.\n",
      "Preparing to unpack .../082-libbsd0_0.11.7-2_amd64.deb ...\n",
      "Unpacking libbsd0:amd64 (0.11.7-2) ...\n",
      "Selecting previously unselected package libpng16-16:amd64.\n",
      "Preparing to unpack .../083-libpng16-16_1.6.39-2_amd64.deb ...\n",
      "Unpacking libpng16-16:amd64 (1.6.39-2) ...\n",
      "Selecting previously unselected package libfreetype6:amd64.\n",
      "Preparing to unpack .../084-libfreetype6_2.12.1+dfsg-5_amd64.deb ...\n",
      "Unpacking libfreetype6:amd64 (2.12.1+dfsg-5) ...\n",
      "Selecting previously unselected package libfontconfig1:amd64.\n",
      "Preparing to unpack .../085-libfontconfig1_2.14.1-4_amd64.deb ...\n",
      "Unpacking libfontconfig1:amd64 (2.14.1-4) ...\n",
      "Selecting previously unselected package libde265-0:amd64.\n",
      "Preparing to unpack .../086-libde265-0_1.0.11-1+deb12u2_amd64.deb ...\n",
      "Unpacking libde265-0:amd64 (1.0.11-1+deb12u2) ...\n",
      "Selecting previously unselected package libnuma1:amd64.\n",
      "Preparing to unpack .../087-libnuma1_2.0.16-1_amd64.deb ...\n",
      "Unpacking libnuma1:amd64 (2.0.16-1) ...\n",
      "Selecting previously unselected package libx265-199:amd64.\n",
      "Preparing to unpack .../088-libx265-199_3.5-2+b1_amd64.deb ...\n",
      "Unpacking libx265-199:amd64 (3.5-2+b1) ...\n",
      "Selecting previously unselected package libheif1:amd64.\n",
      "Preparing to unpack .../089-libheif1_1.15.1-1_amd64.deb ...\n",
      "Unpacking libheif1:amd64 (1.15.1-1) ...\n",
      "Selecting previously unselected package libdeflate0:amd64.\n",
      "Preparing to unpack .../090-libdeflate0_1.14-1_amd64.deb ...\n",
      "Unpacking libdeflate0:amd64 (1.14-1) ...\n",
      "Selecting previously unselected package libjbig0:amd64.\n",
      "Preparing to unpack .../091-libjbig0_2.1-6.1_amd64.deb ...\n",
      "Unpacking libjbig0:amd64 (2.1-6.1) ...\n",
      "Selecting previously unselected package liblerc4:amd64.\n",
      "Preparing to unpack .../092-liblerc4_4.0.0+ds-2_amd64.deb ...\n",
      "Unpacking liblerc4:amd64 (4.0.0+ds-2) ...\n",
      "Selecting previously unselected package libwebp7:amd64.\n",
      "Preparing to unpack .../093-libwebp7_1.2.4-0.2+deb12u1_amd64.deb ...\n",
      "Unpacking libwebp7:amd64 (1.2.4-0.2+deb12u1) ...\n",
      "Selecting previously unselected package libtiff6:amd64.\n",
      "Preparing to unpack .../094-libtiff6_4.5.0-6+deb12u1_amd64.deb ...\n",
      "Unpacking libtiff6:amd64 (4.5.0-6+deb12u1) ...\n",
      "Selecting previously unselected package libxau6:amd64.\n",
      "Preparing to unpack .../095-libxau6_1%3a1.0.9-1_amd64.deb ...\n",
      "Unpacking libxau6:amd64 (1:1.0.9-1) ...\n",
      "Selecting previously unselected package libxdmcp6:amd64.\n",
      "Preparing to unpack .../096-libxdmcp6_1%3a1.1.2-3_amd64.deb ...\n",
      "Unpacking libxdmcp6:amd64 (1:1.1.2-3) ...\n",
      "Selecting previously unselected package libxcb1:amd64.\n",
      "Preparing to unpack .../097-libxcb1_1.15-1_amd64.deb ...\n",
      "Unpacking libxcb1:amd64 (1.15-1) ...\n",
      "Selecting previously unselected package libx11-data.\n",
      "Preparing to unpack .../098-libx11-data_2%3a1.8.4-2+deb12u2_all.deb ...\n",
      "Unpacking libx11-data (2:1.8.4-2+deb12u2) ...\n",
      "Selecting previously unselected package libx11-6:amd64.\n",
      "Preparing to unpack .../099-libx11-6_2%3a1.8.4-2+deb12u2_amd64.deb ...\n",
      "Unpacking libx11-6:amd64 (2:1.8.4-2+deb12u2) ...\n",
      "Selecting previously unselected package libxpm4:amd64.\n",
      "Preparing to unpack .../100-libxpm4_1%3a3.5.12-1.1+deb12u1_amd64.deb ...\n",
      "Unpacking libxpm4:amd64 (1:3.5.12-1.1+deb12u1) ...\n",
      "Selecting previously unselected package libgd3:amd64.\n",
      "Preparing to unpack .../101-libgd3_2.3.3-9_amd64.deb ...\n",
      "Unpacking libgd3:amd64 (2.3.3-9) ...\n",
      "Selecting previously unselected package libc-devtools.\n",
      "Preparing to unpack .../102-libc-devtools_2.36-9+deb12u7_amd64.deb ...\n",
      "Unpacking libc-devtools (2.36-9+deb12u7) ...\n",
      "Selecting previously unselected package libfile-fcntllock-perl.\n",
      "Preparing to unpack .../103-libfile-fcntllock-perl_0.22-4+b1_amd64.deb ...\n",
      "Unpacking libfile-fcntllock-perl (0.22-4+b1) ...\n",
      "Selecting previously unselected package libldap-common.\n",
      "Preparing to unpack .../104-libldap-common_2.5.13+dfsg-5_all.deb ...\n",
      "Unpacking libldap-common (2.5.13+dfsg-5) ...\n",
      "Selecting previously unselected package libsasl2-modules:amd64.\n",
      "Preparing to unpack .../105-libsasl2-modules_2.1.28+dfsg-10_amd64.deb ...\n",
      "Unpacking libsasl2-modules:amd64 (2.1.28+dfsg-10) ...\n",
      "Selecting previously unselected package manpages-dev.\n",
      "Preparing to unpack .../106-manpages-dev_6.03-2_all.deb ...\n",
      "Unpacking manpages-dev (6.03-2) ...\n",
      "Setting up libksba8:amd64 (1.6.3-2) ...\n",
      "Setting up libaom3:amd64 (3.6.0-1) ...\n",
      "Setting up libabsl20220623:amd64 (20220623.1-1) ...\n",
      "Setting up libxau6:amd64 (1:1.0.9-1) ...\n",
      "Setting up liblerc4:amd64 (4.0.0+ds-2) ...\n",
      "Setting up manpages (6.03-2) ...\n",
      "Setting up libbrotli1:amd64 (1.0.9-2+b6) ...\n",
      "Setting up libsasl2-modules:amd64 (2.1.28+dfsg-10) ...\n",
      "Setting up binutils-common:amd64 (2.40-2) ...\n",
      "Setting up libdeflate0:amd64 (1.14-1) ...\n",
      "Setting up linux-libc-dev:amd64 (6.1.90-1) ...\n",
      "Setting up libctf-nobfd0:amd64 (2.40-2) ...\n",
      "Setting up libnpth0:amd64 (1.6-3) ...\n",
      "Setting up libsvtav1enc1:amd64 (1.4.1+dfsg-1) ...\n",
      "Setting up libassuan0:amd64 (2.5.5-5) ...\n",
      "Setting up libgomp1:amd64 (12.2.0-14) ...\n",
      "Setting up bzip2 (1.0.8-5+b1) ...\n",
      "Setting up libldap-common (2.5.13+dfsg-5) ...\n",
      "Setting up libjbig0:amd64 (2.1-6.1) ...\n",
      "Setting up librav1e0:amd64 (0.5.1-6) ...\n",
      "Setting up libfakeroot:amd64 (1.31-1.2) ...\n",
      "Setting up libjansson4:amd64 (2.14-2) ...\n",
      "Setting up libsasl2-modules-db:amd64 (2.1.28+dfsg-10) ...\n",
      "Setting up fakeroot (1.31-1.2) ...\n",
      "update-alternatives: using /usr/bin/fakeroot-sysv to provide /usr/bin/fakeroot (fakeroot) in auto mode\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/fakeroot.1.gz because associated file /usr/share/man/man1/fakeroot-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/faked.1.gz because associated file /usr/share/man/man1/faked-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/es/man1/fakeroot.1.gz because associated file /usr/share/man/es/man1/fakeroot-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/es/man1/faked.1.gz because associated file /usr/share/man/es/man1/faked-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/fr/man1/fakeroot.1.gz because associated file /usr/share/man/fr/man1/fakeroot-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/fr/man1/faked.1.gz because associated file /usr/share/man/fr/man1/faked-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/sv/man1/fakeroot.1.gz because associated file /usr/share/man/sv/man1/fakeroot-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/sv/man1/faked.1.gz because associated file /usr/share/man/sv/man1/faked-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "Setting up perl-modules-5.36 (5.36.0-7+deb12u1) ...\n",
      "Setting up libtirpc-dev:amd64 (1.3.3+ds-1) ...\n",
      "Setting up rpcsvc-proto (1.4.3-1) ...\n",
      "Setting up libjpeg62-turbo:amd64 (1:2.1.5-2) ...\n",
      "Setting up libx11-data (2:1.8.4-2+deb12u2) ...\n",
      "Setting up make (4.3-4.1) ...\n",
      "Setting up libmpfr6:amd64 (4.2.0-1) ...\n",
      "Setting up gnupg-l10n (2.2.40-1.1) ...\n",
      "Setting up xz-utils (5.4.1-0.2) ...\n",
      "update-alternatives: using /usr/bin/xz to provide /usr/bin/lzma (lzma) in auto mode\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzma.1.gz because associated file /usr/share/man/man1/xz.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/unlzma.1.gz because associated file /usr/share/man/man1/unxz.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzcat.1.gz because associated file /usr/share/man/man1/xzcat.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzmore.1.gz because associated file /usr/share/man/man1/xzmore.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzless.1.gz because associated file /usr/share/man/man1/xzless.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzdiff.1.gz because associated file /usr/share/man/man1/xzdiff.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzcmp.1.gz because associated file /usr/share/man/man1/xzcmp.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzgrep.1.gz because associated file /usr/share/man/man1/xzgrep.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzegrep.1.gz because associated file /usr/share/man/man1/xzegrep.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzfgrep.1.gz because associated file /usr/share/man/man1/xzfgrep.1.gz (of link group lzma) doesn't exist\n",
      "Setting up libquadmath0:amd64 (12.2.0-14) ...\n",
      "Setting up libpng16-16:amd64 (1.6.39-2) ...\n",
      "Setting up libmpc3:amd64 (1.3.1-1) ...\n",
      "Setting up libatomic1:amd64 (12.2.0-14) ...\n",
      "Setting up patch (2.7.6-7) ...\n",
      "Setting up fonts-dejavu-core (2.37-6) ...\n",
      "Setting up libgdbm-compat4:amd64 (1.23-3) ...\n",
      "Setting up libgav1-1:amd64 (0.18.0-1+b1) ...\n",
      "Setting up libdav1d6:amd64 (1.0.0-2+deb12u1) ...\n",
      "Setting up libsasl2-2:amd64 (2.1.28+dfsg-10) ...\n",
      "Setting up libwebp7:amd64 (1.2.4-0.2+deb12u1) ...\n",
      "Setting up libubsan1:amd64 (12.2.0-14) ...\n",
      "Setting up libnuma1:amd64 (2.0.16-1) ...\n",
      "Setting up libnsl-dev:amd64 (1.3.0-2) ...\n",
      "Setting up libcrypt-dev:amd64 (1:4.4.33-2) ...\n",
      "Setting up libtiff6:amd64 (4.5.0-6+deb12u1) ...\n",
      "Setting up libasan8:amd64 (12.2.0-14) ...\n",
      "Setting up gpgconf (2.2.40-1.1) ...\n",
      "Setting up libtsan2:amd64 (12.2.0-14) ...\n",
      "Setting up libbinutils:amd64 (2.40-2) ...\n",
      "Setting up libisl23:amd64 (0.25-1.1) ...\n",
      "Setting up libde265-0:amd64 (1.0.11-1+deb12u2) ...\n",
      "Setting up libc-dev-bin (2.36-9+deb12u7) ...\n",
      "Setting up libbsd0:amd64 (0.11.7-2) ...\n",
      "Setting up libyuv0:amd64 (0.0~git20230123.b2528b0-1) ...\n",
      "Setting up libcc1-0:amd64 (12.2.0-14) ...\n",
      "Setting up libperl5.36:amd64 (5.36.0-7+deb12u1) ...\n",
      "Setting up liblocale-gettext-perl (1.07-5) ...\n",
      "Setting up gpg (2.2.40-1.1) ...\n",
      "Setting up liblsan0:amd64 (12.2.0-14) ...\n",
      "Setting up libitm1:amd64 (12.2.0-14) ...\n",
      "Setting up gnupg-utils (2.2.40-1.1) ...\n",
      "Setting up libctf0:amd64 (2.40-2) ...\n",
      "Setting up pinentry-curses (1.2.1-1) ...\n",
      "Setting up manpages-dev (6.03-2) ...\n",
      "Setting up libxdmcp6:amd64 (1:1.1.2-3) ...\n",
      "Setting up cpp-12 (12.2.0-14) ...\n",
      "Setting up libxcb1:amd64 (1.15-1) ...\n",
      "Setting up gpg-agent (2.2.40-1.1) ...\n",
      "Setting up libavif15:amd64 (0.11.1-1) ...\n",
      "Setting up fontconfig-config (2.14.1-4) ...\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (TERM is not set, so the dialog frontend is not usable.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "Setting up gpgsm (2.2.40-1.1) ...\n",
      "Setting up libldap-2.5-0:amd64 (2.5.13+dfsg-5) ...\n",
      "Setting up dirmngr (2.2.40-1.1) ...\n",
      "Setting up perl (5.36.0-7+deb12u1) ...\n",
      "Setting up libgprofng0:amd64 (2.40-2) ...\n",
      "Setting up libfreetype6:amd64 (2.12.1+dfsg-5) ...\n",
      "Setting up libgcc-12-dev:amd64 (12.2.0-14) ...\n",
      "Setting up libdpkg-perl (1.21.22) ...\n",
      "Setting up libx265-199:amd64 (3.5-2+b1) ...\n",
      "Setting up gpg-wks-server (2.2.40-1.1) ...\n",
      "Setting up cpp (4:12.2.0-3) ...\n",
      "Setting up libc6-dev:amd64 (2.36-9+deb12u7) ...\n",
      "Setting up libx11-6:amd64 (2:1.8.4-2+deb12u2) ...\n",
      "Setting up libfontconfig1:amd64 (2.14.1-4) ...\n",
      "Setting up binutils-x86-64-linux-gnu (2.40-2) ...\n",
      "Setting up libxpm4:amd64 (1:3.5.12-1.1+deb12u1) ...\n",
      "Setting up gpg-wks-client (2.2.40-1.1) ...\n",
      "Setting up libstdc++-12-dev:amd64 (12.2.0-14) ...\n",
      "Setting up libfile-fcntllock-perl (0.22-4+b1) ...\n",
      "Setting up libalgorithm-diff-perl (1.201-1) ...\n",
      "Setting up libheif1:amd64 (1.15.1-1) ...\n",
      "Setting up binutils (2.40-2) ...\n",
      "Setting up dpkg-dev (1.21.22) ...\n",
      "Setting up gcc-12 (12.2.0-14) ...\n",
      "Setting up libgd3:amd64 (2.3.3-9) ...\n",
      "Setting up gnupg (2.2.40-1.1) ...\n",
      "Setting up libalgorithm-diff-xs-perl:amd64 (0.04-8+b1) ...\n",
      "Setting up libc-devtools (2.36-9+deb12u7) ...\n",
      "Setting up libalgorithm-merge-perl (0.08-5) ...\n",
      "Setting up g++-12 (12.2.0-14) ...\n",
      "Setting up gcc (4:12.2.0-3) ...\n",
      "Setting up g++ (4:12.2.0-3) ...\n",
      "update-alternatives: using /usr/bin/g++ to provide /usr/bin/c++ (c++) in auto mode\n",
      "Setting up build-essential (12.9) ...\n",
      "Processing triggers for libc-bin (2.36-9+deb12u7) ...\n",
      "Removing intermediate container 88ae187af46e\n",
      " ---> a72782cf25ec\n",
      "Step 3/6 : RUN pip install --upgrade pip\n",
      " ---> Running in d3f97670bebf\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.10/site-packages (23.0.1)\n",
      "Collecting pip\n",
      "  Downloading pip-24.1.1-py3-none-any.whl (1.8 MB)\n",
      "      1.8/1.8 MB 18.6 MB/s eta 0:00:00\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.0.1\n",
      "    Uninstalling pip-23.0.1:\n",
      "      Successfully uninstalled pip-23.0.1\n",
      "Successfully installed pip-24.1.1\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container d3f97670bebf\n",
      " ---> 5ba2e1b9751a\n",
      "Step 4/6 : COPY requirements.txt requirements.txt\n",
      " ---> 1eeeeff1e7a6\n",
      "Step 5/6 : RUN pip install -r requirements.txt\n",
      " ---> Running in 39b6ddcf0deb\n",
      "Collecting absl-py==1.4.0 (from -r requirements.txt (line 1))\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting aiofiles==22.1.0 (from -r requirements.txt (line 2))\n",
      "  Downloading aiofiles-22.1.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting aiohttp==3.9.5 (from -r requirements.txt (line 3))\n",
      "  Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting aiohttp-cors==0.7.0 (from -r requirements.txt (line 4))\n",
      "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting aiosignal==1.3.1 (from -r requirements.txt (line 5))\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting aiosqlite (from -r requirements.txt (line 6))\n",
      "  Downloading aiosqlite-0.20.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting ansicolors==1.1.8 (from -r requirements.txt (line 7))\n",
      "  Downloading ansicolors-1.1.8-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting apache-beam==2.56.0 (from -r requirements.txt (line 8))\n",
      "  Downloading apache_beam-2.56.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting appdirs==1.4.4 (from -r requirements.txt (line 9))\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting astunparse==1.6.3 (from -r requirements.txt (line 10))\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting async-timeout==4.0.3 (from -r requirements.txt (line 11))\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting atpublic==4.1.0 (from -r requirements.txt (line 12))\n",
      "  Downloading atpublic-4.1.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting Babel==2.15.0 (from -r requirements.txt (line 13))\n",
      "  Downloading Babel-2.15.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backcall==0.2.0 (from -r requirements.txt (line 14))\n",
      "  Downloading backcall-0.2.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting backports.tarfile==1.2.0 (from -r requirements.txt (line 15))\n",
      "  Downloading backports.tarfile-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting bidict==0.23.1 (from -r requirements.txt (line 16))\n",
      "  Downloading bidict-0.23.1-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting bigframes==0.22.0 (from -r requirements.txt (line 17))\n",
      "  Downloading bigframes-0.22.0-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting blessed==1.20.0 (from -r requirements.txt (line 18))\n",
      "  Downloading blessed-1.20.0-py2.py3-none-any.whl.metadata (13 kB)\n",
      "Collecting brotlipy==0.7.0 (from -r requirements.txt (line 19))\n",
      "  Downloading brotlipy-0.7.0-cp35-abi3-manylinux2010_x86_64.whl.metadata (2.9 kB)\n",
      "Collecting cachetools==5.3.3 (from -r requirements.txt (line 20))\n",
      "  Downloading cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting click==8.1.7 (from -r requirements.txt (line 21))\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting click-plugins==1.1.1 (from -r requirements.txt (line 22))\n",
      "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting cligj==0.7.2 (from -r requirements.txt (line 23))\n",
      "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting cloudpickle==2.2.1 (from -r requirements.txt (line 24))\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting colorful==0.5.6 (from -r requirements.txt (line 25))\n",
      "  Downloading colorful-0.5.6-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting contourpy==1.2.1 (from -r requirements.txt (line 26))\n",
      "  Downloading contourpy-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting crcmod==1.7 (from -r requirements.txt (line 27))\n",
      "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
      "      89.7/89.7 kB 7.1 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting cycler==0.12.1 (from -r requirements.txt (line 28))\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting Cython==3.0.10 (from -r requirements.txt (line 29))\n",
      "  Downloading Cython-3.0.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
      "Collecting dacite==1.8.1 (from -r requirements.txt (line 30))\n",
      "  Downloading dacite-1.8.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting dataproc_jupyter_plugin==0.1.79 (from -r requirements.txt (line 31))\n",
      "  Downloading dataproc_jupyter_plugin-0.1.79-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting db-dtypes==1.2.0 (from -r requirements.txt (line 32))\n",
      "  Downloading db_dtypes-1.2.0-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting Deprecated==1.2.14 (from -r requirements.txt (line 33))\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting dill==0.3.1.1 (from -r requirements.txt (line 34))\n",
      "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
      "      152.0/152.0 kB 12.1 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting distlib==0.3.8 (from -r requirements.txt (line 35))\n",
      "  Downloading distlib-0.3.8-py2.py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting dm-tree==0.1.8 (from -r requirements.txt (line 36))\n",
      "  Downloading dm_tree-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
      "Collecting dnspython==2.6.1 (from -r requirements.txt (line 37))\n",
      "  Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting docker==4.4.4 (from -r requirements.txt (line 38))\n",
      "  Downloading docker-4.4.4-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting docopt==0.6.2 (from -r requirements.txt (line 39))\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting docstring_parser==0.16 (from -r requirements.txt (line 40))\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting email_validator==2.1.1 (from -r requirements.txt (line 41))\n",
      "  Downloading email_validator-2.1.1-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting Farama-Notifications==0.0.4 (from -r requirements.txt (line 42))\n",
      "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
      "Collecting fastavro==1.9.4 (from -r requirements.txt (line 43))\n",
      "  Downloading fastavro-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting fasteners==0.19 (from -r requirements.txt (line 44))\n",
      "  Downloading fasteners-0.19-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting filelock==3.15.1 (from -r requirements.txt (line 45))\n",
      "  Downloading filelock-3.15.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting fiona==1.9.6 (from -r requirements.txt (line 46))\n",
      "  Downloading fiona-1.9.6-cp310-cp310-manylinux2014_x86_64.whl.metadata (50 kB)\n",
      "      50.2/50.2 kB 5.8 MB/s eta 0:00:00\n",
      "Collecting flatbuffers==24.3.25 (from -r requirements.txt (line 47))\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting fonttools==4.53.0 (from -r requirements.txt (line 48))\n",
      "  Downloading fonttools-4.53.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (162 kB)\n",
      "      162.2/162.2 kB 17.6 MB/s eta 0:00:00\n",
      "Collecting frozenlist==1.4.1 (from -r requirements.txt (line 49))\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting fsspec==2024.6.0 (from -r requirements.txt (line 50))\n",
      "  Downloading fsspec-2024.6.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting gast==0.4.0 (from -r requirements.txt (line 51))\n",
      "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting gcsfs==2024.6.0 (from -r requirements.txt (line 52))\n",
      "  Downloading gcsfs-2024.6.0-py2.py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting geopandas==0.14.4 (from -r requirements.txt (line 53))\n",
      "  Downloading geopandas-0.14.4-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting gitdb==4.0.11 (from -r requirements.txt (line 54))\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting GitPython==3.1.43 (from -r requirements.txt (line 55))\n",
      "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting google-api-core==2.19.0 (from -r requirements.txt (line 56))\n",
      "  Downloading google_api_core-2.19.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-api-python-client==1.12.11 (from -r requirements.txt (line 57))\n",
      "  Downloading google_api_python_client-1.12.11-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting google-apitools==0.5.31 (from -r requirements.txt (line 58))\n",
      "  Downloading google-apitools-0.5.31.tar.gz (173 kB)\n",
      "      173.5/173.5 kB 20.3 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting google-auth==2.30.0 (from -r requirements.txt (line 59))\n",
      "  Downloading google_auth-2.30.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth-httplib2==0.2.0 (from -r requirements.txt (line 60))\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-auth-oauthlib==1.0.0 (from -r requirements.txt (line 61))\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-cloud-aiplatform==1.55.0 (from -r requirements.txt (line 62))\n",
      "  Downloading google_cloud_aiplatform-1.55.0-py2.py3-none-any.whl.metadata (31 kB)\n",
      "Collecting google-cloud-artifact-registry==1.11.3 (from -r requirements.txt (line 63))\n",
      "  Downloading google_cloud_artifact_registry-1.11.3-py2.py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting google-cloud-bigquery==3.24.0 (from -r requirements.txt (line 64))\n",
      "  Downloading google_cloud_bigquery-3.24.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting google-cloud-bigquery-connection==1.15.3 (from -r requirements.txt (line 65))\n",
      "  Downloading google_cloud_bigquery_connection-1.15.3-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting google-cloud-bigquery-storage==2.25.0 (from -r requirements.txt (line 66))\n",
      "  Downloading google_cloud_bigquery_storage-2.25.0-py2.py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting google-cloud-bigtable==2.24.0 (from -r requirements.txt (line 67))\n",
      "  Downloading google_cloud_bigtable-2.24.0-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting google-cloud-core==2.4.1 (from -r requirements.txt (line 68))\n",
      "  Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-cloud-datastore==2.19.0 (from -r requirements.txt (line 69))\n",
      "  Downloading google_cloud_datastore-2.19.0-py2.py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting google-cloud-dlp==3.18.0 (from -r requirements.txt (line 70))\n",
      "  Downloading google_cloud_dlp-3.18.0-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting google-cloud-functions==1.16.3 (from -r requirements.txt (line 71))\n",
      "  Downloading google_cloud_functions-1.16.3-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting google-cloud-iam==2.15.0 (from -r requirements.txt (line 72))\n",
      "  Downloading google_cloud_iam-2.15.0-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting google-cloud-jupyter-config==0.0.10 (from -r requirements.txt (line 73))\n",
      "  Downloading google_cloud_jupyter_config-0.0.10.tar.gz (9.7 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting google-cloud-language==2.13.3 (from -r requirements.txt (line 74))\n",
      "  Downloading google_cloud_language-2.13.3-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting google-cloud-monitoring==2.21.0 (from -r requirements.txt (line 75))\n",
      "  Downloading google_cloud_monitoring-2.21.0-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-cloud-pubsub==2.21.5 (from -r requirements.txt (line 76))\n",
      "  Downloading google_cloud_pubsub-2.21.5-py2.py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting google-cloud-pubsublite==1.10.0 (from -r requirements.txt (line 77))\n",
      "  Downloading google_cloud_pubsublite-1.10.0-py2.py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting google-cloud-recommendations-ai==0.10.10 (from -r requirements.txt (line 78))\n",
      "  Downloading google_cloud_recommendations_ai-0.10.10-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting google-cloud-resource-manager==1.12.3 (from -r requirements.txt (line 79))\n",
      "  Downloading google_cloud_resource_manager-1.12.3-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting google-cloud-spanner==3.47.0 (from -r requirements.txt (line 80))\n",
      "  Downloading google_cloud_spanner-3.47.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting google-cloud-storage==2.14.0 (from -r requirements.txt (line 81))\n",
      "  Downloading google_cloud_storage-2.14.0-py2.py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting google-cloud-videointelligence==2.13.3 (from -r requirements.txt (line 82))\n",
      "  Downloading google_cloud_videointelligence-2.13.3-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-cloud-vision==3.7.2 (from -r requirements.txt (line 83))\n",
      "  Downloading google_cloud_vision-3.7.2-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting google-crc32c==1.5.0 (from -r requirements.txt (line 84))\n",
      "  Downloading google_crc32c-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
      "Collecting google-pasta==0.2.0 (from -r requirements.txt (line 85))\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting google-resumable-media==2.7.1 (from -r requirements.txt (line 86))\n",
      "  Downloading google_resumable_media-2.7.1-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting googleapis-common-protos==1.63.1 (from -r requirements.txt (line 87))\n",
      "  Downloading googleapis_common_protos-1.63.1-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting gpustat==1.0.0 (from -r requirements.txt (line 88))\n",
      "  Downloading gpustat-1.0.0.tar.gz (90 kB)\n",
      "      90.5/90.5 kB 10.9 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting greenlet==3.0.3 (from -r requirements.txt (line 89))\n",
      "  Downloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting grpc-google-iam-v1==0.13.0 (from -r requirements.txt (line 90))\n",
      "  Downloading grpc_google_iam_v1-0.13.0-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting grpc-interceptor==0.15.4 (from -r requirements.txt (line 91))\n",
      "  Downloading grpc_interceptor-0.15.4-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting grpcio==1.64.1 (from -r requirements.txt (line 92))\n",
      "  Downloading grpcio-1.64.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting grpcio-status==1.48.2 (from -r requirements.txt (line 93))\n",
      "  Downloading grpcio_status-1.48.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting gviz-api==1.10.0 (from -r requirements.txt (line 94))\n",
      "  Downloading gviz_api-1.10.0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting gymnasium==0.28.1 (from -r requirements.txt (line 95))\n",
      "  Downloading gymnasium-0.28.1-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting h11==0.14.0 (from -r requirements.txt (line 96))\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting h5py==3.11.0 (from -r requirements.txt (line 97))\n",
      "  Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting hdfs==2.7.3 (from -r requirements.txt (line 98))\n",
      "  Downloading hdfs-2.7.3.tar.gz (43 kB)\n",
      "      43.5/43.5 kB 4.9 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting htmlmin==0.1.12 (from -r requirements.txt (line 99))\n",
      "  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting httpcore==1.0.5 (from -r requirements.txt (line 100))\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting httplib2==0.22.0 (from -r requirements.txt (line 101))\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting httptools==0.6.1 (from -r requirements.txt (line 102))\n",
      "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting httpx==0.27.0 (from -r requirements.txt (line 103))\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting humanize==4.9.0 (from -r requirements.txt (line 104))\n",
      "  Downloading humanize-4.9.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting hypertune==1.1.0 (from -r requirements.txt (line 105))\n",
      "  Downloading hypertune-1.1.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting ibis-framework==7.1.0 (from -r requirements.txt (line 106))\n",
      "  Downloading ibis_framework-7.1.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting ImageHash==4.3.1 (from -r requirements.txt (line 107))\n",
      "  Downloading ImageHash-4.3.1-py2.py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting imageio==2.34.1 (from -r requirements.txt (line 108))\n",
      "  Downloading imageio-2.34.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting iniconfig==2.0.0 (from -r requirements.txt (line 109))\n",
      "  Downloading iniconfig-2.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting jaraco.classes==3.4.0 (from -r requirements.txt (line 110))\n",
      "  Downloading jaraco.classes-3.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting jaraco.context==5.3.0 (from -r requirements.txt (line 111))\n",
      "  Downloading jaraco.context-5.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting jaraco.functools==4.0.1 (from -r requirements.txt (line 112))\n",
      "  Downloading jaraco.functools-4.0.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting jax-jumpy==1.0.0 (from -r requirements.txt (line 113))\n",
      "  Downloading jax_jumpy-1.0.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting jeepney==0.8.0 (from -r requirements.txt (line 114))\n",
      "  Downloading jeepney-0.8.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting joblib==1.4.2 (from -r requirements.txt (line 115))\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting Js2Py==0.74 (from -r requirements.txt (line 116))\n",
      "  Downloading Js2Py-0.74-py3-none-any.whl.metadata (868 bytes)\n",
      "Collecting json5==0.9.25 (from -r requirements.txt (line 117))\n",
      "  Downloading json5-0.9.25-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting jsonpickle==3.2.2 (from -r requirements.txt (line 118))\n",
      "  Downloading jsonpickle-3.2.2-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting jupyter-http-over-ws==0.0.8 (from -r requirements.txt (line 119))\n",
      "  Downloading jupyter_http_over_ws-0.0.8-py2.py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting jupyter-server-mathjax==0.2.6 (from -r requirements.txt (line 120))\n",
      "  Downloading jupyter_server_mathjax-0.2.6-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting jupyter-ydoc==0.2.5 (from -r requirements.txt (line 121))\n",
      "  Downloading jupyter_ydoc-0.2.5-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting jupyter_server_fileid==0.9.2 (from -r requirements.txt (line 122))\n",
      "  Downloading jupyter_server_fileid-0.9.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting jupyter_server_proxy==4.2.0 (from -r requirements.txt (line 123))\n",
      "  Downloading jupyter_server_proxy-4.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting jupyter_server_ydoc==0.8.0 (from -r requirements.txt (line 124))\n",
      "  Downloading jupyter_server_ydoc-0.8.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting jupyterlab_git==0.44.0 (from -r requirements.txt (line 125))\n",
      "  Downloading jupyterlab_git-0.44.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting jupyterlab_server==2.27.2 (from -r requirements.txt (line 126))\n",
      "  Downloading jupyterlab_server-2.27.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting jupyterlab_widgets==3.0.11 (from -r requirements.txt (line 127))\n",
      "  Downloading jupyterlab_widgets-3.0.11-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting jupytext==1.16.2 (from -r requirements.txt (line 128))\n",
      "  Downloading jupytext-1.16.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting keras (from -r requirements.txt (line 129))\n",
      "  Downloading keras-3.4.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting keras-tuner (from -r requirements.txt (line 130))\n",
      "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting kernels-mixer (from -r requirements.txt (line 131))\n",
      "  Downloading kernels_mixer-0.0.13.tar.gz (13 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting keyring==25.2.1 (from -r requirements.txt (line 132))\n",
      "  Downloading keyring-25.2.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting keyrings.google-artifactregistry-auth==1.1.2 (from -r requirements.txt (line 133))\n",
      "  Downloading keyrings.google_artifactregistry_auth-1.1.2-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting kfp==2.5.0 (from -r requirements.txt (line 134))\n",
      "  Downloading kfp-2.5.0.tar.gz (425 kB)\n",
      "      425.4/425.4 kB 39.3 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting kfp-pipeline-spec==0.2.2 (from -r requirements.txt (line 135))\n",
      "  Downloading kfp_pipeline_spec-0.2.2-py3-none-any.whl.metadata (295 bytes)\n",
      "Collecting kfp-server-api==2.0.5 (from -r requirements.txt (line 136))\n",
      "  Downloading kfp-server-api-2.0.5.tar.gz (63 kB)\n",
      "      63.4/63.4 kB 7.4 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting kiwisolver==1.4.5 (from -r requirements.txt (line 137))\n",
      "  Downloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting kt-legacy==1.0.5 (from -r requirements.txt (line 138))\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
      "Collecting kubernetes==12.0.1 (from -r requirements.txt (line 139))\n",
      "  Downloading kubernetes-12.0.1-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting lazy_loader==0.4 (from -r requirements.txt (line 140))\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting libclang==18.1.1 (from -r requirements.txt (line 141))\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting linkify-it-py==2.0.3 (from -r requirements.txt (line 142))\n",
      "  Downloading linkify_it_py-2.0.3-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting llvmlite==0.41.1 (from -r requirements.txt (line 143))\n",
      "  Downloading llvmlite-0.41.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Collecting lxml==5.2.2 (from -r requirements.txt (line 144))\n",
      "  Downloading lxml-5.2.2-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting lz4==4.3.3 (from -r requirements.txt (line 145))\n",
      "  Downloading lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
      "Collecting Markdown==3.6 (from -r requirements.txt (line 146))\n",
      "  Downloading Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting markdown-it-py==3.0.0 (from -r requirements.txt (line 147))\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting matplotlib==3.7.3 (from -r requirements.txt (line 148))\n",
      "  Downloading matplotlib-3.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n",
      "Collecting mdit-py-plugins==0.4.1 (from -r requirements.txt (line 149))\n",
      "  Downloading mdit_py_plugins-0.4.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting mdurl==0.1.2 (from -r requirements.txt (line 150))\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting memray==1.12.0 (from -r requirements.txt (line 151))\n",
      "  Downloading memray-1.12.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (19 kB)\n",
      "Collecting ml-metadata==1.15.0 (from -r requirements.txt (line 152))\n",
      "  Downloading ml_metadata-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting ml-pipelines-sdk==1.15.1 (from -r requirements.txt (line 153))\n",
      "  Downloading ml_pipelines_sdk-1.15.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting more-itertools==10.3.0 (from -r requirements.txt (line 154))\n",
      "  Downloading more_itertools-10.3.0-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting msgpack==1.0.8 (from -r requirements.txt (line 155))\n",
      "  Downloading msgpack-1.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting multidict==6.0.5 (from -r requirements.txt (line 156))\n",
      "  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting multimethod==1.11.2 (from -r requirements.txt (line 157))\n",
      "  Downloading multimethod-1.11.2-py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting multipledispatch==1.0.0 (from -r requirements.txt (line 158))\n",
      "  Downloading multipledispatch-1.0.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting namex==0.0.8 (from -r requirements.txt (line 159))\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting nbdime==3.2.0 (from -r requirements.txt (line 160))\n",
      "  Downloading nbdime-3.2.0-py2.py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting networkx==3.3 (from -r requirements.txt (line 161))\n",
      "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting nltk==3.8.1 (from -r requirements.txt (line 162))\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting numba==0.58.1 (from -r requirements.txt (line 163))\n",
      "  Downloading numba-0.58.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting numpy==1.24.3 (from -r requirements.txt (line 164))\n",
      "  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.5.39 (from -r requirements.txt (line 165))\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.5.39-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-ml-py==11.495.46 (from -r requirements.txt (line 166))\n",
      "  Downloading nvidia_ml_py-11.495.46-py3-none-any.whl.metadata (776 bytes)\n",
      "Collecting oauth2client==4.1.3 (from -r requirements.txt (line 167))\n",
      "  Downloading oauth2client-4.1.3-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting oauthlib==3.2.2 (from -r requirements.txt (line 168))\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting objsize==0.7.0 (from -r requirements.txt (line 169))\n",
      "  Downloading objsize-0.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting opencensus==0.11.4 (from -r requirements.txt (line 170))\n",
      "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting opencensus-context==0.1.3 (from -r requirements.txt (line 171))\n",
      "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting opentelemetry-api==1.25.0 (from -r requirements.txt (line 172))\n",
      "  Downloading opentelemetry_api-1.25.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp==1.25.0 (from -r requirements.txt (line 173))\n",
      "  Downloading opentelemetry_exporter_otlp-1.25.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.25.0 (from -r requirements.txt (line 174))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.25.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc==1.25.0 (from -r requirements.txt (line 175))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http==1.25.0 (from -r requirements.txt (line 176))\n",
      "  Downloading opentelemetry_exporter_otlp_proto_http-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-proto==1.25.0 (from -r requirements.txt (line 177))\n",
      "  Downloading opentelemetry_proto-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-sdk==1.25.0 (from -r requirements.txt (line 178))\n",
      "  Downloading opentelemetry_sdk-1.25.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.46b0 (from -r requirements.txt (line 179))\n",
      "  Downloading opentelemetry_semantic_conventions-0.46b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opt-einsum==3.3.0 (from -r requirements.txt (line 180))\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting optree==0.11.0 (from -r requirements.txt (line 181))\n",
      "  Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (45 kB)\n",
      "      45.4/45.4 kB 4.6 MB/s eta 0:00:00\n",
      "Collecting orjson==3.10.5 (from -r requirements.txt (line 182))\n",
      "  Downloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "      49.7/49.7 kB 4.5 MB/s eta 0:00:00\n",
      "Collecting pandas==1.5.3 (from -r requirements.txt (line 183))\n",
      "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting pandas-profiling==3.6.6 (from -r requirements.txt (line 184))\n",
      "  Downloading pandas_profiling-3.6.6-py2.py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting papermill==2.6.0 (from -r requirements.txt (line 185))\n",
      "  Downloading papermill-2.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting parsy==2.1 (from -r requirements.txt (line 186))\n",
      "  Downloading parsy-2.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting patsy==0.5.6 (from -r requirements.txt (line 187))\n",
      "  Downloading patsy-0.5.6-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting pendulum==3.0.0 (from -r requirements.txt (line 188))\n",
      "  Downloading pendulum-3.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
      "Collecting pillow==10.3.0 (from -r requirements.txt (line 189))\n",
      "  Downloading pillow-10.3.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting pins==0.8.6 (from -r requirements.txt (line 190))\n",
      "  Downloading pins-0.8.6-py2.py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting plotly==5.22.0 (from -r requirements.txt (line 191))\n",
      "  Downloading plotly-5.22.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting portalocker==2.10.0 (from -r requirements.txt (line 192))\n",
      "  Downloading portalocker-2.10.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting portpicker==1.6.0 (from -r requirements.txt (line 193))\n",
      "  Downloading portpicker-1.6.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting prettytable==3.10.0 (from -r requirements.txt (line 194))\n",
      "  Downloading prettytable-3.10.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting proto-plus==1.23.0 (from -r requirements.txt (line 195))\n",
      "  Downloading proto_plus-1.23.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf==3.20.3 (from -r requirements.txt (line 196))\n",
      "  Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (679 bytes)\n",
      "Collecting psutil==5.9.3 (from -r requirements.txt (line 197))\n",
      "  Downloading psutil-5.9.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Collecting py-spy==0.3.14 (from -r requirements.txt (line 198))\n",
      "  Downloading py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (16 kB)\n",
      "Collecting pyarrow==10.0.1 (from -r requirements.txt (line 199))\n",
      "  Downloading pyarrow-10.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting pyarrow-hotfix==0.6 (from -r requirements.txt (line 200))\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting pyasn1==0.6.0 (from -r requirements.txt (line 201))\n",
      "  Downloading pyasn1-0.6.0-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting pyasn1_modules==0.4.0 (from -r requirements.txt (line 202))\n",
      "  Downloading pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting pydantic==1.10.16 (from -r requirements.txt (line 203))\n",
      "  Downloading pydantic-1.10.16-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (151 kB)\n",
      "      151.1/151.1 kB 15.7 MB/s eta 0:00:00\n",
      "Collecting pydata-google-auth==1.8.2 (from -r requirements.txt (line 204))\n",
      "  Downloading pydata_google_auth-1.8.2-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pydot==1.4.2 (from -r requirements.txt (line 205))\n",
      "  Downloading pydot-1.4.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting pyfarmhash==0.3.2 (from -r requirements.txt (line 206))\n",
      "  Downloading pyfarmhash-0.3.2.tar.gz (99 kB)\n",
      "      99.9/99.9 kB 11.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pyjsparser==2.7.1 (from -r requirements.txt (line 207))\n",
      "  Downloading pyjsparser-2.7.1.tar.gz (24 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting PyJWT==2.8.0 (from -r requirements.txt (line 208))\n",
      "  Downloading PyJWT-2.8.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting pymongo==4.7.3 (from -r requirements.txt (line 209))\n",
      "  Downloading pymongo-4.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
      "Collecting pyparsing==3.1.2 (from -r requirements.txt (line 210))\n",
      "  Downloading pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting pyproj==3.6.1 (from -r requirements.txt (line 211))\n",
      "  Downloading pyproj-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting pytest==8.2.2 (from -r requirements.txt (line 212))\n",
      "  Downloading pytest-8.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting python-dotenv==1.0.1 (from -r requirements.txt (line 213))\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting python-multipart==0.0.9 (from -r requirements.txt (line 214))\n",
      "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pytz==2024.1 (from -r requirements.txt (line 215))\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting PyWavelets==1.6.0 (from -r requirements.txt (line 216))\n",
      "  Downloading pywavelets-1.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting ray==2.24.0 (from -r requirements.txt (line 217))\n",
      "  Downloading ray-2.24.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting ray-cpp==2.24.0 (from -r requirements.txt (line 218))\n",
      "  Downloading ray_cpp-2.24.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (6.0 kB)\n",
      "Collecting redis==5.0.6 (from -r requirements.txt (line 219))\n",
      "  Downloading redis-5.0.6-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting regex==2024.5.15 (from -r requirements.txt (line 220))\n",
      "  Downloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "      40.9/40.9 kB 4.2 MB/s eta 0:00:00\n",
      "Collecting requests-oauthlib==2.0.0 (from -r requirements.txt (line 221))\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting requests-toolbelt==0.10.1 (from -r requirements.txt (line 222))\n",
      "  Downloading requests_toolbelt-0.10.1-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting retrying==1.3.4 (from -r requirements.txt (line 223))\n",
      "  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting rich==13.7.1 (from -r requirements.txt (line 224))\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting rouge_score==0.1.2 (from -r requirements.txt (line 225))\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting rsa==4.9 (from -r requirements.txt (line 226))\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting sacrebleu==2.4.2 (from -r requirements.txt (line 227))\n",
      "  Downloading sacrebleu-2.4.2-py3-none-any.whl.metadata (58 kB)\n",
      "      58.0/58.0 kB 5.0 MB/s eta 0:00:00\n",
      "Collecting scikit-image==0.23.2 (from -r requirements.txt (line 228))\n",
      "  Downloading scikit_image-0.23.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Collecting scikit-learn==1.5.0 (from -r requirements.txt (line 229))\n",
      "  Downloading scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting scipy==1.11.4 (from -r requirements.txt (line 230))\n",
      "  Downloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "      60.4/60.4 kB 5.1 MB/s eta 0:00:00\n",
      "Collecting seaborn==0.12.2 (from -r requirements.txt (line 231))\n",
      "  Downloading seaborn-0.12.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting SecretStorage==3.3.3 (from -r requirements.txt (line 232))\n",
      "  Downloading SecretStorage-3.3.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting shapely==2.0.4 (from -r requirements.txt (line 233))\n",
      "  Downloading shapely-2.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting shellingham==1.5.4 (from -r requirements.txt (line 234))\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting simpervisor==1.0.0 (from -r requirements.txt (line 235))\n",
      "  Downloading simpervisor-1.0.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting smart-open==7.0.4 (from -r requirements.txt (line 236))\n",
      "  Downloading smart_open-7.0.4-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting smmap==5.0.1 (from -r requirements.txt (line 237))\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting SQLAlchemy==2.0.30 (from -r requirements.txt (line 238))\n",
      "  Downloading SQLAlchemy-2.0.30-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting sqlglot==19.9.0 (from -r requirements.txt (line 239))\n",
      "  Downloading sqlglot-19.9.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting sqlparse==0.5.0 (from -r requirements.txt (line 240))\n",
      "  Downloading sqlparse-0.5.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting starlette==0.37.2 (from -r requirements.txt (line 241))\n",
      "  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting statsmodels==0.14.2 (from -r requirements.txt (line 242))\n",
      "  Downloading statsmodels-0.14.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting struct2tensor (from -r requirements.txt (line 243))\n",
      "  Downloading struct2tensor-0.46.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting tabulate==0.9.0 (from -r requirements.txt (line 244))\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting tangled-up-in-unicode==0.2.0 (from -r requirements.txt (line 245))\n",
      "  Downloading tangled_up_in_unicode-0.2.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting tenacity==8.3.0 (from -r requirements.txt (line 246))\n",
      "  Downloading tenacity-8.3.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting tensorboard==2.15.2 (from -r requirements.txt (line 247))\n",
      "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting tensorboard-data-server==0.7.2 (from -r requirements.txt (line 248))\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting tensorboard_plugin_profile==2.15.1 (from -r requirements.txt (line 249))\n",
      "  Downloading tensorboard_plugin_profile-2.15.1-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting tensorboardX==2.6.2.2 (from -r requirements.txt (line 250))\n",
      "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting tensorflow==2.15.1 (from -r requirements.txt (line 251))\n",
      "  Downloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting tensorflow-data-validation (from -r requirements.txt (line 252))\n",
      "  Downloading tensorflow_data_validation-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting tensorflow-estimator==2.15.0 (from -r requirements.txt (line 253))\n",
      "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting tensorflow-hub==0.15.0 (from -r requirements.txt (line 254))\n",
      "  Downloading tensorflow_hub-0.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem==0.37.0 (from -r requirements.txt (line 255))\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Collecting tensorflow-metadata (from -r requirements.txt (line 256))\n",
      "  Downloading tensorflow_metadata-1.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting tensorflow-serving-api (from -r requirements.txt (line 257))\n",
      "  Downloading tensorflow_serving_api-2.16.1-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorflow-transform (from -r requirements.txt (line 258))\n",
      "  Downloading tensorflow_transform-1.15.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting tensorflow_model_analysis (from -r requirements.txt (line 259))\n",
      "  Downloading tensorflow_model_analysis-0.46.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting tensorrt==10.1.0 (from -r requirements.txt (line 260))\n",
      "  Downloading tensorrt-10.1.0.tar.gz (16 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting tensorrt-cu12==10.1.0 (from -r requirements.txt (line 261))\n",
      "  Downloading tensorrt-cu12-10.1.0.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting tensorrt-cu12-bindings==10.1.0 (from -r requirements.txt (line 262))\n",
      "  Downloading tensorrt_cu12_bindings-10.1.0-cp310-none-manylinux_2_17_x86_64.whl.metadata (627 bytes)\n",
      "Collecting tensorrt-cu12-libs==10.1.0 (from -r requirements.txt (line 263))\n",
      "  Downloading tensorrt_cu12_libs-10.1.0.tar.gz (630 bytes)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting termcolor==2.4.0 (from -r requirements.txt (line 264))\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting textual==0.67.1 (from -r requirements.txt (line 265))\n",
      "  Downloading textual-0.67.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting tf_keras (from -r requirements.txt (line 266))\n",
      "  Downloading tf_keras-2.16.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting tfx==1.15.1 (from -r requirements.txt (line 267))\n",
      "  Downloading tfx-1.15.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting tfx-bsl==1.15.1 (from -r requirements.txt (line 268))\n",
      "  Downloading tfx_bsl-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting threadpoolctl==3.5.0 (from -r requirements.txt (line 269))\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting tifffile==2024.5.22 (from -r requirements.txt (line 270))\n",
      "  Downloading tifffile-2024.5.22-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting time-machine==2.14.1 (from -r requirements.txt (line 271))\n",
      "  Downloading time_machine-2.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Collecting tomli==2.0.1 (from -r requirements.txt (line 272))\n",
      "  Downloading tomli-2.0.1-py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting toolz==0.12.1 (from -r requirements.txt (line 273))\n",
      "  Downloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting typeguard==4.3.0 (from -r requirements.txt (line 274))\n",
      "  Downloading typeguard-4.3.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting typer==0.12.3 (from -r requirements.txt (line 275))\n",
      "  Downloading typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting tzdata==2024.1 (from -r requirements.txt (line 276))\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting tzlocal==5.2 (from -r requirements.txt (line 277))\n",
      "  Downloading tzlocal-5.2-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting uc-micro-py==1.0.3 (from -r requirements.txt (line 278))\n",
      "  Downloading uc_micro_py-1.0.3-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting ujson==5.10.0 (from -r requirements.txt (line 279))\n",
      "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
      "Collecting uritemplate==3.0.1 (from -r requirements.txt (line 280))\n",
      "  Downloading uritemplate-3.0.1-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting urllib3==1.26.18 (from -r requirements.txt (line 281))\n",
      "  Downloading urllib3-1.26.18-py2.py3-none-any.whl.metadata (48 kB)\n",
      "      48.9/48.9 kB 5.4 MB/s eta 0:00:00\n",
      "Collecting uvicorn==0.30.1 (from -r requirements.txt (line 282))\n",
      "  Downloading uvicorn-0.30.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting uvloop==0.19.0 (from -r requirements.txt (line 283))\n",
      "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting virtualenv==20.26.2 (from -r requirements.txt (line 284))\n",
      "  Downloading virtualenv-20.26.2-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting visions==0.7.5 (from -r requirements.txt (line 285))\n",
      "  Downloading visions-0.7.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting watchfiles==0.22.0 (from -r requirements.txt (line 286))\n",
      "  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets==12.0 (from -r requirements.txt (line 287))\n",
      "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting Werkzeug==3.0.3 (from -r requirements.txt (line 288))\n",
      "  Downloading werkzeug-3.0.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting wordcloud==1.9.3 (from -r requirements.txt (line 289))\n",
      "  Downloading wordcloud-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting wrapt==1.14.1 (from -r requirements.txt (line 290))\n",
      "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting wurlitzer==3.1.1 (from -r requirements.txt (line 291))\n",
      "  Downloading wurlitzer-3.1.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting xxhash==3.4.1 (from -r requirements.txt (line 292))\n",
      "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting y-py==0.6.2 (from -r requirements.txt (line 293))\n",
      "  Downloading y_py-0.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting yarg==0.1.9 (from -r requirements.txt (line 294))\n",
      "  Downloading yarg-0.1.9-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting yarl==1.9.4 (from -r requirements.txt (line 295))\n",
      "  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting ydata-profiling==4.6.0 (from -r requirements.txt (line 296))\n",
      "  Downloading ydata_profiling-4.6.0-py2.py3-none-any.whl.metadata (20 kB)\n",
      "Collecting ydf==0.5.0 (from -r requirements.txt (line 297))\n",
      "  Downloading ydf-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting ypy-websocket==0.8.4 (from -r requirements.txt (line 298))\n",
      "  Downloading ypy_websocket-0.8.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting zstandard==0.22.0 (from -r requirements.txt (line 299))\n",
      "  Downloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp==3.9.5->-r requirements.txt (line 3))\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting jsonschema<5.0.0,>=4.0.0 (from apache-beam==2.56.0->-r requirements.txt (line 8))\n",
      "  Downloading jsonschema-4.22.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting packaging>=22.0 (from apache-beam==2.56.0->-r requirements.txt (line 8))\n",
      "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting python-dateutil<3,>=2.8.0 (from apache-beam==2.56.0->-r requirements.txt (line 8))\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting requests<3.0.0,>=2.24.0 (from apache-beam==2.56.0->-r requirements.txt (line 8))\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typing-extensions>=3.7.0 (from apache-beam==2.56.0->-r requirements.txt (line 8))\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/site-packages (from astunparse==1.6.3->-r requirements.txt (line 10)) (0.43.0)\n",
      "Collecting six<2.0,>=1.6.1 (from astunparse==1.6.3->-r requirements.txt (line 10))\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting ipywidgets>=7.7.1 (from bigframes==0.22.0->-r requirements.txt (line 17))\n",
      "  Downloading ipywidgets-8.1.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting wcwidth>=0.1.4 (from blessed==1.20.0->-r requirements.txt (line 18))\n",
      "  Downloading wcwidth-0.2.13-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting cffi>=1.0.0 (from brotlipy==0.7.0->-r requirements.txt (line 19))\n",
      "  Downloading cffi-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting jupyter-server<3,>=2.7.3 (from dataproc_jupyter_plugin==0.1.79->-r requirements.txt (line 31))\n",
      "  Downloading jupyter_server-2.14.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting websocket-client>=0.32.0 (from docker==4.4.4->-r requirements.txt (line 38))\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting idna>=2.0.0 (from email_validator==2.1.1->-r requirements.txt (line 41))\n",
      "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting certifi (from fiona==1.9.6->-r requirements.txt (line 46))\n",
      "  Downloading certifi-2024.6.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting decorator>4.1.2 (from gcsfs==2024.6.0->-r requirements.txt (line 52))\n",
      "  Downloading decorator-5.1.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting traitlets (from google-cloud-jupyter-config==0.0.10->-r requirements.txt (line 73))\n",
      "  Downloading traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting overrides<8.0.0,>=6.0.1 (from google-cloud-pubsublite==1.10.0->-r requirements.txt (line 77))\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting anyio (from httpx==0.27.0->-r requirements.txt (line 103))\n",
      "  Downloading anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting sniffio (from httpx==0.27.0->-r requirements.txt (line 103))\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting notebook>=5.0 (from jupyter-http-over-ws==0.0.8->-r requirements.txt (line 119))\n",
      "  Downloading notebook-7.2.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting tornado>=4.5 (from jupyter-http-over-ws==0.0.8->-r requirements.txt (line 119))\n",
      "  Downloading tornado-6.4.1-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting jupyter-events>=0.5.0 (from jupyter_server_fileid==0.9.2->-r requirements.txt (line 122))\n",
      "  Downloading jupyter_events-0.10.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting nbformat (from jupyterlab_git==0.44.0->-r requirements.txt (line 125))\n",
      "  Downloading nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting pexpect (from jupyterlab_git==0.44.0->-r requirements.txt (line 125))\n",
      "  Downloading pexpect-4.9.0-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting jinja2>=3.0.3 (from jupyterlab_server==2.27.2->-r requirements.txt (line 126))\n",
      "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting pyyaml (from jupytext==1.16.2->-r requirements.txt (line 128))\n",
      "  Downloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting importlib-metadata>=4.11.4 (from keyring==25.2.1->-r requirements.txt (line 132))\n",
      "  Downloading importlib_metadata-8.0.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting pluggy (from keyrings.google-artifactregistry-auth==1.1.2->-r requirements.txt (line 133))\n",
      "  Downloading pluggy-1.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.10/site-packages (from kubernetes==12.0.1->-r requirements.txt (line 139)) (65.5.1)\n",
      "Collecting colorama (from nbdime==3.2.0->-r requirements.txt (line 160))\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting pygments (from nbdime==3.2.0->-r requirements.txt (line 160))\n",
      "  Downloading pygments-2.18.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting tqdm (from nltk==3.8.1->-r requirements.txt (line 162))\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "      57.6/57.6 kB 7.1 MB/s eta 0:00:00\n",
      "Collecting importlib-metadata>=4.11.4 (from keyring==25.2.1->-r requirements.txt (line 132))\n",
      "  Downloading importlib_metadata-7.1.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting nbclient>=0.2.0 (from papermill==2.6.0->-r requirements.txt (line 185))\n",
      "  Downloading nbclient-0.10.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting entrypoints (from papermill==2.6.0->-r requirements.txt (line 185))\n",
      "  Downloading entrypoints-0.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting importlib-resources>=1.3 (from pins==0.8.6->-r requirements.txt (line 190))\n",
      "  Downloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting exceptiongroup>=1.0.0rc8 (from pytest==8.2.2->-r requirements.txt (line 212))\n",
      "  Downloading exceptiongroup-1.2.1-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting cryptography>=2.0 (from SecretStorage==3.3.3->-r requirements.txt (line 232))\n",
      "  Downloading cryptography-42.0.8-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow==2.15.1->-r requirements.txt (line 251))\n",
      "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting keras (from -r requirements.txt (line 129))\n",
      "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting tensorflow-serving-api (from -r requirements.txt (line 257))\n",
      "  Downloading tensorflow_serving_api-2.15.1-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting platformdirs<5,>=3.9.1 (from virtualenv==20.26.2->-r requirements.txt (line 284))\n",
      "  Downloading platformdirs-4.2.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from Werkzeug==3.0.3->-r requirements.txt (line 288))\n",
      "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting phik<0.13,>=0.11.1 (from ydata-profiling==4.6.0->-r requirements.txt (line 296))\n",
      "  Downloading phik-0.12.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting ipython<8,>=7 (from tensorflow_model_analysis->-r requirements.txt (line 259))\n",
      "  Downloading ipython-7.34.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting ipywidgets>=7.7.1 (from bigframes==0.22.0->-r requirements.txt (line 17))\n",
      "  Downloading ipywidgets-7.8.1-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "INFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tf_keras (from -r requirements.txt (line 266))\n",
      "  Downloading tf_keras-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting pycparser (from cffi>=1.0.0->brotlipy==0.7.0->-r requirements.txt (line 19))\n",
      "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting zipp>=0.5 (from importlib-metadata>=4.11.4->keyring==25.2.1->-r requirements.txt (line 132))\n",
      "  Downloading zipp-3.19.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting jedi>=0.16 (from ipython<8,>=7->tensorflow_model_analysis->-r requirements.txt (line 259))\n",
      "  Downloading jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting pickleshare (from ipython<8,>=7->tensorflow_model_analysis->-r requirements.txt (line 259))\n",
      "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 (from ipython<8,>=7->tensorflow_model_analysis->-r requirements.txt (line 259))\n",
      "  Downloading prompt_toolkit-3.0.47-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting matplotlib-inline (from ipython<8,>=7->tensorflow_model_analysis->-r requirements.txt (line 259))\n",
      "  Downloading matplotlib_inline-0.1.7-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting comm>=0.1.3 (from ipywidgets>=7.7.1->bigframes==0.22.0->-r requirements.txt (line 17))\n",
      "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting ipython-genutils~=0.2.0 (from ipywidgets>=7.7.1->bigframes==0.22.0->-r requirements.txt (line 17))\n",
      "  Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl.metadata (755 bytes)\n",
      "Collecting widgetsnbextension~=3.6.6 (from ipywidgets>=7.7.1->bigframes==0.22.0->-r requirements.txt (line 17))\n",
      "  Downloading widgetsnbextension-3.6.6-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "INFO: pip is looking at multiple versions of ipywidgets to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting ipywidgets>=7.7.1 (from bigframes==0.22.0->-r requirements.txt (line 17))\n",
      "  Downloading ipywidgets-7.8.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "  Downloading ipywidgets-7.7.5-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting ipykernel>=4.5.1 (from ipywidgets>=7.7.1->bigframes==0.22.0->-r requirements.txt (line 17))\n",
      "  Downloading ipykernel-6.29.4-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting ipywidgets>=7.7.1 (from bigframes==0.22.0->-r requirements.txt (line 17))\n",
      "  Downloading ipywidgets-7.7.4-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "  Downloading ipywidgets-7.7.3-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "  Downloading ipywidgets-7.7.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "  Downloading ipywidgets-7.7.1-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema<5.0.0,>=4.0.0->apache-beam==2.56.0->-r requirements.txt (line 8))\n",
      "  Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema<5.0.0,>=4.0.0->apache-beam==2.56.0->-r requirements.txt (line 8))\n",
      "  Downloading referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema<5.0.0,>=4.0.0->apache-beam==2.56.0->-r requirements.txt (line 8))\n",
      "  Downloading rpds_py-0.18.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.5.0->jupyter_server_fileid==0.9.2->-r requirements.txt (line 122))\n",
      "  Downloading python_json_logger-2.0.7-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting rfc3339-validator (from jupyter-events>=0.5.0->jupyter_server_fileid==0.9.2->-r requirements.txt (line 122))\n",
      "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.5.0->jupyter_server_fileid==0.9.2->-r requirements.txt (line 122))\n",
      "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting argon2-cffi>=21.1 (from jupyter-server<3,>=2.7.3->dataproc_jupyter_plugin==0.1.79->-r requirements.txt (line 31))\n",
      "  Downloading argon2_cffi-23.1.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting jupyter-client>=7.4.4 (from jupyter-server<3,>=2.7.3->dataproc_jupyter_plugin==0.1.79->-r requirements.txt (line 31))\n",
      "  Downloading jupyter_client-8.6.2-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting jupyter-core!=5.0.*,>=4.12 (from jupyter-server<3,>=2.7.3->dataproc_jupyter_plugin==0.1.79->-r requirements.txt (line 31))\n",
      "  Downloading jupyter_core-5.7.2-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.7.3->dataproc_jupyter_plugin==0.1.79->-r requirements.txt (line 31))\n",
      "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting nbconvert>=6.4.4 (from jupyter-server<3,>=2.7.3->dataproc_jupyter_plugin==0.1.79->-r requirements.txt (line 31))\n",
      "  Downloading nbconvert-7.16.4-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting prometheus-client>=0.9 (from jupyter-server<3,>=2.7.3->dataproc_jupyter_plugin==0.1.79->-r requirements.txt (line 31))\n",
      "  Downloading prometheus_client-0.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting pyzmq>=24 (from jupyter-server<3,>=2.7.3->dataproc_jupyter_plugin==0.1.79->-r requirements.txt (line 31))\n",
      "  Downloading pyzmq-26.0.3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting send2trash>=1.8.2 (from jupyter-server<3,>=2.7.3->dataproc_jupyter_plugin==0.1.79->-r requirements.txt (line 31))\n",
      "  Downloading Send2Trash-1.8.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting terminado>=0.8.3 (from jupyter-server<3,>=2.7.3->dataproc_jupyter_plugin==0.1.79->-r requirements.txt (line 31))\n",
      "  Downloading terminado-0.18.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting fastjsonschema>=2.15 (from nbformat->jupyterlab_git==0.44.0->-r requirements.txt (line 125))\n",
      "  Downloading fastjsonschema-2.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting jupyterlab<4.3,>=4.2.0 (from notebook>=5.0->jupyter-http-over-ws==0.0.8->-r requirements.txt (line 119))\n",
      "  Downloading jupyterlab-4.2.3-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting notebook-shim<0.3,>=0.2 (from notebook>=5.0->jupyter-http-over-ws==0.0.8->-r requirements.txt (line 119))\n",
      "  Downloading notebook_shim-0.2.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting ptyprocess>=0.5 (from pexpect->jupyterlab_git==0.44.0->-r requirements.txt (line 125))\n",
      "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3.0.0,>=2.24.0->apache-beam==2.56.0->-r requirements.txt (line 8))\n",
      "  Downloading charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Collecting argon2-cffi-bindings (from argon2-cffi>=21.1->jupyter-server<3,>=2.7.3->dataproc_jupyter_plugin==0.1.79->-r requirements.txt (line 31))\n",
      "  Downloading argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting debugpy>=1.6.5 (from ipykernel>=4.5.1->ipywidgets>=7.7.1->bigframes==0.22.0->-r requirements.txt (line 17))\n",
      "  Downloading debugpy-1.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting nest-asyncio (from ipykernel>=4.5.1->ipywidgets>=7.7.1->bigframes==0.22.0->-r requirements.txt (line 17))\n",
      "  Downloading nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting parso<0.9.0,>=0.8.3 (from jedi>=0.16->ipython<8,>=7->tensorflow_model_analysis->-r requirements.txt (line 259))\n",
      "  Downloading parso-0.8.4-py2.py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.5.0->jupyter_server_fileid==0.9.2->-r requirements.txt (line 122))\n",
      "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.5.0->jupyter_server_fileid==0.9.2->-r requirements.txt (line 122))\n",
      "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jsonpointer>1.13 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.5.0->jupyter_server_fileid==0.9.2->-r requirements.txt (line 122))\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.5.0->jupyter_server_fileid==0.9.2->-r requirements.txt (line 122))\n",
      "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting webcolors>=1.11 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.5.0->jupyter_server_fileid==0.9.2->-r requirements.txt (line 122))\n",
      "  Downloading webcolors-24.6.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting async-lru>=1.0.0 (from jupyterlab<4.3,>=4.2.0->notebook>=5.0->jupyter-http-over-ws==0.0.8->-r requirements.txt (line 119))\n",
      "  Downloading async_lru-2.0.4-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting jupyter-lsp>=2.0.0 (from jupyterlab<4.3,>=4.2.0->notebook>=5.0->jupyter-http-over-ws==0.0.8->-r requirements.txt (line 119))\n",
      "  Downloading jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting beautifulsoup4 (from nbconvert>=6.4.4->jupyter-server<3,>=2.7.3->dataproc_jupyter_plugin==0.1.79->-r requirements.txt (line 31))\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting bleach!=5.0.0 (from nbconvert>=6.4.4->jupyter-server<3,>=2.7.3->dataproc_jupyter_plugin==0.1.79->-r requirements.txt (line 31))\n",
      "  Downloading bleach-6.1.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting defusedxml (from nbconvert>=6.4.4->jupyter-server<3,>=2.7.3->dataproc_jupyter_plugin==0.1.79->-r requirements.txt (line 31))\n",
      "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting jupyterlab-pygments (from nbconvert>=6.4.4->jupyter-server<3,>=2.7.3->dataproc_jupyter_plugin==0.1.79->-r requirements.txt (line 31))\n",
      "  Downloading jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting mistune<4,>=2.0.3 (from nbconvert>=6.4.4->jupyter-server<3,>=2.7.3->dataproc_jupyter_plugin==0.1.79->-r requirements.txt (line 31))\n",
      "  Downloading mistune-3.0.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting pandocfilters>=1.4.1 (from nbconvert>=6.4.4->jupyter-server<3,>=2.7.3->dataproc_jupyter_plugin==0.1.79->-r requirements.txt (line 31))\n",
      "  Downloading pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting tinycss2 (from nbconvert>=6.4.4->jupyter-server<3,>=2.7.3->dataproc_jupyter_plugin==0.1.79->-r requirements.txt (line 31))\n",
      "  Downloading tinycss2-1.3.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting webencodings (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.7.3->dataproc_jupyter_plugin==0.1.79->-r requirements.txt (line 31))\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.7.3->dataproc_jupyter_plugin==0.1.79->-r requirements.txt (line 31))\n",
      "  Downloading soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.5.0->jupyter_server_fileid==0.9.2->-r requirements.txt (line 122))\n",
      "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.5.0->jupyter_server_fileid==0.9.2->-r requirements.txt (line 122))\n",
      "  Downloading types_python_dateutil-2.9.0.20240316-py3-none-any.whl.metadata (1.8 kB)\n",
      "Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "    126.5/126.5 kB 15.0 MB/s eta 0:00:00\n",
      "Downloading aiofiles-22.1.0-py3-none-any.whl (14 kB)\n",
      "Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "    1.2/1.2 MB 61.6 MB/s eta 0:00:00\n",
      "Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading ansicolors-1.1.8-py2.py3-none-any.whl (13 kB)\n",
      "Downloading apache_beam-2.56.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.5 MB)\n",
      "    14.5/14.5 MB 96.0 MB/s eta 0:00:00\n",
      "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading atpublic-4.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading Babel-2.15.0-py3-none-any.whl (9.6 MB)\n",
      "    9.6/9.6 MB 104.0 MB/s eta 0:00:00\n",
      "Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading backports.tarfile-1.2.0-py3-none-any.whl (30 kB)\n",
      "Downloading bidict-0.23.1-py3-none-any.whl (32 kB)\n",
      "Downloading bigframes-0.22.0-py2.py3-none-any.whl (441 kB)\n",
      "    441.2/441.2 kB 38.0 MB/s eta 0:00:00\n",
      "Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n",
      "    58.4/58.4 kB 7.4 MB/s eta 0:00:00\n",
      "Downloading brotlipy-0.7.0-cp35-abi3-manylinux2010_x86_64.whl (1.1 MB)\n",
      "    1.1/1.1 MB 60.7 MB/s eta 0:00:00\n",
      "Downloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "    97.9/97.9 kB 13.8 MB/s eta 0:00:00\n",
      "Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
      "Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
      "Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Downloading colorful-0.5.6-py2.py3-none-any.whl (201 kB)\n",
      "    201.4/201.4 kB 23.8 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (305 kB)\n",
      "    305.2/305.2 kB 29.3 MB/s eta 0:00:00\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading Cython-3.0.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "    3.6/3.6 MB 93.1 MB/s eta 0:00:00\n",
      "Downloading dacite-1.8.1-py3-none-any.whl (14 kB)\n",
      "Downloading dataproc_jupyter_plugin-0.1.79-py3-none-any.whl (4.2 MB)\n",
      "    4.2/4.2 MB 85.1 MB/s eta 0:00:00\n",
      "Downloading db_dtypes-1.2.0-py2.py3-none-any.whl (14 kB)\n",
      "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
      "    468.9/468.9 kB 38.9 MB/s eta 0:00:00\n",
      "Downloading dm_tree-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (152 kB)\n",
      "    152.8/152.8 kB 18.5 MB/s eta 0:00:00\n",
      "Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
      "    307.7/307.7 kB 28.6 MB/s eta 0:00:00\n",
      "Downloading docker-4.4.4-py2.py3-none-any.whl (147 kB)\n",
      "    147.0/147.0 kB 17.0 MB/s eta 0:00:00\n",
      "Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading email_validator-2.1.1-py3-none-any.whl (30 kB)\n",
      "Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
      "Downloading fastavro-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "    3.1/3.1 MB 85.7 MB/s eta 0:00:00\n",
      "Downloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
      "Downloading filelock-3.15.1-py3-none-any.whl (15 kB)\n",
      "Downloading fiona-1.9.6-cp310-cp310-manylinux2014_x86_64.whl (15.7 MB)\n",
      "    15.7/15.7 MB 88.7 MB/s eta 0:00:00\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading fonttools-4.53.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "    4.6/4.6 MB 87.2 MB/s eta 0:00:00\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "    239.5/239.5 kB 25.4 MB/s eta 0:00:00\n",
      "Downloading fsspec-2024.6.0-py3-none-any.whl (176 kB)\n",
      "    176.9/176.9 kB 20.4 MB/s eta 0:00:00\n",
      "Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Downloading gcsfs-2024.6.0-py2.py3-none-any.whl (34 kB)\n",
      "Downloading geopandas-0.14.4-py3-none-any.whl (1.1 MB)\n",
      "    1.1/1.1 MB 55.7 MB/s eta 0:00:00\n",
      "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "    62.7/62.7 kB 6.3 MB/s eta 0:00:00\n",
      "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "    207.3/207.3 kB 21.6 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.19.0-py3-none-any.whl (139 kB)\n",
      "    139.0/139.0 kB 14.6 MB/s eta 0:00:00\n",
      "Downloading google_api_python_client-1.12.11-py2.py3-none-any.whl (62 kB)\n",
      "    62.1/62.1 kB 7.3 MB/s eta 0:00:00\n",
      "Downloading google_auth-2.30.0-py2.py3-none-any.whl (193 kB)\n",
      "    193.7/193.7 kB 21.8 MB/s eta 0:00:00\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Downloading google_cloud_aiplatform-1.55.0-py2.py3-none-any.whl (5.1 MB)\n",
      "    5.1/5.1 MB 89.5 MB/s eta 0:00:00\n",
      "Downloading google_cloud_artifact_registry-1.11.3-py2.py3-none-any.whl (185 kB)\n",
      "    185.6/185.6 kB 20.6 MB/s eta 0:00:00\n",
      "Downloading google_cloud_bigquery-3.24.0-py2.py3-none-any.whl (238 kB)\n",
      "    238.5/238.5 kB 25.0 MB/s eta 0:00:00\n",
      "Downloading google_cloud_bigquery_connection-1.15.3-py2.py3-none-any.whl (58 kB)\n",
      "    58.1/58.1 kB 7.6 MB/s eta 0:00:00\n",
      "Downloading google_cloud_bigquery_storage-2.25.0-py2.py3-none-any.whl (199 kB)\n",
      "    199.8/199.8 kB 21.6 MB/s eta 0:00:00\n",
      "Downloading google_cloud_bigtable-2.24.0-py2.py3-none-any.whl (373 kB)\n",
      "    373.7/373.7 kB 34.6 MB/s eta 0:00:00\n",
      "Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\n",
      "Downloading google_cloud_datastore-2.19.0-py2.py3-none-any.whl (176 kB)\n",
      "    176.4/176.4 kB 19.5 MB/s eta 0:00:00\n",
      "Downloading google_cloud_dlp-3.18.0-py2.py3-none-any.whl (180 kB)\n",
      "    180.3/180.3 kB 18.1 MB/s eta 0:00:00\n",
      "Downloading google_cloud_functions-1.16.3-py2.py3-none-any.whl (132 kB)\n",
      "    132.3/132.3 kB 16.5 MB/s eta 0:00:00\n",
      "Downloading google_cloud_iam-2.15.0-py2.py3-none-any.whl (205 kB)\n",
      "    205.2/205.2 kB 23.9 MB/s eta 0:00:00\n",
      "Downloading google_cloud_language-2.13.3-py2.py3-none-any.whl (143 kB)\n",
      "    143.7/143.7 kB 16.1 MB/s eta 0:00:00\n",
      "Downloading google_cloud_monitoring-2.21.0-py2.py3-none-any.whl (344 kB)\n",
      "    344.9/344.9 kB 33.2 MB/s eta 0:00:00\n",
      "Downloading google_cloud_pubsub-2.21.5-py2.py3-none-any.whl (273 kB)\n",
      "    273.2/273.2 kB 28.8 MB/s eta 0:00:00\n",
      "Downloading google_cloud_pubsublite-1.10.0-py2.py3-none-any.whl (299 kB)\n",
      "    299.2/299.2 kB 30.3 MB/s eta 0:00:00\n",
      "Downloading google_cloud_recommendations_ai-0.10.10-py2.py3-none-any.whl (180 kB)\n",
      "    180.3/180.3 kB 20.2 MB/s eta 0:00:00\n",
      "Downloading google_cloud_resource_manager-1.12.3-py2.py3-none-any.whl (333 kB)\n",
      "    333.7/333.7 kB 29.5 MB/s eta 0:00:00\n",
      "Downloading google_cloud_spanner-3.47.0-py2.py3-none-any.whl (384 kB)\n",
      "    384.6/384.6 kB 34.3 MB/s eta 0:00:00\n",
      "Downloading google_cloud_storage-2.14.0-py2.py3-none-any.whl (121 kB)\n",
      "    121.6/121.6 kB 13.3 MB/s eta 0:00:00\n",
      "Downloading google_cloud_videointelligence-2.13.3-py2.py3-none-any.whl (240 kB)\n",
      "    240.4/240.4 kB 24.2 MB/s eta 0:00:00\n",
      "Downloading google_cloud_vision-3.7.2-py2.py3-none-any.whl (459 kB)\n",
      "    459.6/459.6 kB 38.4 MB/s eta 0:00:00\n",
      "Downloading google_crc32c-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "    57.5/57.5 kB 5.5 MB/s eta 0:00:00\n",
      "Downloading google_resumable_media-2.7.1-py2.py3-none-any.whl (81 kB)\n",
      "    81.2/81.2 kB 8.7 MB/s eta 0:00:00\n",
      "Downloading googleapis_common_protos-1.63.1-py2.py3-none-any.whl (229 kB)\n",
      "    229.2/229.2 kB 22.3 MB/s eta 0:00:00\n",
      "Downloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (616 kB)\n",
      "    616.0/616.0 kB 45.6 MB/s eta 0:00:00\n",
      "Downloading grpc_google_iam_v1-0.13.0-py2.py3-none-any.whl (25 kB)\n",
      "Downloading grpc_interceptor-0.15.4-py3-none-any.whl (20 kB)\n",
      "Downloading grpcio-1.64.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n",
      "    5.6/5.6 MB 90.6 MB/s eta 0:00:00\n",
      "Downloading grpcio_status-1.48.2-py3-none-any.whl (14 kB)\n",
      "Downloading gviz_api-1.10.0-py2.py3-none-any.whl (13 kB)\n",
      "Downloading gymnasium-0.28.1-py3-none-any.whl (925 kB)\n",
      "    925.5/925.5 kB 52.3 MB/s eta 0:00:00\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "    58.3/58.3 kB 6.8 MB/s eta 0:00:00\n",
      "Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "    5.3/5.3 MB 88.4 MB/s eta 0:00:00\n",
      "Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "    77.9/77.9 kB 8.9 MB/s eta 0:00:00\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "    96.9/96.9 kB 9.7 MB/s eta 0:00:00\n",
      "Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
      "    341.4/341.4 kB 24.0 MB/s eta 0:00:00\n",
      "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "    75.6/75.6 kB 8.7 MB/s eta 0:00:00\n",
      "Downloading humanize-4.9.0-py3-none-any.whl (126 kB)\n",
      "    126.8/126.8 kB 13.7 MB/s eta 0:00:00\n",
      "Downloading hypertune-1.1.0-py3-none-any.whl (22 kB)\n",
      "Downloading ibis_framework-7.1.0-py3-none-any.whl (1.7 MB)\n",
      "    1.7/1.7 MB 68.8 MB/s eta 0:00:00\n",
      "Downloading ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n",
      "    296.5/296.5 kB 29.9 MB/s eta 0:00:00\n",
      "Downloading imageio-2.34.1-py3-none-any.whl (313 kB)\n",
      "    313.5/313.5 kB 31.1 MB/s eta 0:00:00\n",
      "Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading jaraco.classes-3.4.0-py3-none-any.whl (6.8 kB)\n",
      "Downloading jaraco.context-5.3.0-py3-none-any.whl (6.5 kB)\n",
      "Downloading jaraco.functools-4.0.1-py3-none-any.whl (9.8 kB)\n",
      "Downloading jax_jumpy-1.0.0-py3-none-any.whl (20 kB)\n",
      "Downloading jeepney-0.8.0-py3-none-any.whl (48 kB)\n",
      "    48.4/48.4 kB 5.3 MB/s eta 0:00:00\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "    301.8/301.8 kB 26.5 MB/s eta 0:00:00\n",
      "Downloading Js2Py-0.74-py3-none-any.whl (1.0 MB)\n",
      "    1.0/1.0 MB 56.0 MB/s eta 0:00:00\n",
      "Downloading json5-0.9.25-py3-none-any.whl (30 kB)\n",
      "Downloading jsonpickle-3.2.2-py3-none-any.whl (41 kB)\n",
      "    41.8/41.8 kB 4.5 MB/s eta 0:00:00\n",
      "Downloading jupyter_http_over_ws-0.0.8-py2.py3-none-any.whl (18 kB)\n",
      "Downloading jupyter_server_mathjax-0.2.6-py3-none-any.whl (3.1 MB)\n",
      "    3.1/3.1 MB 83.5 MB/s eta 0:00:00\n",
      "Downloading jupyter_ydoc-0.2.5-py3-none-any.whl (6.2 kB)\n",
      "Downloading jupyter_server_fileid-0.9.2-py3-none-any.whl (16 kB)\n",
      "Downloading jupyter_server_proxy-4.2.0-py3-none-any.whl (34 kB)\n",
      "Downloading jupyter_server_ydoc-0.8.0-py3-none-any.whl (11 kB)\n",
      "Downloading jupyterlab_git-0.44.0-py3-none-any.whl (684 kB)\n",
      "    684.2/684.2 kB 44.8 MB/s eta 0:00:00\n",
      "Downloading jupyterlab_server-2.27.2-py3-none-any.whl (59 kB)\n",
      "    59.4/59.4 kB 6.8 MB/s eta 0:00:00\n",
      "Downloading jupyterlab_widgets-3.0.11-py3-none-any.whl (214 kB)\n",
      "    214.4/214.4 kB 22.3 MB/s eta 0:00:00\n",
      "Downloading jupytext-1.16.2-py3-none-any.whl (153 kB)\n",
      "    153.2/153.2 kB 16.8 MB/s eta 0:00:00\n",
      "Downloading keyring-25.2.1-py3-none-any.whl (38 kB)\n",
      "Downloading keyrings.google_artifactregistry_auth-1.1.2-py3-none-any.whl (10 kB)\n",
      "Downloading kfp_pipeline_spec-0.2.2-py3-none-any.whl (20 kB)\n",
      "Downloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "    1.6/1.6 MB 70.4 MB/s eta 0:00:00\n",
      "Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Downloading kubernetes-12.0.1-py2.py3-none-any.whl (1.7 MB)\n",
      "    1.7/1.7 MB 67.4 MB/s eta 0:00:00\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "    24.5/24.5 MB 75.7 MB/s eta 0:00:00\n",
      "Downloading linkify_it_py-2.0.3-py3-none-any.whl (19 kB)\n",
      "Downloading llvmlite-0.41.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.6 MB)\n",
      "    43.6/43.6 MB 49.7 MB/s eta 0:00:00\n",
      "Downloading lxml-5.2.2-cp310-cp310-manylinux_2_28_x86_64.whl (5.0 MB)\n",
      "    5.0/5.0 MB 94.4 MB/s eta 0:00:00\n",
      "Downloading lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "    1.3/1.3 MB 63.5 MB/s eta 0:00:00\n",
      "Downloading Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "    105.4/105.4 kB 12.5 MB/s eta 0:00:00\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "    87.5/87.5 kB 9.9 MB/s eta 0:00:00\n",
      "Downloading matplotlib-3.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "    11.6/11.6 MB 100.3 MB/s eta 0:00:00\n",
      "Downloading mdit_py_plugins-0.4.1-py3-none-any.whl (54 kB)\n",
      "    54.8/54.8 kB 5.8 MB/s eta 0:00:00\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading memray-1.12.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.5 MB)\n",
      "    3.5/3.5 MB 88.1 MB/s eta 0:00:00\n",
      "Downloading ml_metadata-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.5 MB)\n",
      "    7.5/7.5 MB 40.4 MB/s eta 0:00:00\n",
      "Downloading ml_pipelines_sdk-1.15.1-py3-none-any.whl (1.8 MB)\n",
      "    1.8/1.8 MB 70.0 MB/s eta 0:00:00\n",
      "Downloading more_itertools-10.3.0-py3-none-any.whl (59 kB)\n",
      "    59.2/59.2 kB 6.4 MB/s eta 0:00:00\n",
      "Downloading msgpack-1.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (385 kB)\n",
      "    385.1/385.1 kB 30.6 MB/s eta 0:00:00\n",
      "Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "    124.3/124.3 kB 12.8 MB/s eta 0:00:00\n",
      "Downloading multimethod-1.11.2-py3-none-any.whl (10 kB)\n",
      "Downloading multipledispatch-1.0.0-py3-none-any.whl (12 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading nbdime-3.2.0-py2.py3-none-any.whl (5.3 MB)\n",
      "    5.3/5.3 MB 82.0 MB/s eta 0:00:00\n",
      "Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "    1.7/1.7 MB 70.9 MB/s eta 0:00:00\n",
      "Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "    1.5/1.5 MB 66.9 MB/s eta 0:00:00\n",
      "Downloading numba-0.58.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.6 MB)\n",
      "    3.6/3.6 MB 78.7 MB/s eta 0:00:00\n",
      "Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "    17.3/17.3 MB 86.1 MB/s eta 0:00:00\n",
      "Downloading nvidia_cuda_runtime_cu12-12.5.39-py3-none-manylinux2014_x86_64.whl (895 kB)\n",
      "    895.1/895.1 kB 51.9 MB/s eta 0:00:00\n",
      "Downloading nvidia_ml_py-11.495.46-py3-none-any.whl (25 kB)\n",
      "Downloading oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
      "    98.2/98.2 kB 10.9 MB/s eta 0:00:00\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "    151.7/151.7 kB 15.3 MB/s eta 0:00:00\n",
      "Downloading objsize-0.7.0-py3-none-any.whl (11 kB)\n",
      "Downloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
      "    128.2/128.2 kB 15.9 MB/s eta 0:00:00\n",
      "Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
      "Downloading opentelemetry_api-1.25.0-py3-none-any.whl (59 kB)\n",
      "    59.9/59.9 kB 6.9 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_exporter_otlp-1.25.0-py3-none-any.whl (7.0 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.25.0-py3-none-any.whl (17 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.25.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_http-1.25.0-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_proto-1.25.0-py3-none-any.whl (52 kB)\n",
      "    52.5/52.5 kB 6.1 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_sdk-1.25.0-py3-none-any.whl (107 kB)\n",
      "    107.0/107.0 kB 13.7 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_semantic_conventions-0.46b0-py3-none-any.whl (130 kB)\n",
      "    130.5/130.5 kB 16.9 MB/s eta 0:00:00\n",
      "Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "    65.5/65.5 kB 5.2 MB/s eta 0:00:00\n",
      "Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n",
      "    311.2/311.2 kB 30.8 MB/s eta 0:00:00\n",
      "Downloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
      "    145.0/145.0 kB 18.3 MB/s eta 0:00:00\n",
      "Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "    12.1/12.1 MB 97.9 MB/s eta 0:00:00\n",
      "Downloading pandas_profiling-3.6.6-py2.py3-none-any.whl (324 kB)\n",
      "    324.4/324.4 kB 29.0 MB/s eta 0:00:00\n",
      "Downloading papermill-2.6.0-py3-none-any.whl (38 kB)\n",
      "Downloading parsy-2.1-py3-none-any.whl (9.1 kB)\n",
      "Downloading patsy-0.5.6-py2.py3-none-any.whl (233 kB)\n",
      "    233.9/233.9 kB 25.9 MB/s eta 0:00:00\n",
      "Downloading pendulum-3.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (384 kB)\n",
      "    384.9/384.9 kB 34.3 MB/s eta 0:00:00\n",
      "Downloading pillow-10.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "    4.5/4.5 MB 90.3 MB/s eta 0:00:00\n",
      "Downloading pins-0.8.6-py2.py3-none-any.whl (114 kB)\n",
      "    114.2/114.2 kB 12.8 MB/s eta 0:00:00\n",
      "Downloading plotly-5.22.0-py3-none-any.whl (16.4 MB)\n",
      "    16.4/16.4 MB 90.8 MB/s eta 0:00:00\n",
      "Downloading portalocker-2.10.0-py3-none-any.whl (18 kB)\n",
      "Downloading portpicker-1.6.0-py3-none-any.whl (16 kB)\n",
      "Downloading prettytable-3.10.0-py3-none-any.whl (28 kB)\n",
      "Downloading proto_plus-1.23.0-py3-none-any.whl (48 kB)\n",
      "    48.8/48.8 kB 4.3 MB/s eta 0:00:00\n",
      "Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "    1.1/1.1 MB 54.3 MB/s eta 0:00:00\n",
      "Downloading psutil-5.9.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (292 kB)\n",
      "    292.3/292.3 kB 23.3 MB/s eta 0:00:00\n",
      "Downloading py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n",
      "    3.0/3.0 MB 82.5 MB/s eta 0:00:00\n",
      "Downloading pyarrow-10.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.9 MB)\n",
      "    35.9/35.9 MB 58.0 MB/s eta 0:00:00\n",
      "Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
      "    85.3/85.3 kB 7.4 MB/s eta 0:00:00\n",
      "Downloading pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "    181.2/181.2 kB 17.4 MB/s eta 0:00:00\n",
      "Downloading pydantic-1.10.16-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "    3.1/3.1 MB 83.3 MB/s eta 0:00:00\n",
      "Downloading pydata_google_auth-1.8.2-py2.py3-none-any.whl (15 kB)\n",
      "Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Downloading PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
      "Downloading pymongo-4.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (669 kB)\n",
      "    669.1/669.1 kB 43.9 MB/s eta 0:00:00\n",
      "Downloading pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "    103.2/103.2 kB 9.9 MB/s eta 0:00:00\n",
      "Downloading pyproj-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "    8.3/8.3 MB 102.7 MB/s eta 0:00:00\n",
      "Downloading pytest-8.2.2-py3-none-any.whl (339 kB)\n",
      "    339.9/339.9 kB 27.7 MB/s eta 0:00:00\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "    505.5/505.5 kB 36.4 MB/s eta 0:00:00\n",
      "Downloading pywavelets-1.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "    4.5/4.5 MB 86.7 MB/s eta 0:00:00\n",
      "Downloading ray-2.24.0-cp310-cp310-manylinux2014_x86_64.whl (65.9 MB)\n",
      "    65.9/65.9 MB 33.7 MB/s eta 0:00:00\n",
      "Downloading ray_cpp-2.24.0-cp310-cp310-manylinux2014_x86_64.whl (27.5 MB)\n",
      "    27.5/27.5 MB 63.7 MB/s eta 0:00:00\n",
      "Downloading redis-5.0.6-py3-none-any.whl (252 kB)\n",
      "    252.0/252.0 kB 23.3 MB/s eta 0:00:00\n",
      "Downloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (775 kB)\n",
      "    775.1/775.1 kB 49.0 MB/s eta 0:00:00\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading requests_toolbelt-0.10.1-py2.py3-none-any.whl (54 kB)\n",
      "    54.5/54.5 kB 5.7 MB/s eta 0:00:00\n",
      "Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
      "Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "    240.7/240.7 kB 23.9 MB/s eta 0:00:00\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n",
      "    106.7/106.7 kB 9.8 MB/s eta 0:00:00\n",
      "Downloading scikit_image-0.23.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.7 MB)\n",
      "    14.7/14.7 MB 91.0 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
      "    13.3/13.3 MB 95.3 MB/s eta 0:00:00\n",
      "Downloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
      "    36.4/36.4 MB 57.7 MB/s eta 0:00:00\n",
      "Downloading seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
      "    293.3/293.3 kB 24.2 MB/s eta 0:00:00\n",
      "Downloading SecretStorage-3.3.3-py3-none-any.whl (15 kB)\n",
      "Downloading shapely-2.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "    2.5/2.5 MB 76.7 MB/s eta 0:00:00\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading simpervisor-1.0.0-py3-none-any.whl (8.3 kB)\n",
      "Downloading smart_open-7.0.4-py3-none-any.whl (61 kB)\n",
      "    61.2/61.2 kB 5.8 MB/s eta 0:00:00\n",
      "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Downloading SQLAlchemy-2.0.30-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "    3.1/3.1 MB 87.1 MB/s eta 0:00:00\n",
      "Downloading sqlglot-19.9.0-py3-none-any.whl (336 kB)\n",
      "    336.2/336.2 kB 28.9 MB/s eta 0:00:00\n",
      "Downloading sqlparse-0.5.0-py3-none-any.whl (43 kB)\n",
      "    44.0/44.0 kB 4.1 MB/s eta 0:00:00\n",
      "Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
      "    71.9/71.9 kB 7.0 MB/s eta 0:00:00\n",
      "Downloading statsmodels-0.14.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
      "    10.8/10.8 MB 95.3 MB/s eta 0:00:00\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading tangled_up_in_unicode-0.2.0-py3-none-any.whl (4.7 MB)\n",
      "    4.7/4.7 MB 88.0 MB/s eta 0:00:00\n",
      "Downloading tenacity-8.3.0-py3-none-any.whl (25 kB)\n",
      "Downloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
      "    5.5/5.5 MB 83.3 MB/s eta 0:00:00\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "    6.6/6.6 MB 90.7 MB/s eta 0:00:00\n",
      "Downloading tensorboard_plugin_profile-2.15.1-py3-none-any.whl (5.6 MB)\n",
      "    5.6/5.6 MB 84.5 MB/s eta 0:00:00\n",
      "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "    101.7/101.7 kB 10.1 MB/s eta 0:00:00\n",
      "Downloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
      "    475.2/475.2 MB 4.1 MB/s eta 0:00:00\n",
      "Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
      "    442.0/442.0 kB 30.4 MB/s eta 0:00:00\n",
      "Downloading tensorflow_hub-0.15.0-py2.py3-none-any.whl (85 kB)\n",
      "    85.4/85.4 kB 10.2 MB/s eta 0:00:00\n",
      "Downloading tensorflow_io_gcs_filesystem-0.37.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "    5.1/5.1 MB 87.8 MB/s eta 0:00:00\n",
      "Downloading tensorrt_cu12_bindings-10.1.0-cp310-none-manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "    1.1/1.1 MB 14.2 MB/s eta 0:00:00\n",
      "Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading textual-0.67.1-py3-none-any.whl (561 kB)\n",
      "    561.2/561.2 kB 39.6 MB/s eta 0:00:00\n",
      "Downloading tfx-1.15.1-py3-none-any.whl (3.0 MB)\n",
      "    3.0/3.0 MB 7.4 MB/s eta 0:00:00\n",
      "Downloading tfx_bsl-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.5 MB)\n",
      "    22.5/22.5 MB 79.0 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading tifffile-2024.5.22-py3-none-any.whl (225 kB)\n",
      "    225.5/225.5 kB 23.0 MB/s eta 0:00:00\n",
      "Downloading time_machine-2.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34 kB)\n",
      "Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\n",
      "Downloading toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "    56.1/56.1 kB 7.0 MB/s eta 0:00:00\n",
      "Downloading typeguard-4.3.0-py3-none-any.whl (35 kB)\n",
      "Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "    47.2/47.2 kB 5.0 MB/s eta 0:00:00\n",
      "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "    345.4/345.4 kB 30.3 MB/s eta 0:00:00\n",
      "Downloading tzlocal-5.2-py3-none-any.whl (17 kB)\n",
      "Downloading uc_micro_py-1.0.3-py3-none-any.whl (6.2 kB)\n",
      "Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
      "    53.6/53.6 kB 5.9 MB/s eta 0:00:00\n",
      "Downloading uritemplate-3.0.1-py2.py3-none-any.whl (15 kB)\n",
      "Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
      "    143.8/143.8 kB 16.8 MB/s eta 0:00:00\n",
      "Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
      "    62.4/62.4 kB 6.6 MB/s eta 0:00:00\n",
      "Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
      "    3.4/3.4 MB 88.8 MB/s eta 0:00:00\n",
      "Downloading virtualenv-20.26.2-py3-none-any.whl (3.9 MB)\n",
      "    3.9/3.9 MB 96.0 MB/s eta 0:00:00\n",
      "Downloading visions-0.7.5-py3-none-any.whl (102 kB)\n",
      "    102.7/102.7 kB 11.2 MB/s eta 0:00:00\n",
      "Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "    1.2/1.2 MB 57.4 MB/s eta 0:00:00\n",
      "Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "    130.2/130.2 kB 14.8 MB/s eta 0:00:00\n",
      "Downloading werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
      "    227.3/227.3 kB 23.3 MB/s eta 0:00:00\n",
      "Downloading wordcloud-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511 kB)\n",
      "    511.1/511.1 kB 40.6 MB/s eta 0:00:00\n",
      "Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
      "    77.9/77.9 kB 8.4 MB/s eta 0:00:00\n",
      "Downloading wurlitzer-3.1.1-py3-none-any.whl (8.6 kB)\n",
      "Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "    194.1/194.1 kB 23.3 MB/s eta 0:00:00\n",
      "Downloading y_py-0.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "    1.7/1.7 MB 74.9 MB/s eta 0:00:00\n",
      "Downloading yarg-0.1.9-py2.py3-none-any.whl (19 kB)\n",
      "Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "    301.6/301.6 kB 26.8 MB/s eta 0:00:00\n",
      "Downloading ydata_profiling-4.6.0-py2.py3-none-any.whl (357 kB)\n",
      "    357.5/357.5 kB 29.0 MB/s eta 0:00:00\n",
      "Downloading ydf-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.3 MB)\n",
      "    9.3/9.3 MB 105.3 MB/s eta 0:00:00\n",
      "Downloading ypy_websocket-0.8.4-py3-none-any.whl (10 kB)\n",
      "Downloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "    5.4/5.4 MB 88.9 MB/s eta 0:00:00\n",
      "Downloading aiosqlite-0.20.0-py3-none-any.whl (15 kB)\n",
      "Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "    1.7/1.7 MB 69.7 MB/s eta 0:00:00\n",
      "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
      "    129.1/129.1 kB 14.3 MB/s eta 0:00:00\n",
      "Downloading struct2tensor-0.46.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.0 MB)\n",
      "    3.0/3.0 MB 87.0 MB/s eta 0:00:00\n",
      "Downloading tensorflow_data_validation-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.0 MB)\n",
      "    19.0/19.0 MB 89.8 MB/s eta 0:00:00\n",
      "Downloading tensorflow_metadata-1.15.0-py3-none-any.whl (28 kB)\n",
      "Downloading tensorflow_serving_api-2.15.1-py2.py3-none-any.whl (26 kB)\n",
      "Downloading tensorflow_transform-1.15.0-py3-none-any.whl (451 kB)\n",
      "    451.2/451.2 kB 37.0 MB/s eta 0:00:00\n",
      "Downloading tensorflow_model_analysis-0.46.0-py3-none-any.whl (1.9 MB)\n",
      "    1.9/1.9 MB 72.5 MB/s eta 0:00:00\n",
      "Downloading tf_keras-2.15.1-py3-none-any.whl (1.7 MB)\n",
      "    1.7/1.7 MB 72.6 MB/s eta 0:00:00\n",
      "Downloading anyio-4.4.0-py3-none-any.whl (86 kB)\n",
      "    86.8/86.8 kB 9.5 MB/s eta 0:00:00\n",
      "Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "    60.8/60.8 kB 6.5 MB/s eta 0:00:00\n",
      "Downloading certifi-2024.6.2-py3-none-any.whl (164 kB)\n",
      "    164.4/164.4 kB 16.1 MB/s eta 0:00:00\n",
      "Downloading cffi-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (443 kB)\n",
      "    443.9/443.9 kB 36.4 MB/s eta 0:00:00\n",
      "Downloading cryptography-42.0.8-cp39-abi3-manylinux_2_28_x86_64.whl (3.9 MB)\n",
      "    3.9/3.9 MB 96.8 MB/s eta 0:00:00\n",
      "Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
      "Downloading exceptiongroup-1.2.1-py3-none-any.whl (16 kB)\n",
      "Downloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "    66.8/66.8 kB 7.3 MB/s eta 0:00:00\n",
      "Downloading importlib_metadata-7.1.0-py3-none-any.whl (24 kB)\n",
      "Downloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Downloading ipython-7.34.0-py3-none-any.whl (793 kB)\n",
      "    793.8/793.8 kB 48.2 MB/s eta 0:00:00\n",
      "Downloading ipywidgets-7.7.1-py2.py3-none-any.whl (123 kB)\n",
      "    123.4/123.4 kB 13.6 MB/s eta 0:00:00\n",
      "Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "    133.3/133.3 kB 14.7 MB/s eta 0:00:00\n",
      "Downloading jsonschema-4.22.0-py3-none-any.whl (88 kB)\n",
      "    88.3/88.3 kB 9.3 MB/s eta 0:00:00\n",
      "Downloading jupyter_events-0.10.0-py3-none-any.whl (18 kB)\n",
      "Downloading jupyter_server-2.14.1-py3-none-any.whl (383 kB)\n",
      "    383.4/383.4 kB 32.8 MB/s eta 0:00:00\n",
      "Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "    2.2/2.2 MB 79.4 MB/s eta 0:00:00\n",
      "Downloading nbclient-0.10.0-py3-none-any.whl (25 kB)\n",
      "Downloading nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "    78.5/78.5 kB 8.1 MB/s eta 0:00:00\n",
      "Downloading notebook-7.2.1-py3-none-any.whl (5.0 MB)\n",
      "    5.0/5.0 MB 90.7 MB/s eta 0:00:00\n",
      "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading packaging-24.1-py3-none-any.whl (53 kB)\n",
      "    54.0/54.0 kB 6.3 MB/s eta 0:00:00\n",
      "Downloading pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\n",
      "    63.8/63.8 kB 7.8 MB/s eta 0:00:00\n",
      "Downloading phik-0.12.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (686 kB)\n",
      "    686.1/686.1 kB 51.1 MB/s eta 0:00:00\n",
      "Downloading platformdirs-4.2.2-py3-none-any.whl (18 kB)\n",
      "Downloading pluggy-1.5.0-py3-none-any.whl (20 kB)\n",
      "Downloading pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
      "    1.2/1.2 MB 59.1 MB/s eta 0:00:00\n",
      "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "    229.9/229.9 kB 23.6 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\n",
      "    705.5/705.5 kB 47.9 MB/s eta 0:00:00\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "    64.9/64.9 kB 6.8 MB/s eta 0:00:00\n",
      "Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading tornado-6.4.1-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (436 kB)\n",
      "    436.8/436.8 kB 34.9 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "    78.3/78.3 kB 9.2 MB/s eta 0:00:00\n",
      "Downloading traitlets-5.14.3-py3-none-any.whl (85 kB)\n",
      "    85.4/85.4 kB 9.8 MB/s eta 0:00:00\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
      "Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "    58.8/58.8 kB 6.5 MB/s eta 0:00:00\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
      "Downloading argon2_cffi-23.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "    142.1/142.1 kB 16.3 MB/s eta 0:00:00\n",
      "Downloading fastjsonschema-2.20.0-py3-none-any.whl (23 kB)\n",
      "Downloading ipykernel-6.29.4-py3-none-any.whl (117 kB)\n",
      "    117.1/117.1 kB 13.8 MB/s eta 0:00:00\n",
      "Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
      "Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
      "    1.6/1.6 MB 70.9 MB/s eta 0:00:00\n",
      "Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
      "Downloading jupyter_client-8.6.2-py3-none-any.whl (105 kB)\n",
      "    105.9/105.9 kB 11.4 MB/s eta 0:00:00\n",
      "Downloading jupyter_core-5.7.2-py3-none-any.whl (28 kB)\n",
      "Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
      "Downloading jupyterlab-4.2.3-py3-none-any.whl (11.6 MB)\n",
      "    11.6/11.6 MB 103.9 MB/s eta 0:00:00\n",
      "Downloading matplotlib_inline-0.1.7-py3-none-any.whl (9.9 kB)\n",
      "Downloading nbconvert-7.16.4-py3-none-any.whl (257 kB)\n",
      "    257.4/257.4 kB 24.3 MB/s eta 0:00:00\n",
      "Downloading notebook_shim-0.2.4-py3-none-any.whl (13 kB)\n",
      "Downloading prometheus_client-0.20.0-py3-none-any.whl (54 kB)\n",
      "    54.5/54.5 kB 5.4 MB/s eta 0:00:00\n",
      "Downloading prompt_toolkit-3.0.47-py3-none-any.whl (386 kB)\n",
      "    386.4/386.4 kB 32.3 MB/s eta 0:00:00\n",
      "Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
      "Downloading python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)\n",
      "Downloading pyzmq-26.0.3-cp310-cp310-manylinux_2_28_x86_64.whl (919 kB)\n",
      "    919.8/919.8 kB 51.8 MB/s eta 0:00:00\n",
      "Downloading referencing-0.35.1-py3-none-any.whl (26 kB)\n",
      "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Downloading rpds_py-0.18.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "    1.1/1.1 MB 56.3 MB/s eta 0:00:00\n",
      "Downloading Send2Trash-1.8.3-py3-none-any.whl (18 kB)\n",
      "Downloading terminado-0.18.1-py3-none-any.whl (14 kB)\n",
      "Downloading widgetsnbextension-3.6.6-py2.py3-none-any.whl (1.6 MB)\n",
      "    1.6/1.6 MB 68.5 MB/s eta 0:00:00\n",
      "Downloading zipp-3.19.2-py3-none-any.whl (9.0 kB)\n",
      "Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
      "Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "    117.6/117.6 kB 12.0 MB/s eta 0:00:00\n",
      "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
      "Downloading async_lru-2.0.4-py3-none-any.whl (6.1 kB)\n",
      "Downloading bleach-6.1.0-py3-none-any.whl (162 kB)\n",
      "    162.8/162.8 kB 16.4 MB/s eta 0:00:00\n",
      "Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
      "Downloading debugpy-1.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "    3.0/3.0 MB 85.2 MB/s eta 0:00:00\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
      "    69.1/69.1 kB 6.8 MB/s eta 0:00:00\n",
      "Downloading mistune-3.0.2-py3-none-any.whl (47 kB)\n",
      "    48.0/48.0 kB 5.1 MB/s eta 0:00:00\n",
      "Downloading pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\n",
      "Downloading parso-0.8.4-py2.py3-none-any.whl (103 kB)\n",
      "    103.7/103.7 kB 10.4 MB/s eta 0:00:00\n",
      "Downloading webcolors-24.6.0-py3-none-any.whl (14 kB)\n",
      "Downloading argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)\n",
      "    86.2/86.2 kB 9.7 MB/s eta 0:00:00\n",
      "Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "    147.9/147.9 kB 14.8 MB/s eta 0:00:00\n",
      "Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "Downloading jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n",
      "Downloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
      "Downloading tinycss2-1.3.0-py3-none-any.whl (22 kB)\n",
      "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
      "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
      "    66.4/66.4 kB 7.7 MB/s eta 0:00:00\n",
      "Downloading soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Downloading types_python_dateutil-2.9.0.20240316-py3-none-any.whl (9.7 kB)\n",
      "Building wheels for collected packages: crcmod, dill, docopt, google-apitools, google-cloud-jupyter-config, gpustat, hdfs, htmlmin, kfp, kfp-server-api, pyfarmhash, pyjsparser, rouge_score, tensorrt, tensorrt-cu12, tensorrt-cu12-libs, kernels-mixer\n",
      "  Building wheel for crcmod (setup.py): started\n",
      "  Building wheel for crcmod (setup.py): finished with status 'done'\n",
      "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=30827 sha256=d7d3b499474b2500e0f4b6187e487b44227c6bfa97ecd142f4fc5b90f6f00eb6\n",
      "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
      "  Building wheel for dill (setup.py): started\n",
      "  Building wheel for dill (setup.py): finished with status 'done'\n",
      "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78541 sha256=a4808f58b6d54c766db7f3ff6fa876e1e9131f96ba4c2a985c55f89166dc557c\n",
      "  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n",
      "  Building wheel for docopt (setup.py): started\n",
      "  Building wheel for docopt (setup.py): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=c4c0f9ee4a331e972f3870a8f5e5ac4b91ff9676152fd6601b09ad4938e1fab6\n",
      "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
      "  Building wheel for google-apitools (setup.py): started\n",
      "  Building wheel for google-apitools (setup.py): finished with status 'done'\n",
      "  Created wheel for google-apitools: filename=google_apitools-0.5.31-py3-none-any.whl size=131015 sha256=85c372d8f71180f434f97d7c69b93e19e855aed17a31b38128baa678fc5590a0\n",
      "  Stored in directory: /root/.cache/pip/wheels/04/b7/e0/9712f8c23a5da3d9d16fb88216b897bf60e85b12f5470f26ee\n",
      "  Building wheel for google-cloud-jupyter-config (setup.py): started\n",
      "  Building wheel for google-cloud-jupyter-config (setup.py): finished with status 'done'\n",
      "  Created wheel for google-cloud-jupyter-config: filename=google_cloud_jupyter_config-0.0.10-py2.py3-none-any.whl size=12007 sha256=5b9ed2811998ca10bc636a37b7313da22c502deb48aebf87f789e690084dbfec\n",
      "  Stored in directory: /root/.cache/pip/wheels/39/de/c4/83340c241465da688cbfe2a7040deabb36b4eed6e7e863f368\n",
      "  Building wheel for gpustat (setup.py): started\n",
      "  Building wheel for gpustat (setup.py): finished with status 'done'\n",
      "  Created wheel for gpustat: filename=gpustat-1.0.0-py3-none-any.whl size=19863 sha256=09abe9e7c70112a7053bdb22e99d85bc56d912fda9cdfe7ebb09431dc0d931fc\n",
      "  Stored in directory: /root/.cache/pip/wheels/d2/48/27/33e31726d2001b997a11c23a7c76f7a48d8d96851f14ef0cd2\n",
      "  Building wheel for hdfs (setup.py): started\n",
      "  Building wheel for hdfs (setup.py): finished with status 'done'\n",
      "  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34324 sha256=6a9c7ef614f786025c61eec4388e51d16ee00157782ed07beb128e6d4ba88fb9\n",
      "  Stored in directory: /root/.cache/pip/wheels/e5/8d/b6/99c1c0a3ac5788c866b0ecd3f48b0134a5910e6ed26011800b\n",
      "  Building wheel for htmlmin (setup.py): started\n",
      "  Building wheel for htmlmin (setup.py): finished with status 'done'\n",
      "  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27080 sha256=cb36b266f7ee97aaee40e868a1ebd3c27bd100c8e10d5f900c838fc88354aa4c\n",
      "  Stored in directory: /root/.cache/pip/wheels/dd/91/29/a79cecb328d01739e64017b6fb9a1ab9d8cb1853098ec5966d\n",
      "  Building wheel for kfp (setup.py): started\n",
      "  Building wheel for kfp (setup.py): finished with status 'done'\n",
      "  Created wheel for kfp: filename=kfp-2.5.0-py3-none-any.whl size=585425 sha256=22ee074f77e888f48b3be8ea3717413e12fa5aa23eb31bd01014e4aa4302f9b3\n",
      "  Stored in directory: /root/.cache/pip/wheels/e4/fc/d8/a8b70c6fd81161556bb6659d7bd77080f0d2de9a66d067af5b\n",
      "  Building wheel for kfp-server-api (setup.py): started\n",
      "  Building wheel for kfp-server-api (setup.py): finished with status 'done'\n",
      "  Created wheel for kfp-server-api: filename=kfp_server_api-2.0.5-py3-none-any.whl size=114733 sha256=b7a846c00d7eb4f72a63f73b2bc9ea865038bb11a7d3b841a22f78416d25a3e3\n",
      "  Stored in directory: /root/.cache/pip/wheels/ac/4f/f0/2f622aadcbf8921fb72d24f52efaffacc235f863c195c289c5\n",
      "  Building wheel for pyfarmhash (setup.py): started\n",
      "  Building wheel for pyfarmhash (setup.py): finished with status 'done'\n",
      "  Created wheel for pyfarmhash: filename=pyfarmhash-0.3.2-cp310-cp310-linux_x86_64.whl size=96697 sha256=b9cb50f84699f1929d1ce494a7688fc7c5d476f076ba3d810d3ef66584a643e7\n",
      "  Stored in directory: /root/.cache/pip/wheels/e0/08/da/f66b1f3258fe3f1e767b2136c5444dbfa9fa3f7944cc5e1983\n",
      "  Building wheel for pyjsparser (setup.py): started\n",
      "  Building wheel for pyjsparser (setup.py): finished with status 'done'\n",
      "  Created wheel for pyjsparser: filename=pyjsparser-2.7.1-py3-none-any.whl size=25984 sha256=af8a578c4d70fe4a68587ea15f964e54b7b7cbeaa764bab667129508a4d0e03e\n",
      "  Stored in directory: /root/.cache/pip/wheels/5e/81/26/5956478df303e2bf5a85a5df595bb307bd25948a4bab69f7c7\n",
      "  Building wheel for rouge_score (setup.py): started\n",
      "  Building wheel for rouge_score (setup.py): finished with status 'done'\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=1c2742ad07fb39640f8758e342b836675c8e8e180dc8b9ee0e59b6bc4436f7a9\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "  Building wheel for tensorrt (setup.py): started\n",
      "  Building wheel for tensorrt (setup.py): finished with status 'done'\n",
      "  Created wheel for tensorrt: filename=tensorrt-10.1.0-py2.py3-none-any.whl size=16332 sha256=ee8fa5a19582aaf9646fed6311ed7460ee4777c79927e8db94c1d469cea4bf2e\n",
      "  Stored in directory: /root/.cache/pip/wheels/f5/55/f5/a1836546c0d92da062e9365a0323953f5e6a0a5f51d46da503\n",
      "  Building wheel for tensorrt-cu12 (setup.py): started\n",
      "  Building wheel for tensorrt-cu12 (setup.py): finished with status 'done'\n",
      "  Created wheel for tensorrt-cu12: filename=tensorrt_cu12-10.1.0-py2.py3-none-any.whl size=17554 sha256=5edf7abfb03718d5baa9a3f626efca066f4e9f22248178f4d5897fd561950d73\n",
      "  Stored in directory: /root/.cache/pip/wheels/15/96/43/6559f5cfe251d64e7a7b49efb429ae5258eff95976e5f12312\n",
      "  Building wheel for tensorrt-cu12-libs (pyproject.toml): started\n",
      "  Building wheel for tensorrt-cu12-libs (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for tensorrt-cu12-libs: filename=tensorrt_cu12_libs-10.1.0-py2.py3-none-manylinux_2_17_x86_64.whl size=1056270840 sha256=1ad13c26b3f441267a746df6859e44eb0e8da78d4382458d1fd2eb7675abd49f\n",
      "  Stored in directory: /root/.cache/pip/wheels/18/d0/78/3c2ad1c46e9434a528a07e9d9b8402a96c9a4d55fa2aca0773\n",
      "  Building wheel for kernels-mixer (setup.py): started\n",
      "  Building wheel for kernels-mixer (setup.py): finished with status 'done'\n",
      "  Created wheel for kernels-mixer: filename=kernels_mixer-0.0.13-py3-none-any.whl size=17112 sha256=83f4e2283df3c2b8cc5ce2e83fa1713c5b4f9bb1df38a619c1fe54431b00e8b6\n",
      "  Stored in directory: /root/.cache/pip/wheels/fe/45/f1/1ad21aec6b13be1dd8dc8404c1596030367a14da5c06970d65\n",
      "Successfully built crcmod dill docopt google-apitools google-cloud-jupyter-config gpustat hdfs htmlmin kfp kfp-server-api pyfarmhash pyjsparser rouge_score tensorrt tensorrt-cu12 tensorrt-cu12-libs kernels-mixer\n",
      "Installing collected packages: y-py, webencodings, wcwidth, tensorrt-cu12-bindings, pytz, pyjsparser, pyfarmhash, py-spy, ptyprocess, pickleshare, opencensus-context, nvidia-ml-py, namex, multipledispatch, libclang, kt-legacy, ipython-genutils, htmlmin, flatbuffers, fastjsonschema, Farama-Notifications, docopt, dm-tree, distlib, crcmod, colorful, backcall, appdirs, ansicolors, zstandard, zipp, xxhash, wurlitzer, wrapt, websockets, websocket-client, webcolors, uvloop, urllib3, uritemplate, uri-template, ujson, uc-micro-py, tzlocal, tzdata, typing-extensions, types-python-dateutil, traitlets, tqdm, tornado, toolz, tomli, tinycss2, threadpoolctl, termcolor, tensorrt-cu12, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, tenacity, tangled-up-in-unicode, tabulate, sqlparse, sqlglot, soupsieve, sniffio, smmap, six, simpervisor, shellingham, send2trash, rpds-py, rfc3986-validator, regex, ray-cpp, pyzmq, pyyaml, python-multipart, python-json-logger, python-dotenv, pyparsing, PyJWT, pygments, pycparser, pyasn1, pyarrow-hotfix, psutil, protobuf, prompt-toolkit, prometheus-client, prettytable, portalocker, pluggy, platformdirs, pillow, pexpect, parsy, parso, pandocfilters, packaging, overrides, orjson, objsize, oauthlib, nvidia-cuda-runtime-cu12, numpy, networkx, nest-asyncio, multimethod, multidict, msgpack, more-itertools, mistune, mdurl, MarkupSafe, Markdown, lz4, lxml, llvmlite, kiwisolver, keras, jupyterlab_widgets, jupyterlab-pygments, jupyter-ydoc, jsonpointer, jsonpickle, json5, joblib, jeepney, iniconfig, importlib-resources, idna, hypertune, humanize, httptools, h11, grpcio, greenlet, google-crc32c, gast, fsspec, frozenlist, fqdn, fonttools, filelock, fasteners, fastavro, exceptiongroup, entrypoints, docstring_parser, dnspython, dill, defusedxml, decorator, debugpy, dacite, Cython, cycler, colorama, cloudpickle, click, charset-normalizer, certifi, cachetools, bidict, backports.tarfile, Babel, attrs, atpublic, async-timeout, aiofiles, absl-py, ydf, yarl, Werkzeug, virtualenv, uvicorn, typeguard, tifffile, terminado, tensorrt-cu12-libs, tensorrt, tensorflow-metadata, tensorflow-hub, tensorboardX, SQLAlchemy, smart-open, shapely, scipy, sacrebleu, rsa, rfc3339-validator, retrying, requests, referencing, redis, PyWavelets, python-dateutil, pytest, pyproj, pymongo, pydot, pydantic, pyasn1_modules, pyarrow, proto-plus, portpicker, plotly, patsy, optree, opt-einsum, opentelemetry-proto, numba, nltk, ml-metadata, ml-dtypes, matplotlib-inline, markdown-it-py, linkify-it-py, lazy_loader, kfp-pipeline-spec, jupyter-core, Js2Py, jinja2, jedi, jax-jumpy, jaraco.functools, jaraco.context, jaraco.classes, importlib-metadata, imageio, httplib2, httpcore, h5py, gviz-api, grpc-interceptor, googleapis-common-protos, google-resumable-media, google-pasta, gitdb, email_validator, Deprecated, contourpy, comm, cligj, click-plugins, cffi, blessed, bleach, beautifulsoup4, async-lru, astunparse, anyio, aiosqlite, aiosignal, ypy-websocket, yarg, watchfiles, time-machine, tensorboard_plugin_profile, starlette, scikit-learn, scikit-image, rouge_score, rich, requests-toolbelt, requests-oauthlib, pandas, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, oauth2client, mdit-py-plugins, matplotlib, kfp-server-api, keras-tuner, jupyter-server-terminals, jupyter-client, jsonschema-specifications, ipython, ImageHash, httpx, hdfs, gymnasium, grpcio-status, gpustat, google-auth, GitPython, fiona, docker, cryptography, brotlipy, arrow, argon2-cffi-bindings, aiohttp, wordcloud, visions, typer, statsmodels, SecretStorage, seaborn, pins, phik, pendulum, opentelemetry-semantic-conventions, kubernetes, jsonschema, isoduration, ipykernel, grpc-google-iam-v1, google-auth-oauthlib, google-auth-httplib2, google-apitools, google-api-core, geopandas, db-dtypes, argon2-cffi, aiohttp-cors, textual, tensorboard, ray, pydata-google-auth, opentelemetry-sdk, opencensus, nbformat, keyring, google-cloud-core, google-api-python-client, apache-beam, ydata-profiling, tensorflow, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, nbclient, ml-pipelines-sdk, memray, keyrings.google-artifactregistry-auth, jupytext, jupyter-events, google-cloud-vision, google-cloud-videointelligence, google-cloud-storage, google-cloud-spanner, google-cloud-resource-manager, google-cloud-recommendations-ai, google-cloud-pubsub, google-cloud-monitoring, google-cloud-language, google-cloud-iam, google-cloud-functions, google-cloud-dlp, google-cloud-datastore, google-cloud-bigtable, google-cloud-bigquery-storage, google-cloud-bigquery-connection, google-cloud-bigquery, google-cloud-artifact-registry, tf_keras, tensorflow-serving-api, struct2tensor, papermill, pandas-profiling, opentelemetry-exporter-otlp, nbconvert, kfp, google-cloud-pubsublite, google-cloud-aiplatform, gcsfs, jupyter-server, tfx-bsl, notebook-shim, jupyterlab_server, jupyter_server_proxy, jupyter-server-mathjax, jupyter_server_fileid, jupyter-lsp, ibis-framework, google-cloud-jupyter-config, tensorflow-transform, tensorflow-data-validation, nbdime, kernels-mixer, jupyterlab, jupyter_server_ydoc, notebook, jupyterlab_git, widgetsnbextension, jupyter-http-over-ws, ipywidgets, tensorflow_model_analysis, bigframes, tfx, dataproc_jupyter_plugin\n",
      "Successfully installed Babel-2.15.0 Cython-3.0.10 Deprecated-1.2.14 Farama-Notifications-0.0.4 GitPython-3.1.43 ImageHash-4.3.1 Js2Py-0.74 Markdown-3.6 MarkupSafe-2.1.5 PyJWT-2.8.0 PyWavelets-1.6.0 SQLAlchemy-2.0.30 SecretStorage-3.3.3 Werkzeug-3.0.3 absl-py-1.4.0 aiofiles-22.1.0 aiohttp-3.9.5 aiohttp-cors-0.7.0 aiosignal-1.3.1 aiosqlite-0.20.0 ansicolors-1.1.8 anyio-4.4.0 apache-beam-2.56.0 appdirs-1.4.4 argon2-cffi-23.1.0 argon2-cffi-bindings-21.2.0 arrow-1.3.0 astunparse-1.6.3 async-lru-2.0.4 async-timeout-4.0.3 atpublic-4.1.0 attrs-23.2.0 backcall-0.2.0 backports.tarfile-1.2.0 beautifulsoup4-4.12.3 bidict-0.23.1 bigframes-0.22.0 bleach-6.1.0 blessed-1.20.0 brotlipy-0.7.0 cachetools-5.3.3 certifi-2024.6.2 cffi-1.16.0 charset-normalizer-3.3.2 click-8.1.7 click-plugins-1.1.1 cligj-0.7.2 cloudpickle-2.2.1 colorama-0.4.6 colorful-0.5.6 comm-0.2.2 contourpy-1.2.1 crcmod-1.7 cryptography-42.0.8 cycler-0.12.1 dacite-1.8.1 dataproc_jupyter_plugin-0.1.79 db-dtypes-1.2.0 debugpy-1.8.2 decorator-5.1.1 defusedxml-0.7.1 dill-0.3.1.1 distlib-0.3.8 dm-tree-0.1.8 dnspython-2.6.1 docker-4.4.4 docopt-0.6.2 docstring_parser-0.16 email_validator-2.1.1 entrypoints-0.4 exceptiongroup-1.2.1 fastavro-1.9.4 fasteners-0.19 fastjsonschema-2.20.0 filelock-3.15.1 fiona-1.9.6 flatbuffers-24.3.25 fonttools-4.53.0 fqdn-1.5.1 frozenlist-1.4.1 fsspec-2024.6.0 gast-0.4.0 gcsfs-2024.6.0 geopandas-0.14.4 gitdb-4.0.11 google-api-core-2.19.0 google-api-python-client-1.12.11 google-apitools-0.5.31 google-auth-2.30.0 google-auth-httplib2-0.2.0 google-auth-oauthlib-1.0.0 google-cloud-aiplatform-1.55.0 google-cloud-artifact-registry-1.11.3 google-cloud-bigquery-3.24.0 google-cloud-bigquery-connection-1.15.3 google-cloud-bigquery-storage-2.25.0 google-cloud-bigtable-2.24.0 google-cloud-core-2.4.1 google-cloud-datastore-2.19.0 google-cloud-dlp-3.18.0 google-cloud-functions-1.16.3 google-cloud-iam-2.15.0 google-cloud-jupyter-config-0.0.10 google-cloud-language-2.13.3 google-cloud-monitoring-2.21.0 google-cloud-pubsub-2.21.5 google-cloud-pubsublite-1.10.0 google-cloud-recommendations-ai-0.10.10 google-cloud-resource-manager-1.12.3 google-cloud-spanner-3.47.0 google-cloud-storage-2.14.0 google-cloud-videointelligence-2.13.3 google-cloud-vision-3.7.2 google-crc32c-1.5.0 google-pasta-0.2.0 google-resumable-media-2.7.1 googleapis-common-protos-1.63.1 gpustat-1.0.0 greenlet-3.0.3 grpc-google-iam-v1-0.13.0 grpc-interceptor-0.15.4 grpcio-1.64.1 grpcio-status-1.48.2 gviz-api-1.10.0 gymnasium-0.28.1 h11-0.14.0 h5py-3.11.0 hdfs-2.7.3 htmlmin-0.1.12 httpcore-1.0.5 httplib2-0.22.0 httptools-0.6.1 httpx-0.27.0 humanize-4.9.0 hypertune-1.1.0 ibis-framework-7.1.0 idna-3.7 imageio-2.34.1 importlib-metadata-7.1.0 importlib-resources-6.4.0 iniconfig-2.0.0 ipykernel-6.29.4 ipython-7.34.0 ipython-genutils-0.2.0 ipywidgets-7.7.1 isoduration-20.11.0 jaraco.classes-3.4.0 jaraco.context-5.3.0 jaraco.functools-4.0.1 jax-jumpy-1.0.0 jedi-0.19.1 jeepney-0.8.0 jinja2-3.1.4 joblib-1.4.2 json5-0.9.25 jsonpickle-3.2.2 jsonpointer-3.0.0 jsonschema-4.22.0 jsonschema-specifications-2023.12.1 jupyter-client-8.6.2 jupyter-core-5.7.2 jupyter-events-0.10.0 jupyter-http-over-ws-0.0.8 jupyter-lsp-2.2.5 jupyter-server-2.14.1 jupyter-server-mathjax-0.2.6 jupyter-server-terminals-0.5.3 jupyter-ydoc-0.2.5 jupyter_server_fileid-0.9.2 jupyter_server_proxy-4.2.0 jupyter_server_ydoc-0.8.0 jupyterlab-4.2.3 jupyterlab-pygments-0.3.0 jupyterlab_git-0.44.0 jupyterlab_server-2.27.2 jupyterlab_widgets-3.0.11 jupytext-1.16.2 keras-2.15.0 keras-tuner-1.4.7 kernels-mixer-0.0.13 keyring-25.2.1 keyrings.google-artifactregistry-auth-1.1.2 kfp-2.5.0 kfp-pipeline-spec-0.2.2 kfp-server-api-2.0.5 kiwisolver-1.4.5 kt-legacy-1.0.5 kubernetes-12.0.1 lazy_loader-0.4 libclang-18.1.1 linkify-it-py-2.0.3 llvmlite-0.41.1 lxml-5.2.2 lz4-4.3.3 markdown-it-py-3.0.0 matplotlib-3.7.3 matplotlib-inline-0.1.7 mdit-py-plugins-0.4.1 mdurl-0.1.2 memray-1.12.0 mistune-3.0.2 ml-dtypes-0.3.2 ml-metadata-1.15.0 ml-pipelines-sdk-1.15.1 more-itertools-10.3.0 msgpack-1.0.8 multidict-6.0.5 multimethod-1.11.2 multipledispatch-1.0.0 namex-0.0.8 nbclient-0.10.0 nbconvert-7.16.4 nbdime-3.2.0 nbformat-5.10.4 nest-asyncio-1.6.0 networkx-3.3 nltk-3.8.1 notebook-7.2.1 notebook-shim-0.2.4 numba-0.58.1 numpy-1.24.3 nvidia-cuda-runtime-cu12-12.5.39 nvidia-ml-py-11.495.46 oauth2client-4.1.3 oauthlib-3.2.2 objsize-0.7.0 opencensus-0.11.4 opencensus-context-0.1.3 opentelemetry-api-1.25.0 opentelemetry-exporter-otlp-1.25.0 opentelemetry-exporter-otlp-proto-common-1.25.0 opentelemetry-exporter-otlp-proto-grpc-1.25.0 opentelemetry-exporter-otlp-proto-http-1.25.0 opentelemetry-proto-1.25.0 opentelemetry-sdk-1.25.0 opentelemetry-semantic-conventions-0.46b0 opt-einsum-3.3.0 optree-0.11.0 orjson-3.10.5 overrides-7.7.0 packaging-24.1 pandas-1.5.3 pandas-profiling-3.6.6 pandocfilters-1.5.1 papermill-2.6.0 parso-0.8.4 parsy-2.1 patsy-0.5.6 pendulum-3.0.0 pexpect-4.9.0 phik-0.12.4 pickleshare-0.7.5 pillow-10.3.0 pins-0.8.6 platformdirs-4.2.2 plotly-5.22.0 pluggy-1.5.0 portalocker-2.10.0 portpicker-1.6.0 prettytable-3.10.0 prometheus-client-0.20.0 prompt-toolkit-3.0.47 proto-plus-1.23.0 protobuf-3.20.3 psutil-5.9.3 ptyprocess-0.7.0 py-spy-0.3.14 pyarrow-10.0.1 pyarrow-hotfix-0.6 pyasn1-0.6.0 pyasn1_modules-0.4.0 pycparser-2.22 pydantic-1.10.16 pydata-google-auth-1.8.2 pydot-1.4.2 pyfarmhash-0.3.2 pygments-2.18.0 pyjsparser-2.7.1 pymongo-4.7.3 pyparsing-3.1.2 pyproj-3.6.1 pytest-8.2.2 python-dateutil-2.9.0.post0 python-dotenv-1.0.1 python-json-logger-2.0.7 python-multipart-0.0.9 pytz-2024.1 pyyaml-6.0.1 pyzmq-26.0.3 ray-2.24.0 ray-cpp-2.24.0 redis-5.0.6 referencing-0.35.1 regex-2024.5.15 requests-2.32.3 requests-oauthlib-2.0.0 requests-toolbelt-0.10.1 retrying-1.3.4 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rich-13.7.1 rouge_score-0.1.2 rpds-py-0.18.1 rsa-4.9 sacrebleu-2.4.2 scikit-image-0.23.2 scikit-learn-1.5.0 scipy-1.11.4 seaborn-0.12.2 send2trash-1.8.3 shapely-2.0.4 shellingham-1.5.4 simpervisor-1.0.0 six-1.16.0 smart-open-7.0.4 smmap-5.0.1 sniffio-1.3.1 soupsieve-2.5 sqlglot-19.9.0 sqlparse-0.5.0 starlette-0.37.2 statsmodels-0.14.2 struct2tensor-0.46.0 tabulate-0.9.0 tangled-up-in-unicode-0.2.0 tenacity-8.3.0 tensorboard-2.15.2 tensorboard-data-server-0.7.2 tensorboardX-2.6.2.2 tensorboard_plugin_profile-2.15.1 tensorflow-2.15.1 tensorflow-data-validation-1.15.1 tensorflow-estimator-2.15.0 tensorflow-hub-0.15.0 tensorflow-io-gcs-filesystem-0.37.0 tensorflow-metadata-1.15.0 tensorflow-serving-api-2.15.1 tensorflow-transform-1.15.0 tensorflow_model_analysis-0.46.0 tensorrt-10.1.0 tensorrt-cu12-10.1.0 tensorrt-cu12-bindings-10.1.0 tensorrt-cu12-libs-10.1.0 termcolor-2.4.0 terminado-0.18.1 textual-0.67.1 tf_keras-2.15.1 tfx-1.15.1 tfx-bsl-1.15.1 threadpoolctl-3.5.0 tifffile-2024.5.22 time-machine-2.14.1 tinycss2-1.3.0 tomli-2.0.1 toolz-0.12.1 tornado-6.4.1 tqdm-4.66.4 traitlets-5.14.3 typeguard-4.3.0 typer-0.12.3 types-python-dateutil-2.9.0.20240316 typing-extensions-4.12.2 tzdata-2024.1 tzlocal-5.2 uc-micro-py-1.0.3 ujson-5.10.0 uri-template-1.3.0 uritemplate-3.0.1 urllib3-1.26.18 uvicorn-0.30.1 uvloop-0.19.0 virtualenv-20.26.2 visions-0.7.5 watchfiles-0.22.0 wcwidth-0.2.13 webcolors-24.6.0 webencodings-0.5.1 websocket-client-1.8.0 websockets-12.0 widgetsnbextension-3.6.6 wordcloud-1.9.3 wrapt-1.14.1 wurlitzer-3.1.1 xxhash-3.4.1 y-py-0.6.2 yarg-0.1.9 yarl-1.9.4 ydata-profiling-4.6.0 ydf-0.5.0 ypy-websocket-0.8.4 zipp-3.19.2 zstandard-0.22.0\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\n",
      "\u001b[0mRemoving intermediate container 39b6ddcf0deb\n",
      " ---> f1bc82e0825a\n",
      "Step 6/6 : ENV PYTHONPATH=\"/pipeline:${PYTHONPATH}\"\n",
      " ---> Running in 61e4cfbb11e5\n",
      "Removing intermediate container 61e4cfbb11e5\n",
      " ---> 470fcd28e28d\n",
      "Successfully built 470fcd28e28d\n",
      "Successfully tagged gcr.io/supply-chain-twin-349311/cicd:latest\n",
      "PUSH\n",
      "Pushing gcr.io/supply-chain-twin-349311/cicd:latest\n",
      "The push refers to repository [gcr.io/supply-chain-twin-349311/cicd]\n",
      "b40f87e7ebdd: Preparing\n",
      "49b86b5b72c5: Preparing\n",
      "fa3e71155dcf: Preparing\n",
      "6c208c1eda13: Preparing\n",
      "2e7e15acc0c5: Preparing\n",
      "874337b0fe22: Preparing\n",
      "3796f8a4e35b: Preparing\n",
      "2da9904b909e: Preparing\n",
      "1387079e86ad: Preparing\n",
      "1387079e86ad: Waiting\n",
      "2da9904b909e: Waiting\n",
      "3796f8a4e35b: Waiting\n",
      "874337b0fe22: Waiting\n",
      "2e7e15acc0c5: Layer already exists\n",
      "874337b0fe22: Layer already exists\n",
      "3796f8a4e35b: Layer already exists\n",
      "2da9904b909e: Layer already exists\n",
      "1387079e86ad: Layer already exists\n",
      "49b86b5b72c5: Pushed\n",
      "fa3e71155dcf: Pushed\n",
      "6c208c1eda13: Pushed\n",
      "b40f87e7ebdd: Pushed\n",
      "latest: digest: sha256:6612cc416548b7e5f45a5ec43a8998e630aa41aec85779731e99d8bc09941e14 size: 2216\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                                  IMAGES                                          STATUS\n",
      "63c7c485-2b52-4e3f-a5cc-941a1ea5ad84  2024-06-27T13:50:47+00:00  16M29S    gs://supply-chain-twin-349311_cloudbuild/source/1719496246.867131-112571afb80e469e8c0f76ff3c2b9cc5.tgz  gcr.io/supply-chain-twin-349311/cicd (+1 more)  SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!gcloud builds submit --tag $CICD_IMAGE_URI build/. --timeout=120m --machine-type=e2-highcpu-8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc9b2af",
   "metadata": {},
   "source": [
    "### Run CI/CD from pipeline deployment using Cloud Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00b55593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_REPO_URL=https://github.com/Jashuva-07/mlops.git,_BRANCH=main,_CICD_IMAGE_URI=gcr.io/supply-chain-twin-349311/cicd:latest,_PROJECT=supply-chain-twin-349311,_REGION=us-central1,_GCS_LOCATION=gs://test-lora/chicago-taxi-tips/,_TEST_GCS_LOCATION=gs://test-lora/chicago-taxi-tips/e2e_tests,_BQ_LOCATION=US,_BQ_DATASET_NAME=chi_e2e,_BQ_TABLE_NAME=chicago_taxitrips_prep,_DATASET_DISPLAY_NAME=chicago-taxi-tips,_MODEL_DISPLAY_NAME=chicago-taxi-tips-classifier-v09,_CI_TRAIN_LIMIT=1000,_CI_TEST_LIMIT=100,_CI_UPLOAD_MODEL=0,_CI_ACCURACY_THRESHOLD=0.1,_BEAM_RUNNER=DataflowRunner,_TRAINING_RUNNER=vertex,_TFX_IMAGE_URI=gcr.io/supply-chain-twin-349311/chicago-taxi-tips:tfx-1.2,_PIPELINE_NAME=chicago-taxi-tips-classifier-v09-train-pipeline,_PIPELINES_STORE=gs://test-lora/chicago-taxi-tips/compiled_pipelines\n"
     ]
    }
   ],
   "source": [
    "REPO_URL = \"https://github.com/Jashuva-07/mlops.git\" # Change to your github repo.\n",
    "BRANCH = \"main\"\n",
    "\n",
    "GCS_LOCATION = f\"gs://{BUCKET}/{DATASET_DISPLAY_NAME}/\"\n",
    "TEST_GCS_LOCATION = f\"gs://{BUCKET}/{DATASET_DISPLAY_NAME}/e2e_tests\"\n",
    "CI_TRAIN_LIMIT = 1000\n",
    "CI_TEST_LIMIT = 100\n",
    "CI_UPLOAD_MODEL = 0\n",
    "CI_ACCURACY_THRESHOLD = 0.1\n",
    "BEAM_RUNNER = \"DataflowRunner\"\n",
    "TRAINING_RUNNER = \"vertex\"\n",
    "VERSION = 'tfx-1.2'\n",
    "PIPELINE_NAME = f'{MODEL_DISPLAY_NAME}-train-pipeline'\n",
    "PIPELINES_STORE = os.path.join(GCS_LOCATION, \"compiled_pipelines\")\n",
    "\n",
    "TFX_IMAGE_URI = f\"gcr.io/{PROJECT}/{DATASET_DISPLAY_NAME}:{VERSION}\"\n",
    "\n",
    "SUBSTITUTIONS=f\"\"\"\\\n",
    "_REPO_URL='{REPO_URL}',\\\n",
    "_BRANCH={BRANCH},\\\n",
    "_CICD_IMAGE_URI={CICD_IMAGE_URI},\\\n",
    "_PROJECT={PROJECT},\\\n",
    "_REGION={REGION},\\\n",
    "_GCS_LOCATION={GCS_LOCATION},\\\n",
    "_TEST_GCS_LOCATION={TEST_GCS_LOCATION},\\\n",
    "_BQ_LOCATION={BQ_LOCATION},\\\n",
    "_BQ_DATASET_NAME={BQ_DATASET_NAME},\\\n",
    "_BQ_TABLE_NAME={BQ_TABLE_NAME},\\\n",
    "_DATASET_DISPLAY_NAME={DATASET_DISPLAY_NAME},\\\n",
    "_MODEL_DISPLAY_NAME={MODEL_DISPLAY_NAME},\\\n",
    "_CI_TRAIN_LIMIT={CI_TRAIN_LIMIT},\\\n",
    "_CI_TEST_LIMIT={CI_TEST_LIMIT},\\\n",
    "_CI_UPLOAD_MODEL={CI_UPLOAD_MODEL},\\\n",
    "_CI_ACCURACY_THRESHOLD={CI_ACCURACY_THRESHOLD},\\\n",
    "_BEAM_RUNNER={BEAM_RUNNER},\\\n",
    "_TRAINING_RUNNER={TRAINING_RUNNER},\\\n",
    "_TFX_IMAGE_URI={TFX_IMAGE_URI},\\\n",
    "_PIPELINE_NAME={PIPELINE_NAME},\\\n",
    "_PIPELINES_STORE={PIPELINES_STORE}\\\n",
    "\"\"\"\n",
    "\n",
    "!echo $SUBSTITUTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0bc589ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created [https://cloudbuild.googleapis.com/v1/projects/supply-chain-twin-349311/locations/global/builds/14392ebb-365d-4711-9b45-c408770e3a8a].\n",
      "Logs are available at [ https://console.cloud.google.com/cloud-build/builds/14392ebb-365d-4711-9b45-c408770e3a8a?project=1049330678395 ].\n",
      "Waiting for build to complete. Polling interval: 1 second(s).\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"14392ebb-365d-4711-9b45-c408770e3a8a\"\n",
      "\n",
      "FETCHSOURCE\n",
      "BUILD\n",
      "Starting Step #0 - \"Clone Repository\"\n",
      "Step #0 - \"Clone Repository\": Already have image (with digest): gcr.io/cloud-builders/git\n",
      "Step #0 - \"Clone Repository\": Cloning into 'mlops'...\n",
      "Step #0 - \"Clone Repository\": fatal: could not read Username for 'https://github.com': No such device or address\n",
      "Finished Step #0 - \"Clone Repository\"\n",
      "ERROR\n",
      "ERROR: build step 0 \"gcr.io/cloud-builders/git\" failed: step exited with non-zero status: 128\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "BUILD FAILURE: Build step failure: build step 0 \"gcr.io/cloud-builders/git\" failed: step exited with non-zero status: 128\n",
      "\u001b[1;31mERROR:\u001b[0m (gcloud.builds.submit) build 14392ebb-365d-4711-9b45-c408770e3a8a completed with status \"FAILURE\"\n"
     ]
    }
   ],
   "source": [
    "!gcloud builds submit --no-source --timeout=120m --config build/pipeline-deployment.yaml --substitutions {SUBSTITUTIONS} --machine-type=e2-highcpu-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16028a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m122",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cpu:m122"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
